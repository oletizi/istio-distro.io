[{"url":"https://istio.tetratelabs.io/zh/community/event/getistio-inaugural/","title":"00: GetIstio 介绍——社区开幕 meetup","description":"第 0 届：GetIstio 介绍——社区开幕 meetup。","content":" 2021年3月4日 at 下午 12:30 BST  查看你的时区  GetMesh 社区首届 meetup 将作为云原生学院第 18 期直播的特别活动，在 Bilibili 直播。\n 主持人：厉辉 嘉宾：宋净超（Tetrate 布道师/云原生社区创始人）、周礼赞（Tetrate 创始工程师/Envoy 维护者） 直播间：https://live.bilibili.com/22230973 会议纪要：腾讯文档  议题  IstioCon 2021 回顾 Istio 2021 Roadmap Tetrate 开源项目 GetIstio 及 GetEnvoy 介绍 Istio 第三轮官网中文翻译志愿者招募 Istio 学习资源分享  听众收获 2 月底首届 IstioCon 刚刚结束，通过本次直播你会了解到 Istio 社区的一些动向，还有企业级服务网格公司 Tetrate 新开源的项目 GetIstio 及已开源的 GetEnvoy，还有云原生社区 Istio SIG 的活动。\n点此加入 "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/","title":"GetMesh 概览","description":"了解更多关于 GetMesh CLI，如何安装和管理它。","content":"GetMesh 是开始使用 Istio 最简单的方法，并确保您使用的是受信任和支持的 Istio 版本。安装和更新 GetMesh 非常简单，只需发出以下命令即可。\ncurl -sL https://istio.tetratelabs.io/getmesh/install.sh | bash 为什么使用 CLI? GetMesh CLI 简化了 Istio 的安装、管理和升级，使您可以最大限度地利用服务网格和开源的优势。\nGetIsio CLI 工具满足企业级需求，因为它：\n 强制获取 Istio 的认证版本，并只允许安装 Istio 的兼容版本。 允许在多个 istioctl 版本之间无缝切换。 符合 FIPS 标准。 通过整合多个来源的验证库，提供基于平台的 Istio 配置验证。 使用一些云提供商证书管理系统来创建 Istio CA 证书，用于签署服务网格管理工作负载。 提供附加的与云提供商多个集成点。  对于企业生命周期和变更管理实践来说，Istio 的发布时间表可能非常激进。GetMesh 通过针对不同的 Kubernetes 发行版测试所有 Istio 版本的功能完整性来解决这一问题。GetMesh 的 Istio 版本积极支持安全补丁和其他 bug 更新，比上游 Istio 提供的支持寿命要长得多。\n符合 FIPS 标准的版本 有些服务网格客户需要支持更高的安全要求。GetMesh 通过提供两种 Istio 发行版来解决合规性问题。\n tetrate 跟踪上游 Istio，并可能应用额外的补丁。 tetratefips 是符合 FIPS 标准的版本。  上述功能是通过一种优雅的透明方法实现的，现有的设置和工具被充分利用，以提供额外的功能和企业所需的特性集和控制。\n GetMesh 连接到默认 Kubernetes 配置文件所指向的 Kubernetes 集群。如果设置了 KUBECONFIG 环境变量，则以其为优先。 配置验证是针对两个目标进行的。  集群当前的配置，可能包含多个 Istio 配置结构 此外，GetMesh 还验证了清单 yaml 文件（尚未应用于集群的文件）   为 Istio 创建 CA 证书时，假设已经设置好了发行中间 CA 证书的提供商。这是可选的，默认情况下，Istio 为工作负载证书提供自签名证书。  "},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/prerequisites/","title":"先决条件","description":"","content":"要在实践教程中遍历 Istio，我们将需要 Kubernetes 集群和 Istio 的运行实例。\n1. Kubernetes 集群 所有云提供商都已管理了 Kubernete 集群产品，我们可以用来安装 Istio 服务网格。\n我们还可以使用以下平台之一在您的计算机上本地运行 Kubernetes 集群：\n 迷你库 Docker 桌面 种类 MicroK8s  使用本地 Kubernetes 群集时，请确保您的计算机满足 Istio 安装的最低要求（例如 16384 MB RAM 和 4 个 CPU）。此外，请确保 Kubernetes 集群版本为 v1.19.0 或更高版本。\n安装 Kubernetes CLI 如果您需要安装 Kubernetes CLI，请按照以下说明进行操作。\n我们可以运行 kubectl version 以检查是否已安装 CLI。您应该看到类似于以下内容的输出：\n$ kubectl version Client Version: version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;19\u0026#34;, GitVersion:\u0026#34;v1.19.2\u0026#34;, GitCommit:\u0026#34;f5743093fd1c663cb0cbc89748f730662345d44d\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2020-09-16T21:51:49Z\u0026#34;, GoVersion:\u0026#34;go1.15.2\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;darwin/amd64\u0026#34;} Server Version: version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;19\u0026#34;, GitVersion:\u0026#34;v1.19.0\u0026#34;, GitCommit:\u0026#34;e19964183377d0ec2052d1f1fa930c4d7575bd50\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2020-08-26T14:23:04Z\u0026#34;, GoVersion:\u0026#34;go1.15\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} 2. 使用 Tetrate Istio Distro 安装 Istio Tetrate Istio Distro 是开始使用 Istio 的最简单方法。设置 Kubernetes 集群后，可以下载 Tetrate Istio Distro：\ncurl -sL https://istio.tetratelabs.io/getmesh/install.sh | bash 最后，要安装 Istio 的演示配置文件，请使用以下命令：\ngetmesh istioctl install --set profile=demo 3. 标记用于 Istio 边车注入的命名空间 我们需要标记希望 Istio 自动将 Sidecar 代理注入 Kubernetes 部署的命名空间。\n要标记 kubectl label 命名空间，我们可以使用命令并default用名为的标签标记命名空间（在我们的示例中）istio-injection=enabled：\nkubectl label namespace default istio-injection=enabled 4. 安装 Hello world 应用程序（可选） 作为要在群集上部署的示例，您可以使用 Hello World Web 应用程序。您可以从中提取镜像 gcr.io/tetratelabs/hello-world:1.0.0，并使用以下命令创建 Kubernetes 部署和服务。\nkubectl create deploy helloworld --image=gcr.io/tetratelabs/hello-world:1.0.0 --port=3000 将以下 YAML 复制到 helloworld-svc.yaml 并使用进行部署 kubectl apply -f helloworld-svc.yaml。\napiVersion: v1 kind: Service metadata: name: helloworld labels: app: helloworld spec: ports: - name: http port: 80 targetPort: 3000 selector: app: helloworld 要从外部 IP 访问服务，我们还需要一个网关资源：\napiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: public-gateway spec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - \u0026#39;*\u0026#39; 将上述 YAML 保存到 gateway.yaml 并使用进行部署 kubectl apply -f gateway.yaml。\n现在，我们可以通过外部 IP 地址访问已部署的 Hello World Web 应用程序。您可以使用以下命令获取 IP 地址：\nkubectl get svc istio-ingressgateway -n istio-system -o jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39; "},{"url":"https://istio.tetratelabs.io/zh/community/event/","title":"活动","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/community/event/istiocon-2021/","title":"IstioCon 2021","description":"IstioCon 2021 是业界最受欢迎的服务网格的首届社区会议。","content":"IstioCon 2021 是一个由社区主导的活动，展示了在生产中运行 Istio 的经验教训，来自 Istio 社区的实践经验，并有来自整个 Istio 生态系统的维护者参与。会议提供了主题演讲、技术讲座、闪电演讲、研讨会和路线图会议的组合。趣味性和游戏也包括两个社交时间，以减轻负担，并与 Istio 社区、供应商和维护者交流。\n我们很高兴推出 IstioCon，作为 Istio 社区成员聚会、交流和分享信息的新方式。在它的第一年，IstioCon 将是一个线上的活动，连接我们的全球社区。\nIstioCon 是一个由社区主导的会议，展示了 Istio 在生产中的经验教训，来自 Istio 社区的实践经验，以及来自整个 Istio 生态系统的维护者。我们将提供主题演讲、技术讲座、闪电演讲、研讨会、路线图会议，以及有趣的游戏和社交时间，我们邀请您与 Istio 社区、供应商和维护者一起减负，并与他们交流。我们希望您能加入我们，并参与其中。\n立即注册\n"},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/zero-downtime-releases/","title":"如何执行零停机时间发布","description":"","content":"零停机时间发行的目的是在不影响用户的情况下发行该应用程序的新版本。如果您正在运行网站，则意味着您可以发布新版本而无需关闭网站。这意味着您可以在发布新应用程序的同时向该应用程序发出连续请求，而应用程序用户将永远不会收到可怕的 504 Service Unavailable 响应。\n您可能想知道，如果 Kubernetes 选项更加简单，为什么我们将使用 Istio 进行滚动更新。是的，如果零停机时间部署是您唯一要使用的平台，则可能不应该使用 Istio。您可以使用 Istio 实现相同的行为。但是，您可以更好地控制如何以及何时将流量路由到特定版本。\n先决条件 您可以按照先决条件获取有关如何安装和设置 Istio 的说明。\nKubernetes 部署需要进行版本控制 服务的每个部署都需要进行版本控制——您需要一个名为version: v1（或release: prod类似名称的标签）以及该部署的名称，因此很清楚它代表哪个版本（例如helloworld-v1）。通常，每个部署上至少要设置以下两个标签：\nlabels: app: helloworld version: v1 如果有意义的话，您还可以包括许多其他标签，但是您应该有一个标签来标识您的组件及其版本。\nKubernetes 服务需要通用 无需在 Kubernetes 服务选择器中放置版本标签。带有应用程序 / 组件名称的标签就足够了。另外，请记住以下几点：\n 从包含当前正在运行的版本的目标规则开始，并确保使其保持同步。最终不需要包含许多未使用或过时的子集的目标规则。 如果使用匹配和条件，请始终在 VirtualService 资源中定义 “后备” 路由。如果您不这样做，那么任何不符合条件的请求都将落入数字天堂，并且不会得到满足。  让我们来看下面的例子：\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: my-service spec: hosts: - my-service.default.svc.cluster.local http: - match: - headers: my-header: regex: \u0026#39;.*debug.*\u0026#39; route: - destination: host: my-service.default.svc.cluster.local port: number: 3000 subset: debug 上面的 VirtualService 缺少 “备用” 路由。如果请求不匹配（my-header: debug例如，缺少），则 Istio 将不知道将流量路由到何处。要解决此问题，请始终定义一个在所有匹配项都不为 true 时适用的路由。这是相同的 VirtualService，但具有到的子集的后备路由prod。\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: my-service spec: hosts: - my-service.default.svc.cluster.local http: - match: - headers: my-header: regex: \u0026#39;.*debug.*\u0026#39; route: - destination: host: my-service.default.svc.cluster.local port: number: 3000 subset: debug - route: - destination: host: my-service.default.svc.cluster.local port: number: 3000 subset: prod 牢记这些准则，这是使用 Istio 进行零停机时间部署的大致过程。我们从名为 Kubernetes 的部署开始helloworld-v1，该目标规则包含一个子集（v1）和一个 VirtualService 资源，该资源将所有流量路由到该v1子集。这是 DestinationRule 资源的样子：\napiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: helloworld spec: host: helloworld.default.svc.cluster.local subsets: - name: v1 labels: version: v1 以及相应的 VirtualService：\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: helloworld spec: hosts: - helloworld http: - route: - destination: host: helloworld port: number: 3000 subset: v1 weight: 100 部署这两个资源后，所有流量都将路由到该v1子集。\n推出第二版 在部署第二个版本之前，您需要做的第一件事就是修改 DestinationRule 并添加一个代表第二个版本的子集。\n  部署修改后的目标规则，以添加新的子集：\napiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: helloworld spec: host: helloworld.default.svc.cluster.local subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2   创建 / 部署helloworld-v2 Kubernetes 部署。\n  更新虚拟服务并重新部署它。在虚拟服务中，您可以配置到子集v1的流量的百分比和到新子集的流量的百分比v2。\n  您可以通过多种方式执行此操作 - 您可以逐步路由更多流量v2（例如，以 10％的增量），或者可以在版本之间进行直接的 50/50 分割，甚至可以将 100％的流量路由到新的v2子集。\n最后，将所有流量路由到最新 / 最新子集后，您可以按照以下顺序进行操作，以删除先前的v1部署和子集：\n v1从 VirtualService 中删除该子集，然后重新部署它。这将导致所有流量都进入v2子集。 v1从 DestinationRule 中删除该子集，然后重新部署它。 最后，v1由于不再发送任何流量，您现在可以安全地删除 Kubernetes 部署。  如果到了这一部分，所有流量现在都在流向v2子集，并且您不再有任何v1工件在运行。\n"},{"url":"https://istio.tetratelabs.io/zh/config-validation/","title":"配置验证","description":"Istio 配置验证。","content":"Istio 配置是由一组多个对象和对象类型定义的，很容易出现操作者错误或架构疏忽。getmesh config-validate 命令对集群的当前配置和尚未应用的 yaml 清单进行验证。\n该命令使用外部资源（如上游 Istio 验证、Kiali 库和 Tetrate Istio Distro 自定义配置检查）调用一系列验证。然后组合的验证输出将被发送到 stdout。我们一直在积极添加自定义配置验证检查。\n"},{"url":"https://istio.tetratelabs.io/zh/community/event/getenvoy-deep-dive/","title":"01：使用 GetEnvoy 轻松实现 Envoy 和 WASM","description":"第 1 届：使用 GetEnvoy 轻松实现 Envoy 和 WASM。","content":" 2021年3月4日 at 下午 9:00 PST  查看你的时区   Zoom：https://us02web.zoom.us/j/89163866904 会议纪要：Google doc  社区的第 1 届 meetup 上推出更广泛的 Istio 生态系统，介绍 Envoy 以及像 GetIstio 一样，GetEnvoy 项目如何帮助确保在任何云或平台上取得成功。Christoph Pakulski 将展示 WASM 的力量，以及 Istio 和 Envoy 如何更好地结合。\n 欢迎和介绍  社区新闻 未来话题 社区资源   GetEnvoy  Envoy 概览 GetEnvoy CLI GetEnvoy demo GetEnvoy roadmap   问答 最后是资源链接  点此加入 "},{"url":"https://istio.tetratelabs.io/zh/istio-ca-certs-integrations/","title":"Istio CA Certs 集成","description":"GCP CAS 集成","content":"Istio 提供了不同的机制来签署 mTLS 功能的工作负载证书。如：\n Istio CA 使用自签的根证书。 Istio CA 使用管理员指定的证书和密钥以及管理员指定的根证书。 自定义 CA 发行的密钥和证书文件安装到 sidecar 上。 实验性自定义 CA 集成使用 Kubernetes CSR API（Kubernetes 1.18+）。 外部 CA 使用 Istio CA gRPC API（通过 Istiod RA 模型或直接验证工作负载和验证 SAN）。  GetMesh 与 AWS 证书管理器、GCP 证书授权服务（CAS）和 cert-manager 的私有 CA 集成，以签署工作负载证书。\n"},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/traffic-mirroring/","title":"如何使用流量镜像","description":"","content":"除了可以基于各种传入请求属性（例如 URL 的一部分，标头值，请求方法等）在不同应用程序版本之间进行更多的 “传统” 流量路由之外，Istio 还支持流量镜像。\n当您不想发布应用程序的新版本并将用户暴露给它时，可以使用流量镜像。但是，您仍然希望对其进行部署，并观察其工作原理，收集遥测数据，并将现有应用程序的性能和功能与新应用程序进行比较。\n您可能会问——部署和发布某些内容有什么区别？当我们谈论将服务部署到生产环境时，我们只是将可执行代码（二进制文件，容器，以及执行代码所需的任何形式）移动到生产环境中。但是，我们没有向其发送任何生产流量。该应用程序已存在，但不影响它旁边运行的任何现有应用程序和服务。\n发布应用程序涉及采用已部署的实例并开始将生产流量路由到该实例。此时，我们移至生产环境的代码正在运行，并且可能会影响其他应用程序和最终用户。\n在两个版本之间路由流量（进行蓝绿色发布）是有用且有用的，但是存在风险。例如，如果新应用程序损坏或出现故障怎么办？即使新应用仅接收了 1％的生产流量，它仍然会对许多用户产生负面影响。\n什么是流量镜像？ 流量镜像的想法是最大程度地降低将用户暴露于潜在损坏或错误的应用程序中的风险。我们没有部署，释放流量并将其路由到新应用程序，而是部署了新应用程序并将镜像的生产流量发送到该应用程序的发行版。\n然后，您可以观察到应用程序接收到的镜像流量是否有错误，而不会影响任何生产流量。除了在应用程序的已部署版本上运行各种测试之外，我们现在还可以使用实际的生产流量并扩大测试范围。这给了我们更大的信心，并将释放出无法正常工作的东西的风险降到最低。\n请注意，发送到镜像实例的请求是 “即发即弃”，并且镜像实例发回的任何响应都将被忽略。\n如何使用 Istio 启用流量镜像？ 这是一个快速的 YAML 代码段，显示了如何使用 Istio 启用流量镜像。\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: my-app spec: hosts: - my-app http: - route: - destination: host: my-app.default.svc.cluster.local port: number: 3000 subset: v1 weight: 100 mirror: host: my-app.default.svc.cluster.local port: number: 3000 subset: test-v1 上面的 VirtualService 将 100％的流量路由到 v1 子集，同时还将相同的流量镜像到该test-v1子集。发送给v1子集的相同请求将被复制并触发该test-v1子集。\n最快看到此效果的方法是test-v1在将一些请求发送到应用程序的 v1 版本时查看应用程序的日志。\n调用应用程序时您将获得的响应将来自该v1子集。但是，您还将看到请求镜像到该test-v1子集：\nkubectl logs my-app-test-v1–78fc64b995-krzf7 -c svc -f \u0026gt; my-app@test-1.0.0 start /app \u0026gt; node server.js Listening on port 3000 GET /hello 200 9.303 ms — 59 GET /hello 200 0.811 ms — 59 GET /hello 200 0.254 ms — 59 GET /hello 200 3.563 ms — 59 "},{"url":"https://istio.tetratelabs.io/zh/community/event/getistio-deep-dive/","title":"02：使用 GetIstio 轻松管理 Istio","description":"第 2 届：GetIstio 是管理 Istio 最简便的方式。","content":" 2021年3月16日 at 下午 9:00 PDT  查看你的时区   Zoom：https://us02web.zoom.us/j/89163866904 会议纪要：Google doc  第二届社区 meetup 将深入了解 getmesh gen-ca，以帮助 Istio 与中间证书颁发机构（CA）整合。GetIstio 将通过管理 Istio 跨云的安装、运维和升级来完成比 CA 集成更多的工作。加入我们，我们将以简单的方式深入了解 Istio!\n 欢迎和介绍  社区新闻 未来话题 社区资源   GetIstio  GetIstio CLI GetIstio demo GetIstio roadmap   getmesh gen-ca  从不同的管理服务中生成中间 CA   问答 最后是资源链接  点此加入 "},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/sticky-sessions/","title":"如何使用粘性会话","description":"","content":"什么是粘性会话？ 粘性会话背后的想法是将对特定会话的请求路由到服务第一个请求的同一端点。通过粘性会话，您可以基于 HTTP 标头或 cookie 将服务实例与调用者相关联。如果您的服务在第一个请求上执行昂贵的操作，但为所有后续调用缓存该值，则可能要使用粘性会话。这样，如果同一用户发出请求，将不会执行昂贵的操作，并且将使用缓存中的值。\n先决条件 您可以按照先决条件获取有关如何安装和设置 Istio 的说明。\n如何在 Istio 中使用粘性会话？ 为了演示粘性会话的功能，我们将使用一个名为sticky-svc的示例服务。调用时，此服务检查x-user标头的存在。如果标题存在，它将尝试在内部缓存中查找标题值。在使用新x 用户的任何第一个请求中，该值将不在缓存中，因此该服务将休眠 5 秒钟（模拟昂贵的操作），然后，该值将被缓存。具有相同x-user标头值的所有后续请求都将立即返回。这是来自服务源代码的此简单逻辑的代码段：\nvar ( cache = make(map[string]bool) ) func process(userHeaderValue string) { if cache[userHeaderValue] { return } cache[userHeaderValue] = true time.Sleep(5 * time.Second) } 要查看活动中的粘性会话，我们将需要部署该服务的多个副本。这样，当我们启用粘性会话时，具有相同x 用户头值的请求将始终被定向到最初为该请求提供相同x 用户值的 pod 。我们发出的第一个请求仍然需要 5 秒钟。但是，任何后续请求都是即时的。\n让我们继续先创建 Kubernetes 部署和服务。\napiVersion: apps/v1 kind: Deployment metadata: name: sticky-svc namespace: default labels: app: sticky-svc version: v1 spec: replicas: 5 selector: matchLabels: app: sticky-svc version: v1 template: metadata: labels: app: sticky-svc version: v1 spec: containers: - image: gcr.io/tetratelabs/sticky-svc:1.0.0 imagePullPolicy: Always name: svc ports: - containerPort: 8080 --- kind: Service apiVersion: v1 metadata: name: sticky-svc namespace: default labels: app: sticky-svc spec: selector: app: sticky-svc ports: - port: 8080 name: http 复制 将上面的 YAML 保存到sticky-deployment.yaml并运行kubectl apply -f sticky-deployment.yaml以创建 Deployment and Service。\n要从外部 IP 访问服务，我们还需要一个网关资源：\napiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: gateway spec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - \u0026#39;*\u0026#39; 将上述 YAML 保存到gateway.yaml并使用进行部署kubectl apply -f gateway.yaml。\n接下来，我们可以部署 VirtualService 并将其附加到网关。\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: sticky-svc namespace: default spec: hosts: - \u0026#39;*\u0026#39; gateways: - gateway http: - route: - destination: host: sticky-svc.default.svc.cluster.local port: number: 8080 将上述 YAML 保存到sticky-vs.yaml并使用创建kubectl apply -f sticky-vs.yaml\n让我们通过设置标头值/ping几次调用端点，确保无需配置粘性会话即可正常运行x-user：\n$ curl -H \u0026#34;x-user: ricky\u0026#34; http://localhost/ping Call was processed by host sticky-svc-689b4b7876-cv5t9 for user ricky and it took 5.0002721s 第一个请求（按预期）将花费 5 秒。如果再进行几个请求，您会发现其中一些请求也将花费 5 秒，而其中一些请求（定向到以前的 Pod）将花费更少的时间，也许是 500 微秒。\n通过创建粘性会话，我们希望实现所有后续请求都在几微秒内完成，而不是花费 5 秒。粘性会话设置可以在服务的目标规则中配置。\n在较高级别上，有两个选项可以选择负载均衡器设置。第一个选项称为简单，我们只能选择下表中所示的一种负载平衡算法。\n   名称 描述     ROUND_ROBIN 循环负载均衡算法（默认）   LEAST_CONN 该算法选择两个随机的健康主机，并选择活动请求较少的主机   随机的 随机选择一个主机   通行证 在没有任何负载平衡的情况下将连接转发到请求的 IP 地址    例如，此代码段会将负载平衡算法设置为LEAST_CONN：\napiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: sticky-svc namespace: default spec: host: sticky-service.default.svc.cluster.local trafficPolicy: loadBalancer: simple: LEAST_CONN 设置负载均衡器设置的第二个选项是使用名为的字段consistentHash。此选项使我们能够基于 HTTP 标头（httpHeaderName），Cookie（httpCookie）或其他属性（例如，使用useSourceIp: true设置的源 IP）提供会话亲缘关系。\n让我们使用x-user标头名称在目标规则中定义一致的哈希算法并进行部署：\napiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: sticky-svc namespace: default spec: host: sticky-svc.default.svc.cluster.local trafficPolicy: loadBalancer: consistentHash: httpHeaderName: x-user 复制 将上述 YAML 保存到sticky-dr-hash.yaml并使用进行部署kubectl apply -f sticky-dr-hash.yaml。\n在测试之前，让我们重新启动所有 Pod，以便获得一个干净的状态并清除内存中的缓存。首先，我们将部署缩减为 0 个副本，然后将其缩减为 5 个副本：\nkubectl scale deploy sticky-svc --replicas=0 kubectl scale deploy sticky-svc --replicas=5 复制 所有副本都运行后，尝试向端点发出第一个请求：\n$ curl -H \u0026#34;x-user: ricky\u0026#34; http://localhost/ping Call was processed by host sticky-svc-689b4b7876-cq8hs for user ricky and it took 5.0003232s 不出所料，第一个请求需要 5 秒钟。但是，任何后续请求都将发送到同一实例，并且所需的时间要少得多：\n$ curl -H \u0026#34;x-user: ricky\u0026#34; http://localhost/ping Call was process by host sticky-svc-689b4b7876-cq8hs for user ricky and it took 47.4µs $ curl -H \u0026#34;x-user: ricky\u0026#34; http://localhost/ping Call was process by host sticky-svc-689b4b7876-cq8hs for user ricky and it took 53.7µs $ curl -H \u0026#34;x-user: ricky\u0026#34; http://localhost/ping Call was process by host sticky-svc-689b4b7876-cq8hs for user ricky and it took 46.1µs $ curl -H \u0026#34;x-user: ricky\u0026#34; http://localhost/ping Call was process by host sticky-svc-689b4b7876-cq8hs for user ricky and it took 76.5µs 这是一个棘手的环节！如果我们与其他用户发送请求，则最初会花费 5 秒钟，但随后它将再次发送到同一 pod。\n"},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/","title":"Istio 实践教程","description":"在你让 Istio 运行之后，按照这些教程来磨练你的 Istio 技能。","content":"本节包含 Istio 的实用教程和演练。\n   标题 描述     先决条件 所有先决条件列表以及有关如何安装和配置它们的说明   如何执行零停机时间发布 了解如何使用 Istio 在不停机的情况下发布新版本   如何使用流量镜像 了解有关流量镜像以及如何在 Istio 中使用它的信息   如何使用粘性会话 了解粘性会话以及如何在 Istio 中使用它们   如何设置 SSL 证书 了解如何使用真实的 SSL 证书设置 Istio 入口网关   如何部署多个 Istio 入口网关 了解如何部署多个 Istio 入口网关   将 AWS Cloud Map 与 Istio 集成 了解如何集成云资源发现服务（AWS Cloud Map）   如何安装 Apache SkyWalking 了解如何安装 Apache SkyWalking 并将其与 Istio 集成以获得可观察性    "},{"url":"https://istio.tetratelabs.io/zh/community/event/istio-big-talk-ep-01/","title":"《Istio 大咖说》第 1 期：Istio 开源四周年回顾与展望","description":"让我们一起回顾 Istio 发布四周年的点点滴滴。","content":"节目信息  时间：2021 年 5 月 25 日晚 8 点 主持人：宋净超（Tetrate） 嘉宾：马若飞（FreeWheel） 嘉宾介绍：《Istio 实战指南》作者、极客时间《Service Mesh 实战》专栏作者、AWS Container Hero 视频回放：《Istio 大咖说》第 1 期：Istio 开源四周年回顾与展望 幻灯片归档：GitHub 互动文档：本期无  本期简介 想了解 Istio 的来历吗？想知道 Istio 自我救赎般的架构重构吗？想窥探 Istio 开发背后的趣事吗？想一起解读最新版本的新特性吗？北京时间 5 月 25 日晚上 8 点，相约 B 站，让我们一起回顾 Istio 发布四周年的点点滴滴，B 站直播间不见不散！\n"},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/setting-up-ssl-certs/","title":"如何设置 SSL 证书","description":"","content":"目前，必须使用 SSL 证书。它们通过加密来帮助保护服务器和客户端之间发送的数据，从而使您的网站更具信誉。本节将探讨几种不同的方法来获取 SSL 证书并将Istio 网关配置为使用它们。\n我们将学习如何手动创建自签名证书，然后获取真实的 SSL 证书并进行设置。正如您将看到的，设置所有这些并不太复杂。\n先决条件 为了继续学习，您将需要一个实际的，由云托管的 Kubernetes 集群。需要一个云托管群集，因为我们需要一个外部 IP 地址来连接域名。当然，您还需要一个域名。\n您可以按照先决条件获取有关如何安装和设置 Istio 的说明。\n部署样本应用程序 为了确保所有内容都能正常工作，我们将首先部署一个简单的 Hello World Web 应用程序。如果您要使用自己的应用程序 / 服务，请随时使用。否则，您可以继续使用并使用该 gcr.io/tetratelabs/hello-world:1.0.0 镜像。\nkubectl create deploy helloworld --image=gcr.io/tetratelabs/hello-world:1.0.0 --port=3000 接下来，让我们为其创建一个 Kubernetes 服务。\napiVersion: v1 kind: Service metadata: name: helloworld labels: app: helloworld spec: ports: - name: http port: 80 targetPort: 3000 selector: app: helloworld 将上述 YAML 复制到helloworld-svc.yaml并使用进行部署kubectl apply -f helloworld-svc.yaml。\n 请注意，我们没有使用kubectl expose命令，因为我们需要在 Kubernetes 服务（例如http）中命名端口，而我们不能通过暴露命令来做到这一点。\n 要从外部 IP 访问服务，我们还需要一个网关资源：\napiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: public-gateway spec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - \u0026#39;*\u0026#39; 将上述 YAML 保存到gateway.yaml并使用进行部署kubectl apply -f gateway.yaml。\n 注意：该hosts字段的值为*。在为域名创建 SSL 证书后，我们将更改此字段的值。该值将是实际的域名。\n 最后，我们还需要一个 VirtualService，将流量路由到 helloworld Kubernetes 服务：\napiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: helloworld spec: hosts: - \u0026#39;*\u0026#39; gateways: - public-gateway http: - route: - destination: host: helloworld.default.svc.cluster.local port: number: 80 将上述 YAML 保存到helloworld-vs.yaml并使用进行部署kubectl apply -f helloworld-vs.yaml。\n部署了所有这些资源后，您现在可以获取 Istio 入口网关的外部 IP：\nkubectl get svc -l istio=ingressgateway -n istio-system 如果打开EXTERNAL-IP列中显示的 IP ，您将看到与下图相似的内容。\n我们从应用程序中获得了响应，但也Not Secure从浏览器中获得了消息，该消息告诉用户连接不安全，也没有给人很大的信心。\n自签名证书和手动设置 让我们从最简单的场景开始，我们手动获得证书。首先 - 选择您要使用的域 - 请注意，要进行测试，您不必拥有实际的域名，因为我们将使用自签名证书。\n 自签名证书未由证书颁发机构（CA）签名。您将使用这些证书进行开发和测试。但是，它们不提供由 CA 签名的证书提供的所有安全功能。\n 我将使用mysuperdomain.com我的域名。\nexport DOMAIN_NAME=mysuperdomain.com 第一步，我们将创建根证书（$DOMAIN_NAME.crt）和用于对证书进行签名的私钥（$DOMAIN_NAME.key）：\nopenssl req -x509 -sha256 -nodes -days 365 -newkey rsa:2048 -subj \u0026#39;/O=$DOMAIN_NAME Inc./CN=$DOMAIN_NAME\u0026#39; -keyout $DOMAIN_NAME.key -out $DOMAIN_NAME.crt 上面的命令创建一个.crt和.key文件。\n接下来，我们需要创建私钥和签名请求：\nopenssl req -out helloworld.$DOMAIN_NAME.csr -newkey rsa:2048 -nodes -keyout helloworld.$DOMAIN_NAME.key -subj \u0026#34;/CN=helloworld.$DOMAIN_NAME/O=hello world from $DOMAIN_NAME\u0026#34; 最后，我们可以创建证书：\nopenssl x509 -req -days 365 -CA $DOMAIN_NAME.crt -CAkey $DOMAIN_NAME.key -set_serial 0 -in helloworld.$DOMAIN_NAME.csr -out helloworld.$DOMAIN_NAME.crt 现在您已经有了证书和密钥，您可以创建 Kubernetes Secret 来存储证书和密钥。\n必须调用带有证书的 secret，istio-ingressgateway-certs,我们必须将其部署到istio-system 命名空间。这样，Istio 入口网关将自动加载 secret。\nkubectl create secret tls istio-ingressgateway-certs -n istio-system --key helloworld.$DOMAIN_NAME.key --cert helloworld.$DOMAIN_NAME.crt 设置好 secret 之后，让我们更新网关资源，并告诉它使用此证书和私钥：\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: public-gateway spec: selector: istio: ingressgateway servers: - port: number: 443 name: https protocol: HTTPS tls: mode: SIMPLE # These are coming from the istio-ingressgateway-certs secret serverCertificate: /etc/istio/ingressgateway-certs/tls.crt privateKey: /etc/istio/ingressgateway-certs/tls.key hosts: - helloworld.$DOMAIN_NAME EOF 同样，我们需要使用设置为$DOMAIN_NAME环境变量的域名来更新 VirtualService 中的 hosts 字段：\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: helloworld spec: hosts: - helloworld.$DOMAIN_NAME gateways: - public-gateway http: - route: - destination: host: helloworld.default.svc.cluster.local port: number: 80 EOF 测试此功能最简单的方法是使用 cURL 和该--resolve标志。\nresolve 标志的格式为[DOMAIN]:[PORT]:[IP]，它将与该[DOMAIN]:[PORT]部分匹配的所有请求路由到指定的 IP 地址。这样，我们无需访问 DNS / 域注册商的网站并进行更改即可对其进行测试，并且我们可以使用一个甚至不存在的域。\n本例中的 IP 地址是入口网关的外部 IP 地址。让我们将网关的 IP 地址保存到EXTERNAL_IP环境变量中：\nexport EXTERNAL_IP=$(kubectl get svc istio-ingressgateway -n istio-system -o jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39;) 最后，让我们使用此 cURL 命令来测试 SSL 证书是否得到验证和使用：\ncurl -v --resolve helloworld.$DOMAIN_NAME:443:$EXTERNAL_IP --cacert $DOMAIN_NAME.crt https://helloworld.$DOMAIN_NAME 我们告诉 cURLhelloworld.mysuperdomain.com:443使用上述命令将对入站网关的外部 IP 地址的所有请求解析为。此外，我们提供了先前创建的 CA 证书的名称。\n从输出中，您将能够看到服务器证书的详细信息以及显示该证书已验证的行以及helloworldPod 的实际响应：\n... * Server certificate: * subject: CN=helloworld.mysuperdomain.com; O=hello world from mysuperdomain.com * start date: Feb 2 23:32:11 2021 GMT * expire date: Feb 2 23:32:11 2022 GMT * common name: helloworld.mysuperdomain.com (matched) * issuer: O=mysuperdomain.com Inc.; CN=mysuperdomain.com * SSL certificate verify ok. ... Hello World 真实签名的证书和手动设置 上一节中的自签名证书路径对于踢轮胎和测试事物很有用。我们将需要由您的客户可以信任的真实证书颁发机构（CA）签名的证书。\n有两种方法可以获取 SSL 证书。最受欢迎的是Let\u0026rsquo;s Encrypt。我们将使用SSL For Free，它使用 Let\u0026rsquo;s Encrypt 颁发证书。如果您想花钱，还可以从域注册商或DigiCert购买 SSL 证书。\n在本节中，我们将使用真实的域名和实际的 SSL 证书——这意味着，如果您想继续学习，请确保已准备好要使用的域。\n注册域后，免费打开 SSL 以获取 SSL 证书。请注意，您将必须注册一个免费帐户才能创建 SSL 证书。\n 输入您的域名，例如mydomain.com在文本字段中。 单击创建免费 SSL 证书按钮。 在仪表板上，单击 “**New Certificate”**按钮。   输入域名，然后单击下一步按钮。 选择 90 天证书选项，然后单击下一步。 确认自动生成 CSR 选项，然后单击 “下一步”。 在最后一页上，选择 “**免费”**选项，然后单击 “下一步”。  创建证书后，我们将需要验证域名并证明我们拥有为其创建 SSL 证书的域名。\n可以使用三个选项来验证域：电子邮件验证（确保在域上设置了电子邮件），DNS（CNAME）验证和 HTTP 文件上传。\n您可以使用这些选项中的任何一个。我将使用 CNAME 验证。CNAME 验证涉及登录到您的域注册商，并设置具有特定值的 CNAME 记录。\n设置姓名记录 登录到域名注册商的网站后，我们还要为该域创建一个 A 记录，该记录将指向您的群集的外部 IP 地址。\n由于我们请求 mydomain.com 和www.mydomain.com的证书，因此 A 记录应指向mydomain.comIP 地址。\n验证域 设置 A 记录和 CNAME 之后，可以单击 “**验证域”**按钮。请注意，值传播和验证域可能需要一些时间。\n验证域后，将颁发证书，您将能够下载包含生成文件的 ZIP 包。\n该软件包将包含以下文件：\n ca_bundle.crt certificate.crt 私钥  重新创建秘密 让我们删除现有ingressgateway-certs机密，并使用真实证书创建一个新机密：\nkubectl delete secret istio-ingressgateway-certs -n istio-system 我们可以使用从下载的软件包中获得的真实 SSL 证书和密钥来重新创建 Secret：\nkubectl create secret tls istio-ingressgateway-certs -n istio-system --key private.key --cert certificate.crt 我们还需要更新网关和 VirtualService 来修改主机名。\n让我们先更新网关（确保将其更新mysuperdomain.com为您的实际域名）：\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: public-gateway spec: selector: istio: ingressgateway servers: - port: number: 443 name: https protocol: HTTPS tls: mode: SIMPLE # These are coming from the istio-ingressgateway-certs secret serverCertificate: /etc/istio/ingressgateway-certs/tls.crt privateKey: /etc/istio/ingressgateway-certs/tls.key hosts: - mysuperdomain.com EOF 同样，对 VirtualService 进行更改：\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: helloworld spec: hosts: - mysuperdomain.com gateways: - public-gateway http: - route: - destination: host: helloworld.default.svc.cluster.local port: number: 80 EOF 随着这两个资源的更新，您可以打开所选的浏览器并导航到域。您应该Hello World!在域名显示网站安全之前看到响应和挂锁。如果单击挂锁并检查证书，您将在证书中看到您的域名，以及根授权（Let\u0026rsquo;s Encrypt）和到期日期。\n"},{"url":"https://istio.tetratelabs.io/zh/community/event/istio-big-talk-ep-02/","title":"《Istio 大咖说》第 2 期：从微服务架构到 Istio——架构升级实践分享","description":"本次我们将站在企业用户角度上，邀请了潘天颖分享 Istio 在小电科技的完整落地经验。","content":"节目信息  时间：2021 年 6 月 2 日晚 8 点 主持人：宋净超（Tetrate） 嘉宾：潘天颖（小电科技） 嘉宾介绍：小电科技工程师，云原生爱好者，Kubernetes contributor，Apache committer。 直播间：https://live.bilibili.com/23095515 视频回放：https://www.bilibili.com/video/BV1QQ4y1X7hP/ 幻灯片归档：GitHub  本期简介 云原生赛场已经进入了下半场的比拼，Istio 作为服务网格赛道上的明星选手，社区活跃度和用户知名度都位列前茅。但是国内环境下 Istio 的落地实践却并不多。是什么阻碍了 Istio 的落地，到底 Istio 好不好用？到底什么情况下使用 Istio 利大于弊？本次我们将站在企业用户角度上，邀请了潘天颖分享 Istio 在小电科技的完整落地经验，讲述为什么要从传统微服务架构迁移至服务网格架构，其中遇到的困难与解决方法，以及针对 Istio 的改进方案。\n听众收益  了解 Istio 现状以及使用 Istio 的利弊分析 讲述一次完整的服务迁移至 Istio 实践，可供借鉴 了解一些在使用 Istio 中经常会遇到的典型 Issue 以及解决方案  "},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/multiple-ingress-gateways/","title":"如何部署多个 Istio 入口网关","description":"","content":"安装 Istio 时，可以选择要使用的安装配置文件。最新的 Istio 版本中有六个安装配置文件：default、demo、minimal、remote、empty 和 preview。\n每个配置文件包含不同的组件组合。例如，如果您选择最小配置文件，则只会安装istiod。不会安装出口或入口网关。另一方面，如果使用演示配置文件，则 Istio 会同时安装入口和出口网关istiod。\n您可以在Istio 的 docs 页面上阅读有关配置配置文件的更多信息，并检查属于配置文件的组件。\n使用 Tetrate Istio Distro 您可以传入安装配置文件名称来安装 Istio。例如，要安装演示配置文件，可以运行以下命令：\ngetmesh istioctl install --set profile=demo 您还可以通过将其他--set \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt;键 / 值对传递给命令来自定义 Istio 安装，而不考虑配置文件 。\n为什么要使用多个网关？ 现在，在您创建多个入口网关（以及您的云提供商使用多个负载均衡器）之前，请确保您需要它。负载平衡器需要花钱，这是您需要管理的另一件事。单个负载均衡器可以在很多情况下很好地工作，但是在某些情况下，您可能有一个私有或内部负载均衡器，而又有一个公共负载均衡器。\n具有单个负载均衡器的方案如下图所示。\n在这种情况下，我们有两个不同的外部 IP，它们指向在同一 Kubernetes 集群中运行的两个不同的入口网关。让我们看看如何实现这一目标。\n配置网关 首先，我们需要查看单个 Ingress 网关的 Istio 配置，当您使用默认网关（或演示 / 预览配置文件）时将对其进行部署。我们可以使用以下profile dump命令获取配置：\ngetmesh istioctl profile dump --config-path components.ingressGateways \u0026gt; ingress-gateway.yaml  如果您看到一条消息，说proto: tag has too few fields: \u0026quot;-\u0026quot;您可以放心地忽略它。这是当前正在解决的已知问题。\n ingress-gateway.yaml文件内容如下所示：\n在这种情况下，我们有两个不同的外部 IP，它们指向在同一 Kubernetes 集群中运行的两个不同的入口网关。让我们看看如何实现这一目标。\n配置网关 首先，我们需要查看单个 Ingress 网关的 Istio 配置，当您使用默认网关（或演示 / 预览配置文件）时将对其进行部署。我们可以使用以下profile dump命令获取配置：\ngetmesh istioctl profile dump --config-path components.ingressGateways \u0026gt; ingress-gateway.yaml  如果您看到一条消息，说proto: tag has too few fields: \u0026quot;-\u0026quot;您可以放心地忽略它。这是当前正在解决的已知问题。\n ingress-gateway.yaml文件内容如下所示：\n- enabled: true k8s: env: - name: ISTIO_META_ROUTER_MODE value: standard hpaSpec: maxReplicas: 5 metrics: - resource: name: cpu targetAverageUtilization: 80 type: Resource minReplicas: 1 scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: istio-ingressgateway resources: limits: cpu: 2000m memory: 1024Mi requests: cpu: 100m memory: 128Mi service: ports: - name: status-port port: 15021 protocol: TCP targetPort: 15021 - name: http2 port: 80 protocol: TCP targetPort: 8080 - name: https port: 443 protocol: TCP targetPort: 8443 - name: tcp-istiod port: 15012 protocol: TCP targetPort: 15012 - name: tls port: 15443 protocol: TCP targetPort: 15443 strategy: rollingUpdate: maxSurge: 100% maxUnavailable: 25% name: istio-ingressgateway 上面定义的设置用于默认的 Istio 入口网关。YAML 包括 HorizontalPodAutoscaler 配置（hpaSpec），资源限制和请求（resources），服务端口（ports），部署策略（strategy）和环境变量（env）。\n安装 Istio 时，我们可以直接在 IstioOperator 资源中定义一个或多个网关。这是一个部署单个（默认）入口网关的 Istio 运算符的示例：\napiVersion: install.istio.io/v1alpha1 kind: IstioOperator spec: components: ingressGateways: - name: istio-ingressgateway enabled: true 要部署第二个入口网关，我们可以在ingressGatewaysfield 下添加一个条目。例如，让我们添加第二个istio-ingressgateway-staging在命名空间中调用的网关staging：\napiVersion: install.istio.io/v1alpha1 kind: IstioOperator spec: components: ingressGateways: - name: istio-ingressgateway enabled: true - name: istio-ingressgateway-staging namespace: staging enabled: true 在进行部署之前，我们还需要修改此新网关将使用的标签。请记住，如果我们不指定任何内容，则 Istio 将使用默认的网关配置，并且最终将得到两个带有相同标签的网关，尽管它们位于不同的命名空间中。\nIstioOperator 允许我们仅通过设置label字段来添加新标签或修改现有标签。更新后的 IstioOperator 如下所示：\napiVersion: install.istio.io/v1alpha1 kind: IstioOperator spec: components: ingressGateways: - name: istio-ingressgateway enabled: true - name: istio-ingressgateway-staging namespace: staging enabled: true label: istio: istio-ingressgateway-staging 此 YAML 确保将标签istio: istio-ingressgateway-staging应用于 Istio 为入口网关创建的所有资源。在安装运算符之前，我们需要先创建staging名称空间：\nkubectl create ns staging 现在我们准备安装 Istio。将上述 YAML 保存到istio-2-gw.yaml并用于getmesh安装：\n$ getmesh istioctl install -f istio-2-gw.yaml This will install the Istio default profile with [\u0026#34;Istio core\u0026#34; \u0026#34;Istiod\u0026#34; \u0026#34;Ingress gateways\u0026#34;] components into the cluster. Proceed? (y/N) y ✔ Istio core installed ✔ Istiod installed ✔ Ingress gateways installed ✔ Installation complete 安装完成后，可以在staging名称空间中列出 Pod 和 Services ：\n$ kubectl get po,svc -n staging NAME READY STATUS RESTARTS AGE pod/istio-ingressgateway-staging-8b59464d7-fvlhx 1/1 Running 0 5m30s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/istio-ingressgateway-staging LoadBalancer 10.96.13.200 XX.XXX.XXX.XX 15021:31259/TCP,80:31104/TCP,443:31853/TCP,15443:31053/TCP 5m29s 您会注意到正在运行的istio-ingressgateway-stagingPod 和istio-ingressgateway-staging类型为 LoadBalancer 的服务，其外部 IP 与在istio-system名称空间中运行的默认入口网关不同。\n测试多个 Istio 网关 是时候测试网关了！确保使用标记了default名称空间istio-injection=enabled（请参阅先决条件），然后使用下面的代码片段创建服务，部署，网关和 VirtualService。\ncat \u0026lt;\u0026lt; EOF | kubectl apply -f - apiVersion: v1 kind: Service metadata: name: nginx namespace: default labels: app: nginx spec: ports: - port: 80 name: http selector: app: nginx --- apiVersion: apps/v1 kind: Deployment metadata: name: nginx namespace: default labels: app: nginx spec: replicas: 1 selector: matchLabels: app: nginx template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:alpine imagePullPolicy: IfNotPresent ports: - containerPort: 80 --- apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: gateway namespace: default spec: selector: istio: ingressgateway servers: - port: number: 80 name: http protocol: HTTP hosts: - \u0026#39;*\u0026#39; --- apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: nginx-1 namespace: default spec: hosts: - \u0026#34;*\u0026#34; gateways: - gateway http: - route: - destination: host: nginx port: number: 80 EOF 等待 Pod 启动，然后在浏览器中打开第一个入口网关 IP 地址。您可以使用以下命令获取 IP 地址：\nkubectl get svc istio-ingressgateway -n istio-system -o jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39; 您应该恢复默认的 “欢迎使用 nginx！” 页。让我们看看如果尝试打开部署的第二个入口网关的外部 IP 会发生什么。您可以使用上述类似的命令通过更新服务名称和名称空间来获取 IP 地址：\nkubectl get svc istio-ingressgateway-staging -n staging -o jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39; 您将无法连接到登台入口网关，这是预期的。我们尚未部署任何可配置入口的网关资源。让我们将标签值更新为istio-ingressgateway-staging并重新部署网关资源：\ncat \u0026lt;\u0026lt;EOF | kubectl apply -f - apiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: gateway namespace: default spec: selector: istio: istio-ingressgateway-staging servers: - port: number: 80 name: http protocol: HTTP hosts: - \u0026#39;*\u0026#39; EOF 这次，您应该通过登台网关访问 Nginx 主页，而原始网关不会指向任何内容。\n此时，您可以创建一个单独的网关资源来独立控制两个入口网关。\n"},{"url":"https://istio.tetratelabs.io/zh/ecosystem-partners/","title":"生态 &amp; 合作伙伴","description":"看看 Tetrate Istio Distro 的合作伙伴，看看他们如何从中受益。","content":"我们与各种组织建立合作关系，以创造 Istio 和他们的产品之间的协同作用，以便为社会提供巨大的价值。在这里，我们可以了解更多关于这些合作伙伴关系，你会发现其中的收益。\n AppViewX Jetstack Keyfactor Weaveworks  "},{"url":"https://istio.tetratelabs.io/zh/community/event/istio-big-talk-ep-03/","title":"《Istio 大咖说》第 3 期：如何让 Istio 变得更为高效和智能","description":"本次直播将介绍网易自研的智能网格管理器 Slime。","content":" 时间：6 月 9 日（星期三）晚 8 点 - 9 点 直播间：https://live.bilibili.com/23095515 主持人：宋净超（Tetrate） 嘉宾：杨笛航（网易数帆） 话题：如何让 Istio 变得更为高效和智能 直播回放：https://www.bilibili.com/video/BV18o4y1y75e/ 幻灯片归档：GitHub  嘉宾简介 杨笛航，Istio 社区成员，网易数帆架构师，负责网易轻舟 Service Mesh 配置管理，并主导 Slime 组件设计与研发，参与网易严选和网易传媒的 Service Mesh 建设。具有三年 Istio 控制面功能拓展和性能优化经验。\n话题介绍 Istio 作为当前最火的 Service Mesh 框架，既有大厂背书，也有优秀的设计，及活跃的社区。但是随着 Mixer 组件的移除，我们无法通过扩展 mixer adapter 的方式实现高阶的流量管理功能，Istio 的接口扩展性成为亟待解决的问题。本次直播将分享本次分享将介绍网易自研的智能网格管理器 Slime，借助它，我们实现了配置懒加载，自适应限流，HTTP 插件管理等扩展功能，从而更为高效的使用 Istio。\n听众收益  了解在实际业务中驾驭 Istio 框架的挑战 了解 Slime 的设计特点、技术路线及开源进展 了解网易解决 Service Mesh 架构成熟的经验  "},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/aws-cloudmap-integration/","title":"将 AWS Cloud Map 与 Istio 集成","description":"","content":"本教程描述了如何将 AWS Cloud Map 与 Istio 服务网格集成。\n概述 AWS Cloud Map 是 Amazon Web Services（AWS）提供的托管服务注册表。如果您在 Istio 网格中的应用程序需要访问在 Cloud Map 中注册的外部服务，那么您可能要利用 Cloud Map 中的终结点信息。通过创建 在 Cloud Map 中保存端点信息的 ServiceEntry 资源，我们可以很好地控制和观察服务的出口。但是，Istio 不提供将 ServiceEntries 与 Cloud Map 中的相应记录自动同步的功能。这就是 Istio Cloud Map Operator 发挥作用的地方。\nIstio Cloud Map Operator 旨在通过将 ServiceEntry 推送到 Kube API 服务器来将 Cloud Map 数据同步到 Istio。它会定期检查 AWS 中的 Cloud Map 资源，并且如果信息中有任何更新，则它将在 k8s 集群中创建 / 更新 ServiceEntry 资源。\n先决条件 在继续之前，请确保您已经安装了 Istio 的 Kubernetes 集群。\n您可以按照先决条件获取有关如何安装和设置 Istio 的说明。\n部署 Istio Cloud Map Operator 首先，我们需要下载并部署 Istio Cloud Map Operator：\n  下载位于此处的清单。\n  创建对操作员具有对 AWS Cloud Map 的读取访问权的 AWS IAM 身份。\n  修改 YAML 文件aws-config.yaml，如下所示：\n 通过更新密钥中的值来设置操作员使用的访问密钥。  apiVersion: v1 kind: Secret metadata: name: aws-creds type: Opaque data: access-key-id: \u0026lt;base64-encoded-IAM-access-key-id\u0026gt; # EDIT ME secret-access-key: \u0026lt;base64-encoded-IAM-secret-access-key\u0026gt; # EDIT ME  设置目标 AWS 区域。  apiVersion: v1 kind: ConfigMap metadata: name: aws-config data: aws-region: us-west-2 # EDIT ME   使用 Kubernetes CLI 应用修改后的清单。\n  验证部署 假设您的 AWS Cloud Map 中包含以下数据，\n# list the service in Cloud Map $ aws servicediscovery list-services | jq \u0026#39;.Services[] | \u0026#34;Name: \\(.Name), Id: \\(.Id)\u0026#34;\u0026#39; \u0026#34;Name: getmesh-external-service, Id: srv-ou6hvfmjpls2lev6\u0026#34; # check namespace of your service $ aws servicediscovery get-namespace --id $(aws servicediscovery get-service --id srv-ou6hvfmjpls2lev6 | jq -r \u0026#39;.Service.NamespaceId\u0026#39;) | jq \u0026#39;.Namespace.Name\u0026#39; \u0026#34;my-namespace\u0026#34; # list endpoints $ aws servicediscovery list-instances --service-id srv-ou6hvfmjpls2lev6 | jq \u0026#39;.Instances[] | .Attributes\u0026#39; { \u0026#34;AWS_INSTANCE_IPV4\u0026#34;: \u0026#34;52.192.72.89\u0026#34; } 然后，您可以通过检查是否已创建 ServiceEntry 来验证 Kubernetes 部署，该 ServiceEntry 包含与 AWS Cloud Map 中完全相同的终端节点信息。\n您可以运行以下命令以获取资源的 YAML 表示形式：\nkubectl get serviceentries.networking.istio.io cloudmap-getmesh-external-service.my-namespace -o yaml 上面命令的输出如下所示：\napiVersion: networking.istio.io/v1beta1 kind: ServiceEntry metadata: spec: addresses: - 52.192.72.89 endpoints: - address: 52.192.72.89 ports: http: 80 https: 443 hosts: - getmesh-external-service.my-namespace ports: - name: http number: 80 protocol: HTTP - name: https number: 443 protocol: HTTPS resolution: STATIC 请注意，主机名getmesh-external-service.my-namespace采用以下格式：${Cloud Map's service name}.${service namespace}。\n"},{"url":"https://istio.tetratelabs.io/zh/istio-cheatsheet/","title":"Istio 速查表","description":"管理 Istio 所需的重要命令。","content":"设置  在安装 Istio 之后，请务必进行事前检查和事后检查。通过 GetMesh 安装 Istio 时，默认情况下启用此功能。 作为最佳实践，请安装发行版镜像。 Istio Operator API。 高级定制。 为平台搭建。 不同的云提供商对启用 Istio CNI 的配置要求不同。要启用 CNI，必须在--network-plugin azure添加了标志的情况下创建 AKS 集群。单击此处了解更多详细信息。 从 Istio 1.8 开始，默认情况下，Istio 会通过收集 prometheus.io 批注将应用程序指标合并到 Istio 指标中。在应用程序度量标准数据被认为是敏感的情况下，这可能不合适。可以--set meshConfig.enablePrometheusMerge=false在安装过程中通过在网格级别禁用此默认合并。或者，可以通过prometheus.istio.io/merge-metrics: \u0026quot;false\u0026quot;在窗格上添加注释来针对每个工作负载禁用此功能。单击此处了解更多详细信息。 要在命名空间级别启用自动sidecar注入，请设置 kubectl label \u0026lt;namespace\u0026gt; default istio-injection=enabled  Istio 官方常见问题解答 应用  Istio 对应用程序服务关联，Pod 标签等进行了一些假设，这些假设可以使网格正常运行。可以在这里找到详细信息。 资源注释——虽然 pod 注释提供了改变 Istio sidecar 行为的有用手段，但允许应用团队使用 pod 注释必须是在特殊的基础上，因为它开辟了绕过网格级别设置的途径，并带来了安全风险。 应谨慎使用基于 HTTP 和 TCP 的就绪探针，因为它们需要允许从 kubelet 到 pod 的非 mTLS 流量。而是使用在 pod 内执行命令的基于命令的探针，而不是向 pod 发送请求。 集群中的每个无头服务必须使用唯一的端口。如果两个无头服务共享同一端口，则系统的行为是不确定的。 使用 ServiceEntries 代替 ExternalName 服务。 Istio 中的协议选择。  常见问题  使用 Istio CNI 的初始化容器 由于 Istio CNI 甚至在应用程序 Pod 启动之前就设置了流量重定向，因此可能会导致与应用程序初始化容器不兼容。请参阅此处了解更多详细信息和解决方法。 Istio 入口网关的空回复 通常，Istio 入口网关 Pod 是通过云提供商负载平衡器或其他 GTM / LTM 到达的。如果 TLS 在负载均衡器处终止，并重新建立到 Istio 入口网关，并且未设置下游 SNI 标头字段，则 Istio Ingress 网关将无法基于 SNI 标头终止 TLS。这将导致 Istio 网关的响应为空。为避免这种情况，提供程序负载平衡器必须设置 SNI 标头，否则 Istio 入口网关应为所有具有通配符 dns cert 的主机提供服务。如果是后者，则可以通过 HTTP\u0026rsquo;Authority' 标头进一步路由到应用程序服务。 禁止来自 Istio Ingress Gateway 的响应 对于未应用授权策略的工作负载，Istio 不会实施允许所有请求的访问控制。当授权策略适用于工作负载时，默认情况下拒绝对工作负载的访问。网关工作负载也是如此。当将命名空间级别的策略应用于控制对集群内部流量的访问时，该策略也将应用于该命名空间中的 Ingress 网关，从而可以阻止到网关的外部流量。这是常见的陷阱之一。在这种情况下，请向入口工作负载添加其他授权以允许外部流量。有关如何使流量进入 Kubernetes 和 Istio 以及基于 IP 的白 / 黑清单的详细信息，请参阅文档 EKS VM 集成 EKS 集群的服务负载平衡器通常使用 Ingress.Hostname 而不是默认的 Ingress.IP。从 Istio 1.8.2 开始，在运行istioctl experimental workload entry configure用于将 VM 集成到网格中的命令时，需要在 EKS 集群上传递的--ingressIP标志eastwestgateway。否则，网关地址将为空，并且 VM 将无法连接至控制平面。通常，当使用具有类似行为的 EKS 或发行版时，依赖 Ingress.IP 的应用程序必须更改为使用 Ingress.Hostname。 Istio 网络 Istio 安全 Istio 可观察性 Sidecar 注入问题 配置验证问题  Istio 网络  Istio 网络文档的最佳做法 服务进入  必须严密监视服务条目的添加，以确保不向用户命名空间提供任意外部访问。 主机名  给定主机名只能有一个服务条目。同一主机名的多个服务条目将导致未定义的行为。 主机名上不得有两个服务条目重叠。例如，两个带有主机 * .example.com 和 * .com 的服务条目将在运行时导致未定义的行为。 主机名只能使用完全限定的域名。简称，不带 “。” 不应该使用。   地址  服务条目中的地址字段等同于 Kubernetes 服务的 ClusterIP 字段。没有地址字段的服务条目等同于无头服务。因此，除了使用 HTTP 或 HTTPS / TLS 协议的服务条目外，所有对无头服务的限制都在这里适用。当且仅当所有服务条目都使用相同协议时，才允许在同一端口上使用多个无地址服务条目。在这种情况下，协议可以是 HTTP 或 TLS 之一。在使用 HTTP 的情况下，使用 HTTP Host 标头区分目标服务。对于 TLS，使用 TLS 连接中的 SNI 值来区分目标服务。请参阅地址字段为空时 Istio 智能 DNS 代理如何解决此问题。 除非地址字段具有 CIDR 块，否则请避免使用 NONE 解析模式。没有地址字段且分辨率为 NONE 的服务条目将允许流量访问该服务条目中指定的端口上的任何 IP，从而造成潜在的安全问题。     虚拟服务  对于给定的主机名，应该只有一个虚拟服务。多个虚拟服务将导致不良行为。避免使用短名称来引用虚拟服务中的主机，因为解释受运行时上下文的约束，从而产生了不希望的歧义。 对于 HTTP 规则，与正则表达式相比，首选完全匹配或前缀 URL 匹配。除非精心设计，否则基于正则表达式的匹配速度很慢并且具有意想不到的副作用。 虚拟服务不能被继承。因此，主机 * .example.com 的虚拟服务的设置独立于主机 * .com 的 VirtualService 的设置。如果具有不同通配符主机的多个虚拟服务与给定的主机名匹配，则只有最特定的虚拟服务中的设置才会在运行时应用。   目的地规则  在创建用于流量转移的子集时，在创建带有子集的目标规则与创建引用这些子集的虚拟服务之间要留出几秒钟的延迟。延迟可确保当飞行员发送引用那些子集的路由配置时，该子集的 Envoy 上游配置就位。 可以使用通配符目标规则跨主机范围指定单个目标规则。例如，istio-config 根命名空间中的全局目标规则使用相互 TLS 配置与 * .local 主机名匹配的所有服务。当为更特定的主机名（例如 * .ns1.svc.cluster.local 或 svc1.ns1.svc.cluster.local）创建目标规则时，将选择最特定的目标规则。其他通配符目标规则的设置不会被继承。因此，重要的是任何用户编写的目标规则都应携带在全局目标规则中设置的所有必需设置，例如相互 TLS，异常检测值（如果有）等。   虚拟服务范围和目的地  除非严格控制配置访问，否则客户端仍然可以通过在客户端命名空间中使用 exportTo 值为 \u0026lsquo;。编写规则来覆盖服务器指定的目标规则和虚拟服务。服务的目标规则和虚拟服务（在 Kubernetes 或服务条目中）会影响与该服务进行对话的所有 Sidecar。异常检测，重试策略等设置在客户端sidecar上执行。虽然可能很容易让每个使用者命名空间编写自己的虚拟服务和其他命名空间服务的目标规则，但如果无法限制此类自定义配置的可见性，则可能导致未定义的行为。   sidecar  除非严格控制配置访问，否则命名空间所有者可以使用整个命名空间范围的 Sidecar 覆盖全局指定的 Sidecar，从而通过声明对 egress.hosts 部分中的*/ 的*依赖来导致与没有 Sidecar 的系统相同的行为。即使是从具有潜在冲突配置的多个命名空间导入服务和配置。 建议在 Istio 中使用 Sidecar API 来限制每个工作负载对系统中其他工作负载的依赖性。仅使用一个 Sidecar 资源即可用于整个命名空间，而无需工作负载选择器来配置整个命名空间范围的默认值就足够了。每个 Sidecar 资源都指定命名空间中工作负载所需的主机。这些主机与 Kubernetes 服务，Istio 服务条目和 Istio VirtualServices 中的主机名相对应。根据导入的服务主机名，还将从服务的命名空间中自动导入相应的目标规则。 sidecar在本egress.hosts节中声明对其他命名空间中服务的依赖。声明对主机名的依赖关系（带或不带通配符）将使 Pilot 尝试搜索存在该主机的所有命名空间，并从所有匹配的命名空间中导入。例如，    出口： -主机： -“ * / *” 或者\n出口： -主机： -foo.example.com＃从任何导出该主机的命名空间中导入 -.fun.com＃从任何与此模式匹配的命名空间中导入所有主机 需要注意的是，如果在多个命名空间中存在与同一主机冲突的服务条目，或者在多个命名空间中具有与同一主机冲突的虚拟服务（带有exportTo: *），则特定资源的选择取决于这些资源的创建顺序。这种行为可能会在生产中引起意想不到的后果，因为这通常对开发人员而言并不明显。\n sidecar不支持继承。如果命名空间声明了 Sidecar 资源，则命名空间本地 Sidecar 优先于全局默认 Sidecar。 当多个 Sidecar 具有重叠的工作负载选择器时，为吊舱选择 Sidecar 资源是任意的。因此，必须注意确保在使用工作负载选择器创作 Sidecar 时，每个 Sidecar 在其命名空间中都针对一组独特的 pod。  Istio 安全  Istio 安全最佳实践 Kubernetes CSR API 需要 Kubernetes 1.18 + 版本。某些 Kubernetes 发行版legacy-unknown甚至在较早版本的 Kubernetes 中都支持 Kubernetes 签名者，并且所有 X509 扩展都得到了认可。由于这不是一个普遍的事实，因此在选择legacy-unknown签名者时，请注意较低的 Kubernetes 版本。  Istio 可观察性 Istio 可观察性的最佳实践。\n调试  要检查 Istio 集群配置以及尚未应用的 Istio 配置是否有效，请运行getmesh config-validate 命令。 很多时候，默认特使日志提供了大量有关流量的信息。使用此链接可获得默认的特使日志格式详细信息。 为了更好地了解网格，istio-proxy 和控制平面窗格，Istio 提供了基于 istioctl 和 UI 的仪表板功能。详情在这里。  有用的链接  GetMesh CLI Kubectl 本地 Kubernetes（种类，microk8s，minikube，dockerdesktop）  整合方式  Skywalking（日志聚合和可视化）：使用开源工具分析平台，该工具通过日志聚合提供对多集群和多云环境的图形分析 Zipkin（跟踪）：跟踪和分析分布式事务的路径，性能和延迟 Prometheus（监视器）：记录指标以跟踪 Istio 和网格中应用程序的运行状况 Grafana（可视化）：连接到各种数据源并使用图表，表格和热图可视化数据 Kiali：使用此服务网格可视化工具执行基本的故障排除  文献资料  Tetrate Istio Distro func-e 交互式学习 Istio 概念 Envoy 文件 Istio 详细信息：  流量管理 安全构造 可观察性    "},{"url":"https://istio.tetratelabs.io/zh/community/event/istio-big-talk-ep-04/","title":"《Istio 大咖说》第 4 期：如何让 Istio 在大规模生产中落地","description":"本次直播将分享百度的 Istio 生产落地经验。","content":" 时间：6 月 23 日（星期三）晚 8 点 - 9 点 直播间：https://live.bilibili.com/23095515 主持人：宋净超（Tetrate） 嘉宾：陈鹏（百度） 话题：如何让 Istio 在大规模生产中落地 提问地址：腾讯文档 直播回放：https://www.bilibili.com/video/BV18M4y1u76t  嘉宾简介 陈鹏，百度研发工程师，现就职于百度基础架构部云原生团队，主导和参与了服务网格在百度内部多个核心业务的大规模落地，对云原生、Service Mesh、Isito 等方向有深入的研究和实践经验。\n话题介绍  百度服务治理现状 \u0026amp; Istio 落地挑战 深入解读如何让 Isito 在大规模生产环境落地 实践经验总结 \u0026amp; 思考  通过本次分享你将了解当前 Isito 落地的困境和解决思路。\n"},{"url":"https://istio.tetratelabs.io/zh/faq/","title":"FAQ","description":"Tetrate Istio Distro 常见问题。","content":"Tetrate Istio Distro 是什么？ 今天，我们推出了 Tetrate Istio Distro，这是一个 Istio 上游组件的发行版，经过 Tetrate 的测试、优化、保护和支持。Tetrate Istio Distro 为不同的 Kubernetes 环境提供经过审核的 Istio 原生版本，使 Istio 生命周期管理变得简单而安全。初始版本已通过 EKS、EKS-D 的审核，并提供与 AWS KMS 的本地集成。我们将逐步增加对新的 Kubernetes 版本和新的 KMS 后端的支持。Tetrate Istio Distro 将根据其支持政策支持最新的 3 个版本，并为 FedRAMP 环境提供符合 FIPS 标准的 Istio 版本。\n为什么使用 Tetrate Istio Distro？ 如果您正在采用 Istio，并且需要一个可靠、安全的发行版来运行在 AWS、Azure 或 GCP 环境中，您应该使用 Tetrate Istio Distro。\n它是免费的吗？ 是的。Tetrate Istio Distro 是一个免费（如语音和啤酒）的开源项目，我们欢迎社区参与和贡献。\nTetrate Istio Distro 的支持版本有哪些？ 请点击 Github 项目上的支持平台页面。\nTetrate Istio Distro 有哪些不同的组件，与上游的 Istio 相比如何？ Tetrate Istio Distro 是上游 Istio 的发行版，它由一个 CLI、一个代理和集成 API 组成。 更多细节请查看 Tetrate Istio Distro CLI 命令参考、Cert 集成 和安全补丁。\n我正在使用 Istio OSS，如何切换到 getmesh？ Tetrate Istio Distro 是 Istio 的上游发行版。\n我是 Istio 的新手，应该从何处着手？ 我们建议你从 Tetrate Istio Distro 的经审核的环境开始。你可以安心地使用 Isito 的所有功能。\n我是一个平台管理员，试图在我的组织中简化 Istio 二进制文件。我应该如何使用 Tetrate Istio Distro？ 有多种方法可以利用 Tetrate Istio Distro。请参考命令参考和教程。\n我如何知道我的 Istio 是否有 CVE？ 如果您已经订阅了社区更新，Tetrate Istio Distro 将通知您 CVE 和零日漏洞。\nTetrate Istio Distro 可以帮助我升级 Istio 吗？ 可以，Tetrate Istio Distro 可以帮助我升级 Istio。Tetrate Istio Distro 可以通过 getmesh 升级命令实现无缝升级。\n项目概述 你们是在创建 Istio 项目的分叉吗？ 不，我们不是在创建 Istio 项目的分叉。我们是在创建一个上游的发行版。我们对 Istio 的任何改进都会在上游进行。\nTetrate Istio Distro 是否会影响我的应用程序的性能，影响的方式是什么？ 不会。作为上游发行版，Tetrate Istio Distro 对 Istio 的性能没有影响。\n你们计划多长时间从上游 Istio 项目中为 Tetrate Istio Distro 添加一次新功能？ 一旦上游 Istio 有新版本，Tetrate Istio Distro 会尽快提供新版本的 Istio。\n我如何申请 Tetrate Istio Distro 的新功能？ 我们的路线图是公开的。请创建一个功能请求，并对路线图上的功能进行投票。\n我们可以为 Tetrate Istio Distro 的工作做贡献吗？ 是的，Tetrate Istio Distro 是开源的，并且采用 Apache 许可证。您可以对 Tetrate Istio Distro 的任何组件做出贡献。\n"},{"url":"https://istio.tetratelabs.io/zh/community/event/istio-big-talk-ep-05/","title":"《Istio 大咖说》第 5 期：腾讯云服务网格生产落地最佳实践","description":"本次直播将分享腾讯云服务网格生产落地最佳实践。","content":" 时间：6 月 30 日（星期三）晚 8 点 - 9 点 直播间：https://live.bilibili.com/23095515 主持人：宋净超（Tetrate） 嘉宾：钟华（腾讯云） 话题：腾讯云服务网格生产落地最佳实践 提问地址：腾讯文档 直播回放：Bilibili 幻灯片归档：GitHub  嘉宾简介 钟华，腾讯云高级工程师，Istio contributor，Dapr contributor, Tencent Cloud Mesh 技术负责人。专注于容器和服务网格，在容器化、服务网格生产落地和性能调优方面具有丰富经验。\n话题介绍  Istio 生产落地挑战 腾讯云服务网格全托管架构介绍 大规模服务网格性能优化 Istio 生产落地最佳实践  通过本次分享了解大规模场景下，Istio 性能调优和最佳实践，包括 xDS 懒加载，控制面负载平衡，控制面灰度升级，Ingress gateway 优化等。\n"},{"url":"https://istio.tetratelabs.io/zh/community/","title":"社区","description":"贡献社区","content":"您可以通过多种方式来贡献和参与社区：\n 开始为 Github 上的 GetIstio 项目做贡献。 加入并参与我们的某个活动。 加入 Tetrate Community Slack 上的 #GetMesh 频道。 在 Tetrate 学院 获得 Istio 认证。  "},{"url":"https://istio.tetratelabs.io/zh/istio-in-practice/install-skywalking/","title":"集成 Apache SkyWalking","description":"","content":"这是在您的环境中将 Istio 与Apache Skywalking集成的快速入门。\n有关详细步骤，请参阅 Apache Skywalking 网站上的博客文章。\n要突出基本的集成步骤：\n 根据文档安装 Tetrate Istio Distro 使用getmesh命令部署 Istio，并使用以下命令启用访问日志服务（ALS）：  getmesh istioctl install --set profile=demo \\  --set meshConfig.enableEnvoyAccessLogService=true \\  --set meshConfig.defaultConfig.envoyAccessLogService.address=skywalking-oap.istio-system:11800  使用标记应用程序命名空间  kubectl label namespace \u0026lt;namespace\u0026gt; istio-injection=enabled  根据博客文章部署 Apache SkyWalking 和应用程序 通过 SkyWalking WebUI 监视您的应用程序  "},{"url":"https://istio.tetratelabs.io/zh/community/event/istio-big-talk-ep-06/","title":"《Istio 大咖说》第 6 期：Envoy Proxy 在线答疑","description":"本次直播将分享腾讯云服务网格生产落地最佳实践。","content":" 时间：8 月 3 日（星期二）中午 12:30 - 2:00 直播间：https://live.bilibili.com/23095515 主持人：宋净超（Tetrate） 嘉宾：周礼赞（Tetrate） 话题：Envoy proxy 在线答疑 提问地址：腾讯文档 直播回放：Bilibili  嘉宾简介 周礼赞，Tetrate 工程师，Envoy 核心 maintainer。\n话题介绍 我们在过去两个月内已经陆续举办了 5 期《Istio 大咖说》，直播过程中很多观众反馈想要了解下 Envoy，有很多关于 Envoy 的问题却没有人可以来解答，而 Envoy 作为 Istio 中默认的数据平面，可以说如果你搞懂了 Envoy 就算把 Istio 搞懂 80%了。这次我们邀请了来自企业级服务网格提供商 Tetrate 公司的周礼赞，他是 Envoy 的核心 maintainer，之前也在云原生社区中分享过一次《云原生学院第 17 期：Envoy 调试流量的常用技巧》，他身处美国，因为时差的关系，我们选择在中午的时候直播答疑，大家要趁此机会，将心中的关于 Envoy 的疑问抛出来，记录在上面图片链接的腾讯文档里，我们将在北京时间下周二中午12 点半到 2 点为大家统一解答。\n"},{"url":"https://istio.tetratelabs.io/zh/download/","title":"下载","description":"下载列表。","content":"目前 GetMesh 可以运行在 Linux 和 MacOS 上，要部署 GetMesh，你只需要一个简单的命令：\ncurl -sL https://istio.tetratelabs.io/getmesh/install.sh | bash 请按照 Tetrate Istio Distro 安装和更新页面，了解下载和后续步骤的详细说明，以使 GetMesh 在您的机器上运行。\n支持的 Istio 版本 Tetrate Istio Distro 跟踪 Istio 上游版本。作为 GetMesh 构建管道的一部分，我们会运行一系列测试以确保 Istio 发行版在底层 Kubernetes 平台上运行良好。\nTetrate Istio Distro 认证的 Istio 发行版已经针对以下 Kubernetes 发行版进行了测试。\n EKS - 1.18, 1.17, 1.16 GKE - 1.18, 1.17, 1.16 AKS - 1.18, 1.17, 1.16  目前正在进行添加其他 Kubernetes 发行版和最新版本 Kubernetes 的工作。\n虽然 Istio 的核心功能已经在不同的 Kubernetes 发行版上进行了测试和认证，但建议用户认识到，Istio 的某些功能规定了最低的 Kubernetes 版本（例如，Kubernetes CSR API 签署 Istio 工作负载需要 Kubernetes 1.18+），而某些其他功能则需要设置特定的供应商配置（例如，启用 Istio CNI 插件）。\n你可以在本页找到其他下载的 Istio 发行版和 istioctl 二进制文件，适用于 Linux、MacOS 和 Windows。我们建议使用 GetIsio 来获取所需文件。\nGetMesh ensures that all Istio releases are supported for at least 14 months from release date.\nBelow is the summary of Istio releases, security patches and minor updates. Please make sure that the version you're running include the security updates available. Also please plan upgrades when your version is planned to be out of support.  Currently supported releases are 1.17, 1.16, 1.15, 1.14, 1.13, 1.12, 1.11 and 1.10. \n        1.13 is End Of Life by 2023-04-11 please consider migrating to supported version soon\nIstio 二进制下载 Linux Istio 发行版 以下是获取 Istio 和 istioctl 发行版的链接。\n Distribution type Istio version Release Notes Full Istio download URL Istioctl download URL   tetrate-v0   1.17.1   Release Notes 1.17.1   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.17.1   Release Notes 1.17.1   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     tetrate-v0   1.16.3   Release Notes 1.16.3   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.16.3   Release Notes 1.16.3   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     tetrate-v0   1.15.4   Release Notes 1.15.4   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.15.4   Release Notes 1.15.4   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     tetrate-v0   1.14.6   Release Notes 1.14.6   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.14.6   Release Notes 1.14.6   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     tetrate-v0   1.13.7   Release Notes 1.13.7   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.13.7   Release Notes 1.13.7   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     tetrate-v0   1.12.8   Release Notes 1.12.8   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.12.8   Release Notes 1.12.8   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     tetrate-v0   1.11.8   Release Notes 1.11.8   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.11.8   Release Notes 1.11.8   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     tetrate-v0   1.10.3   Release Notes 1.10.3   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7     istio-v0   1.10.3   Release Notes 1.10.3   Istio Distro\namd64 arm64 armv7   istioctl\namd64 arm64 armv7    MacOSS Istio 发行版 以下是获取 Istio 和 istioctl 发行版的链接。\n Distribution type Istio version Release Notes Full Istio download URL Istioctl download URL   tetrate-v0   1.17.1   Release Notes 1.17.1   Istio Distro   istioctl     istio-v0   1.17.1   Release Notes 1.17.1   Istio Distro   istioctl     tetrate-v0   1.16.3   Release Notes 1.16.3   Istio Distro   istioctl     istio-v0   1.16.3   Release Notes 1.16.3   Istio Distro   istioctl     tetrate-v0   1.15.4   Release Notes 1.15.4   Istio Distro   istioctl     istio-v0   1.15.4   Release Notes 1.15.4   Istio Distro   istioctl     tetrate-v0   1.14.6   Release Notes 1.14.6   Istio Distro   istioctl     istio-v0   1.14.6   Release Notes 1.14.6   Istio Distro   istioctl     tetrate-v0   1.13.7   Release Notes 1.13.7   Istio Distro   istioctl     istio-v0   1.13.7   Release Notes 1.13.7   Istio Distro   istioctl     tetrate-v0   1.12.8   Release Notes 1.12.8   Istio Distro   istioctl     istio-v0   1.12.8   Release Notes 1.12.8   Istio Distro   istioctl     tetrate-v0   1.11.8   Release Notes 1.11.8   Istio Distro   istioctl     istio-v0   1.11.8   Release Notes 1.11.8   Istio Distro   istioctl     tetrate-v0   1.10.3   Release Notes 1.10.3   Istio Distro   istioctl     istio-v0   1.10.3   Release Notes 1.10.3   Istio Distro   istioctl    Windows Istio 发行版 以下是获取 Istio 和 istioctl 发行版的链接。\n Distribution type Istio version Release Notes Full Istio download URL Istioctl download URL   tetrate-v0   1.17.1   Release Notes 1.17.1   Istio Distro   istioctl     istio-v0   1.17.1   Release Notes 1.17.1   Istio Distro   istioctl     tetrate-v0   1.16.3   Release Notes 1.16.3   Istio Distro   istioctl     istio-v0   1.16.3   Release Notes 1.16.3   Istio Distro   istioctl     tetrate-v0   1.15.4   Release Notes 1.15.4   Istio Distro   istioctl     istio-v0   1.15.4   Release Notes 1.15.4   Istio Distro   istioctl     tetrate-v0   1.14.6   Release Notes 1.14.6   Istio Distro   istioctl     istio-v0   1.14.6   Release Notes 1.14.6   Istio Distro   istioctl     tetrate-v0   1.13.7   Release Notes 1.13.7   Istio Distro   istioctl     istio-v0   1.13.7   Release Notes 1.13.7   Istio Distro   istioctl     tetrate-v0   1.12.8   Release Notes 1.12.8   Istio Distro   istioctl     istio-v0   1.12.8   Release Notes 1.12.8   Istio Distro   istioctl     tetrate-v0   1.11.8   Release Notes 1.11.8   Istio Distro   istioctl     istio-v0   1.11.8   Release Notes 1.11.8   Istio Distro   istioctl     tetrate-v0   1.10.3   Release Notes 1.10.3   Istio Distro   istioctl     istio-v0   1.10.3   Release Notes 1.10.3   Istio Distro   istioctl    "},{"url":"https://istio.tetratelabs.io/zh/community/event/istio-big-talk-ep-07/","title":"《Istio 大咖说》第 7 期：基于 Envoy/Istio 的云原生 API 网关 —— 开源项目 Hango 的设计与实现","description":"本次直播将分享基于 Envoy/Istio 的云原生 API 网关 Hango 的设计与实现。","content":" 分享时间：2021 年 8 月 25 日（周三）晚上 8:00 到 9:00 议题名称：基于 Envoy/Istio 的云原生 API 网关 —— 开源项目 Hango 的设计与实现 主持人：宋净超（Tetrate） 分享嘉宾：韩佳浩（网易轻舟） 直播间地址：https://live.bilibili.com/23095515 回放地址：https://www.bilibili.com/video/BV1YL411b7e6/ 提问地址：https://docs.qq.com/doc/DRUZSbHVkck9Wc0V4 PPT 下载：见 Istio 大咖说往期节目列表  讲师简介 韩佳浩，网易数帆资深研发工程师，主导 Hango 网关开源研发及设计，负责网易数帆轻舟 API 网关集团内部大规模落地及产品化建设。具有三年网关相关研发及大规模实践经验。\n话题介绍 云原生架构演进下，更多的业务着重于 API 的统一暴露，API 网关便成为 API 统一接入的必备组件。本次分享主要从云原生概念出发，探讨云原生模式下 API 网关的选型之道；介绍网易研发的高性能、可扩展，功能丰富的云原生 API 网关 Hango 的设计之道以及落地实践。\n问答   Envoy体系学习图谱，现在是整体文档都看完有用到时再翻文档\n答：可以关注社区动态，学习思路路线上可以根据自己想对 Envoy了解的程度按照以下线路进行：了解 Envoy 基本架构 -\u0026gt; 使用 Envoy 常用特性 -\u0026gt; 尝试扩展 envoy -\u0026gt; 对 Envoy 做深度定制，另外 Tetrate 即将推出免费的 Envoy 教程，敬请关注。\n  Hango项目与网易轻舟项目是什么关系？开源版么？\n答：网易轻舟项目包含轻舟微服务、轻舟API网关、轻舟容器等产品，轻舟API网关是Hango项目的商业版。\n  Ingress Controller与API Management是否有必要合为一个产品？ 就是 k8s 资源，意思两个产品位置是否需要合一？\n答：具体需要看网关的定位，如果作为微服务网关的话，不建议合为一个产品；如果承担ingress功能，可以合一。\n  使用 Envoy 以网关的形式和以 Sidecar 的形式做服务治理有什么区别，使用场景分别是什么呢？以网关的形式做东西南北向流量的服务治理的方案可行吗？\n答：网关主要做南北流量治理；Sidecar承担集群东西流量治理。在大规模场景下，不建议网关作为东西流量治理；服务调用关系简单，API规模有限可以。\n  Hango必须配合Istio一起使用吗？\n答：推荐使用Istio, 仅单独使用网关数据面丧失网关动态配置能力，自身静态配置复杂度也大大提高。\n  接问题5，如果是可以独立使用，在k8s内额外创建一个网关，这个网关目的是什么，这在集群内服务之间互访的时候等于破坏了Kubernetes本身的svc特性，consumer服务找这个网关所注册的服务？能否举例一个具体的场景。\n答：不推荐独立使用，网关的功能对外统一暴露集群内API。网关暴露的意义，一部分是代理，另一部分是丰富的治理功能以及多维度的指标监控。\n  加载 Lua后性能有下降吗？\n答：简单的插件，性能基本在20%损失。\n  边缘网关有哪些场景？看到ppt里有写，但是没有讲。\n答：类似集群中的统一API暴露，只是不需要额外的用户配置。\n  性能没太看懂，9wqps是几台机器？几c？\n答：容器：8c8g 物理机：56c256g\n  lua 怎么保证脚本安全？隔离性怎么样？写个while true 会不会把整个网关搞崩？\n答：lua的插件链的异常不会导致主线程crash，异常后跳过逻辑，执行之后的插件链。\n  大规模场景下，踩过哪些坑\n答：升级的平滑度以及线上规模的预估。\n  可以认为是在Istio gateway + virtualservice的一个升级版么？ 是不是用了这个网关我就可以不用Istio gateway了？\n答：是的\n  "},{"url":"https://istio.tetratelabs.io/zh/categories/","title":"Categories","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/categories/event/","title":"event","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/","title":"Tetrate Istio Distro | Simple, safe enterprise-grade Istio","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/tags/istio/","title":"Istio","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/tags/","title":"Tags","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/blog/tuya-istio-practice/","title":"涂鸦智能的 Istio 企业级生产环境的实践","description":"涂鸦智能前端团队的 Istio 实践。","content":"背景 Istio 作为当前最活跃的 service mesh 项目，提供着众多的能力，流量管理，安全性，可观察性，每一项能力都是服务治理，运维所必需的。Istio 丰富的能力同时也带来一定性的复杂系统运维的挑战，但是相对于能力以及未来的扩展性，Istio 能力给服务治理带来了无限的想象，机遇同时充满着挑战。\n当前涂鸦智能前端业务 Istio 控制面版本为 1.5.0，接入 Istio 控制面 700 + 服务，1100+pod 实例，承担涂鸦智能前端最大的业务集群的流量管控和能力支撑。\n涂鸦智能在开发流程上存在的问题 前端基础团队 2018 年开始接触 Kubernetes，并基于 kubernetes 自建了发布平台服务于前端业务团队，但随着业务团队越来越大，开发发布流程上开始出现一些问题：\n 多分支并行开发的验证问题 多地域环境带来的配置复杂性导致的线上问题  最开始考虑让业务团队自己内部调整处理，但由于出现问题的团队越来越多，我们开始考虑通过灰度发布能力来解决这些开发发布流程上的问题，在日常预发环境，多个分支发布多个灰度版本，根据不同的 header 分发流量到不同版本，保证每个 feature 分支有单独的实例进行验证，相互之间互不影响。在线上环境提供灰度能力给测试回归，作为项目质量的最后一道防线。\n我们调研了多个方案，也参考内部其他团队的灰度方案，基于实现复杂性和能力的丰富度考量，在 2020 年初，我们开始在生产环境部署了 Istio。虽然 Istio 的接入在一定程度上提高了系统的复杂性，但是它确实给我们带来了惊喜。\n引入 Istio 解决的问题 灰度发布 基于 Istio 原生自带的资源 VirtualService 和 DestinationRule 构建了发布平台的灰度发布能力。\n 发布平台发布的每个应用都打上两个 label canarytag 和 stage，stage 用于标识正常发布和灰度发布，canarytag 用来标识不同的灰度版本 每发布一个灰度版本，我们就会创建一个对应的灰度 ReplicaSet 实例 发布对应的 DestinationRule 配置通过 label canarytag，stage 把正常发布和不同版本灰度的实例定义为不同实例集合 通过 VirtualService 根据不同的 header 分发的不同实例集合  下图展示的是配置信息。\n流量观测和异常感知 我们基于社区原生的 prometheus-operator 搭建了我们的监控平台，每个集群都会单独部署一个 prometheus-operator，并根据采集的对象，划分为业务、Kubernetes 集群基础设施、Istio 数据面流量三个范围，并部署相应的业务 prometheus 实例：Kubernetes 集群基础设施监控 prometheus 实例和 Istio 流量监控 prometheus 实例。\n并通过 Grafana 搭建了整体的数据面流量监控大盘，实现了对流量的观测。\n并基于当前的监控数据，配置了对应的告警规则，对流量的异常和波动有手段去感知和发现，并及时处理。\nsum(envoy_cluster_upstream_cx_active{namespace!=\u0026#34;fe-pre\u0026#34;}) by (namespace, service) \u0026lt; 1 无可用服务告警 sum by(namespace, service) (rate(envoy_cluster_upstream_rq_503[1m])) \u0026gt; 0 503异常告警 sum by(namespace, service) (rate(envoy_cluster_upstream_rq{response_code_class!=\u0026#34;2xx\u0026#34;}[1m])) != 0 业务异常告警 现阶段的成果以及存在问题 当前线上最大的业务集群所有 pod 实例都已经接入至 Istio 控制面，由 Istio 把控整体的流量，具备流量观测能力。\n灰度发布数占发布总数的 60% 以上，越来越来的项目开始使用灰度发布能力，并覆盖了公司最大的两个业务线，灰度能力和稳定性得到了业务的认可和好评。\n但随着业务量的越来越大，pod 实例数的越来越多，也碰到了一些问题：\n 团队使用的 Istio 版本为 1.5.0，该版本在 pilot 推送大量 xds 更新时，会导致 envoy 的 readiness 探针检查失败，并再次导致 eds 的大量更新，导致集群波动，该问题社区已经解决，团队也规划升级至 1.7.7 版本解决。 Pilot 所在机器异常重启后，接入该 pilot 实例的 envoy 无法感知到服务端的异常，需要等待 tcp keepalive 超时并检查失败后才会开始重连至正常的 Istiod，在这段时间内，集群的更新都不会被同步，默认配置需要等待 975 秒，该问题可以通过配置 envoy 的引导配置解决，修改 envoy 默认引导配置 xds-grpc cluster upstream_connection_options 的 tcp_keepalive 配置，保证在 1 分钟内进行重连。  \u0026#34;upstream_connection_options\u0026#34;: { \u0026#34;tcp_keepalive\u0026#34;: { \u0026#34;keepalive_time\u0026#34;: 30, \u0026#34;keepalive_probes\u0026#34;: 3, \u0026#34;keepalive_interval\u0026#34;: 5 } } 未来展望 涂鸦前端基础团队在 2020 年初开始使用 Istio，对于 Istio 丰富的能力和强大的扩展性的使用还在探索阶段，对于未来，我们会着重往两个方向进行探索和挖掘：\n 基于当前 Istio 的能力，实现对流量的精细化管理以及服务的降级、熔断，当前对于前端微服务的治理能力缺失，遇上异常场景没有有效手段来保证服务的稳定性 基于 Istio 的故障注入能力提供故障 use case 并对业务进行注入，提高整体业务系统的容错性，稳定性  "},{"url":"https://istio.tetratelabs.io/zh/blog/ebay-istio-practice/","title":"eBay 基于 Istio 的统一流量管理实践","description":"eBay 的 Istio 使用实践分享。","content":"作者：孟凡杰，eBay 资深架构师，负责 Kubernetes 在企业落地过程中的架构和开发工作，专注于网络、多集群、服务治理和服务网格等方向。Kubernetes 社区贡献者，曾参与社区集群联邦的开发和服务控制器重构等工作。\nKubernetes 作为 eBay 的统一云平台，统管了在线业务、大数据、搜索后台等多种异构应用。集群数量高达上百，其中的大型集群中，单个集群运行数千个微服务，数十万 Pod。不同类型的应用，针对流量管控的需求也各有不同，如何用一套统一的模型将各种流量管控需求统一起来是 eBay 多年来一直面临的挑战。\n以云应用为例，为实现跨数据中心高可用的需求，生产应用的网络拓扑可以简要描述如下：\n eBay 采用多活数据中心的网络拓扑，因此任何生产应用都需要完成跨三个数据中心的部署。 为满足单集群的高可用，针对每个数据中心，任何应用都需进行多副本部署，并配置负载均衡。 以实现全站微服务化，但为保证高可用，服务之间的调用仍以南北流量为主。 针对核心应用，除集群本地负载均衡配置以外，还需配置跨数据中心负载均衡，并通过权重控制将 99% 的请求转入本地数据中心，将 1% 的流量转向跨地域的数据中心。该配置的主要目的是当某应用的所有本地服务实例失效时，运维可快速将跨数据中心负载均衡器上指向本地的 99% 流量的成员禁止掉，流量可在秒级转向其他数据中心从而保护业务不受影响。业务版本发布、硬件故障、防火墙、路由器等网络设备变更都有可能导致本地服务实例失效。  部署模式 eBay 有多个数据中心，每个数据中心包含多个有独立供电和制冷的可用区（Availability Zone），每个可用区部署多个 Kubernetes 集群。因每个可用区的网络延迟较小，因此我们当前以可用区为最小管理域搭建 Istio 控制面。在每个可用区内，选择一个 Kubernetes 集群作为网关集群，部署 Istio Primary，在同一可用区的其他集群安装 Istio Remote。在这样的配置下，同一可用区的多个集群内服务和服务之间的通信均转化为东西流量，跨可用区的通信需要经由 Istio 网关。\n此种 Istio 部署模式主要依托于 Kubernetes 的运营模式，我们将不同可用区的计算节点搭建了不同的 Kubernetes 集群。这样的配置可实现同一网格内的服务访问低延迟，并且使得服务网格的规模可用，并对故障域做了很好的管控。\n接入网关 作为互联网公司，流量管理中最重要的一环就是如何接收来自公网的用户请求。将集群外部客户端发起的请求转入集群内部，是流量管理需要解决的第一个问题。\n在纯软件架构下，负载均衡组件被划分为基于四层的负载均衡器和基于七层的 API 网关。四层负载均衡器负责提供服务的虚拟 IP 地址，接收客户请求，并将客户请求转入上游实例。七层 API 网关负责基于应用层协议的高级路由功能，比如 TLS 卸载，基于访问路径的跳转，HTTP 协议包头的修改等等。\n四层网关 四层网关的主要技术手段是通过网络地址转换（NAT) 或者隧道技术（Tunnel）等技术，将来自外部客户端发至虚拟 IP 地址的用户请求转发至集群内部。网络地址转换是最常用的方法，其优势是简单易用，排查问题简单。IP Tunnel 相较 NAT 技术配置更复杂，但是基于 IP Tunnel 技术通常能实现 DSR，既保留了原始 IP 地址，又能有比较高的数据转发效率，因此与 NAT 相比是更优的方案。\n在 Kubernetes 架构下，这些四层负载均衡器的控制面板可以定义为 Kubernetes Pod 以实现故障转移，扩缩容等高级功能。而基于 Linux 自带组件比如 IPVS，即可实现基于四层的数据包转发。\n四层网关的配置依赖于 Kubernetes Service Controller 完成以下配置：\n 虚拟 IP 地址分配，当用户创建 Service 对象以后，Service Controller 需要从预先配置的公网 IP 中选择一个可用的虚拟 IP 地址分配给该服务。 配置 IPVS 接口，完成负载均衡规则的配置。 路由宣告，虚拟 IP 地址与物理设备的 IP 不一样，它没有绑定在任何物理设备上，但基于 BGP 协议和 ECMP，它能让多个设备配置同一个 IP 地址的路由信息。当 Service Controller 为 Service 分配虚拟 IP 地址并配置好 IPVS 规则以后，Controller 还需要将该虚拟 IP 地址从配置好的节点中宣告出去。基于 BGP 协议，数据中心中的其他路由器即可获知如何将虚拟 IP 地址转发至该网关节点。有了 ECMP 的支持，多个四层负载均衡组件行为一致，也就是他们配置一样的规则，宣告一样的 IP，每个实例都会承载该虚拟 IP 地址的流量。相比主备模式的硬件负载均衡器，此方案的所有负载均衡节点都是 Active 模式，没有 Standby 设备的额外硬件开销。  每个节点的核心功能是负载均衡规则配置，包括以下特性：\nN 元组哈希\n基于源 IP，源端口，目标 IP，目标端口，以及协议的 N 元组哈希，保证针对同一个连接，总是选择同一个上游实例。路由器的 ECMP 哈希算法与设备相关，同样的 N 元组有可能会被转发至多个目标，在本场景中是四层负载均衡。只要在 IPVS 主机上按照 N 元组重新做哈希，那么无论请求被转发至哪个 IPVS 实例，都会被转发至相同的上游服务器。所有实例计算的的哈希结果都一致，这样多个 IPVS 实例之间不用同步状态。当一个节点出现故障时，其他节点可将请求转发至同一个上游。\n一致性哈希\n基于 N 元组的哈希算法，会尽量将请求平分到多个上游服务器，在 Kubernetes 世界里，上游服务器以 Pod 的形式存在，扩缩容，Failover 是常见场景。在普通哈希算法中，目标的变动意味着大量的 rehash，采用一致性哈希算法后，只需要将变动的部分重新哈希即可，减少了大量哈希计算的 CPU 开销。\nConnection Tracking\nConnection Tracking 表用来记录最近连接的后端选择结果，当 IPVS 模块处理数据进行负载均衡操作时，首先查询该连接表，如果发现对应的 N 元组已经有了对应的目标实例且该实例依然健康，那么直接复用此结果。如果不存在或者对应的实例状态不正常则需要基于一致性哈希重新计算，计算结果会被保存在该连接表中供后面的请求数据复用。\n数据包封包\n选择好对应的上游服务器以后，IPVS 模块开始处理数据包。按照第五章的内容，内核协议栈在处理数据包是，可以基于 NAT 或者 Tunnel 两种模式，NAT 的问题是用户原始 IP 会丢失，这里选取更优的 Tunnel 模式，IPVS 模块会保持原始数据包不变，在原始数据包外面封装一层 IP 包头，数据包的内层包头源是客户端 IP，目标是服务虚拟 IP 地址，外层包头源是 IPVS PodIP，目标是上游服务器 PodIP，然后基于 IP over IP 协议发送数据给上游。\n健康检查\n健康检查是负载均衡的基本功能，在我们打造的软件负载均衡中也需要。Seasaw 库有 API 支持多种健康检查模式，只需在控制器中调用接口对所有上游目标做健康检查，如果某个上游服务器检查失败，需要将 IPVS 中对应的转发规则删除掉。\n基于软件的四层负载均衡有多重实现方式，基于操作系统自带的 IPVS 模块是最直接，成本最低的方案。当然 IPVS 在处理数据的过程中需要依赖操作系统协议栈，转发效率并非最高。如果需要更大的流量处理能力，有很多数据平面加速技术可用，比如 DPDK 和 XDP。\n七层应用网关 Istio 提供 Ingress Gateway，配合四层负载均衡，即可实现全站的入站流量高可用接入方案。\n作为四层负载均衡的转发目标，七层 API 网关需要配合完成隧道技术的配置。因为四层负载均衡基于 IP Tunnel 配置转发规则，当它转发数据时，是以 IP Over IP 协议发送的数据包，作为目标，Envoy Pod 在接收到请求以后，需要将 IPIP 包拆解。这需要在 Enovy Pod 中创建类型为 IPIP 的设备并绑定虚拟 IP 地址。\n微服务架构网站的主站通常是数十到数百上甚至千个微服务的集合，不同微服务以不同访问路径注册在同一主域名下。同时 API 网关会有一些通用的访问控制策略，比如外网 IP 不能访问以 /admin 结尾的路径等，这些访问控制在 Istio 有很好的支持。\nEnvoy 接收到请求后，会按照既定的七层转发规则将请求转发至对应的目标，对于边缘网关来说，这些目标通常是处于云端的服务虚拟 IP 地址。Envoy 在接受到云端处理结果以后，需要将该请求转发回给客户端，因为该请求抵达 Envoy Pod 时是 IPIP 包，在操作系统卸载了外层包头以后，内层数据包包头是客户端 IP 和服务虚拟 IP 地址，Envoy 在回包时，只需将源目标地址翻转再发送数据，该响应包即可走默认网关绕过 IPVS 而直接发送至客户端，此模式为大家熟知的 DSR 模式。\n流量管理 协议升级 针对接入 Istio 的应用默认启用 mTLS，这样如果是东西流量，则服务和服务之间的通信天然加密，站内流量的安全等级得到了提升。\n应对规模化挑战 Istio 的强大之处在于，通过一套模型将东西和南北流量统一管控，针对东西流量，无太多需要定制化的功能。我们生产化过程中主要的工作是持续集成和持续发布 Pipeline 的构建，以及大量的性能测试工作，并且基于规模性测试和性能测试结果，定义 Istio 运维模型。其中针对超大集群，Istio 则面对比较多的挑战。\nIstiod 默认发现集群中所有的服务，并且每个服务的每个端口构建一个 Envoy Cluster，若模式开启了 sni-dnat 模式，则 Istiod 还构建一份符合域名规范的 Envoy Cluster。针对服务数量较多的超大规模集群，Envoy 配置会变的超大。在早期版本中，我们经历了很多 8000 多个服务导致 Istiod 生成的配置超出 Envoy 能承受的上限而引发的接入网关完全不可用的故障。\nIstio 在后续的版本中，为 Istio 对象增加了 ExportTo 属性，以实现可见性控制。通过将接入的服务只 export 给需要的微服务，可控制 Envoy 的配置规模，降低 Envoy 的 footprint，并提升推送效率。\n虽然通过 ExportTo 可精简 Envoy 的配置，但是 Istio 控制面板依然会将集群内的所有服务都发现出来。针对超大规模集群，Istiod 依然面临因为需要监控和处理的对象过多而导致的资源占用过大，处理效率过低的问题。社区 1.9 版本在推动 Istiod 基于 Namespace Labels 过滤监控对象的功能，这个功能有利于解决超大集群规模下，Istiod 控制面板本身的规模和性能问题。\n接入网关证书自动化 Istio 基于 Envoy 的发现机制 SDS 实现了网站域名的证书管理，但是它要求管理员预先将证书放入 Istio 根 Namespace，并且在创建 Istio Gateway 对象时，通过定义 credentialName 来引用预先定义的证书信息。这适用于同一 Kubernetes 集群只提供一个域名的场景，但针对域名动态创建的场景，这种半自动的运维模式显然是不可能的。需要实现自定义的 SDS 以完成与企业证书签发中心的对接，其方案可简单理解为，通过自定义控制器监控 Istio Gateway 对象中的 hosts 属性完成证书的自动签发，并且通过 SDS 将证书推送给 Envoy。\n接入域名自动化 同一应用网关可实现多个拥有不同域名的应用接入，针对不同域名的应用，需要完成域名配置的自动化。为实现该目标，定义了 NameService 对象，允许用户定义 FQDN，TTL，不同 DNS Provider，目标服务等等。在目标服务完成配置以后，域名配置可自动完成。\n管理模型抽象和高级流量管控 Istio 的模型抽象非常灵活，通过 Istio 对象可为应用定义不同网络拓扑。但同时面临诸多挑战：\n 针对数十个可用区，上百个 Kubernetes 集群，让用户面向每个集群做配置不现实。这样做的结果是管理混乱，客户需要关心太多基础架构细节，计算资源调控难度大，配置不统一，变更造成的故障可能性高。 Istio 对象无状态属性，很难直观获取配置是否正确、是否已推送完成等信息。 多路径软件接入网关的健康检查机制。  Kubernetes 通过集群联邦实现多集群的管理，我们基于集群联邦实现了一套 Federated AccessPoint，其核心是将 Kubernetes 中描述负载均衡的 Service 对象和 Istio 中描述网络流量的 Gateway、VirtualService、DestinationRule、ServiceEntry、WorkloadEntry 等对象定义为模板，将 AvailabilityZone 或者 Kubernetes Cluster 作为部署目标，并且支持 Override 属性的集群联邦对象。\n针对此流量模型，提供丰富的策略控制，包括：\n PlacementPolicy 控制，用户可以选择目标集群来完成流量配置，甚至可以选择关联的 FederatedDeployment 对象，使得 AccessPoint 自动发现目标集群并完成配置。 完成了状态上报，包括网关虚拟 IP 地址，网关 FQDN，证书安装状态以及版本信息，路由策略是否配置完成等。这补齐了 Istio 自身的短板，使得任何部署在 Istio 的应用的网络配置状态一目了然。 发布策略控制，针对多集群的配置，可实现单集群的灰度发布，并且能够自动暂停发布，管理员验证单个集群的变更正确以后，再继续发布。通过此机制，避免因为全局流量变更产生的故障。 不同域名的 AccessPoint 可拥有不同的四层网关虚拟 IP 地址，以实现基于 IP 地址的四层网络隔离。 基于跨地域的流量管控，Istio 实现了基于 workload locality 的故障转移策略和权重策略管理，基于这些策略可实现跨地域的高可用流量管理。  Istio 面临的机遇和挑战 Istio 优势明显，它尝试将南北流量和东西流量作为一个统一命题管理起来，这使得基于同一套技术栈，将微服务架构从 API 网关演进到服务网格成为可能，其诸多特性使得 Istio 成为社区最活跃的开源服务网格项目。\n 可移植性，不仅支持 Kubernetes，也支持虚拟平台 OpenStack 以及 Consul。 跨语种的服务网格平台，统一 Java，Scala，Nodejs 等诸多语言。 Istio 将南北和东西流量统一管理，统一服务网格和 API 网关用户体验，降低运营成本。 天然安全，自动化证书管理，认证授权的集成。 充分的功能支持，能看到的 API 网关的所有功能都有支持。 背后有强大的社区支持，谷歌将 Istio 作为下一代微服务治理平台，IBM，微软，华为，阿里等云计算巨头都积极参与 Istio 项目的推进和生产化。  同时作为新兴项目，用来管理分布式系统中最复杂的流量管理，Istio 同样面临众多挑战：\n 规模和效率。Kubernetes 支持的集群规模越来越大，几千个计算节点，数十万 Pod，数千上万 Service 的生产集群越来越常见。Istio 在支持大规模集群场景还有很多挑战，代码需要做诸多优化。Istio 的多集群部署甚至还会让量级翻数倍，如何支持超大规模集群，是 Istio 面临的最大挑战之一。 复杂性，无论从控制平面复杂性还是模型抽象看，Istio 都是一个复杂系统，更多的功能模块意味着运维的复杂度更高。 与企业已存服务的整合，Istio 生产化需要与企业现有服务的整合，比如与企业 CA 的整合，与企业 Tracing 系统的整合，与企业监控平台的整合等等。 存量业务的迁移，很多企业已经有基于 SpringCloud 等开源框架的微服务系统，此系统已经支持了诸多熔断限流，API 网关等功能，与 Istio 提供的功能重复。是否要将这些存量业务迁移到 Istio，如何迁移都是巨大挑战。  尽管如此，Istio 有社区的强大支持，有诸多巨头公司和大项目的背书，它能补充 Kubernetes 在流量管理层面的功能缺失，使其成为一个完整的微服务治理平台。总之，Istio 未来可期。\n我们把更多基于 Kubernetes 和 Istio 的生产实践经验，写进了《Kubernetes 生产化实践之路》这本书里，目前京东正在五折热销。\n"},{"url":"https://istio.tetratelabs.io/zh/blog/coohom-istio-practice/","title":"酷家乐如何使用 Istio 解决新服务治理系统（Serverless）接入已有成熟自研 Java 服务治理体系","description":"酷家乐的 Istio 使用实践分享。","content":"本文来自酷家乐先进技术工程团队，作者罗宁，酷家乐资深开发工程师。\n公司背景 酷家乐公司以分布式并行计算和多媒体数据挖掘为技术核心，推出的家居云设计平台，致力于云渲染、云设计、BIM、VR、AR、AI 等技术的研发，实现“所见即所得”体验，5分钟生成装修方案，10秒生成效果图，一键生成 VR 方案的 SAAS 云端软件服务平台。\n核心问题 公司快速增长的业务需求，使得支持各开发语言的 Serverless 设施在国内外六个 Kubernetes 集群上线落地，但公司现状已有一套成熟的自研 Java 服务服务治理系统，承载了部署在 Kubernetes / KVM 平台的上千服务。这两者的服务治理体系完全不同，如何打通之间的调用顺利落地 Serverless 平台为产品功能研发增加效能呢？\n策略制定 酷家乐使用的成熟开源 Serverless 设施是依赖于 Istio 服务网格的 Knative，在 Kubernetes 集群中 Istio 提供的灵活又强大的动态路由/流量管理功能，配上一些相关的网关设施，不仅可以巧妙的解决不同体系服务相互调用的问题，且依旧保持了在酷家乐目前治理体系下的灵活可用。\n结果收获 使用 Istio 服务网格设施，将 Serverless 平台服务在测试/预发/生产多个环境下无缝接入到公司自研服务治理体系中，使用 Java 服务的成熟业务无需发生架构变动，而新兴业务在 Serverless 平台上，数百服务借助 NodeJS/Python/C++/Golang 等语言能力，及 Serverless 快速发布，天生弹性等特性为数十业务组提供高效产能。\n在成熟又复杂的服务治理平台上，引入新兴技术平台 酷家乐公司在后端服务上经过多年的经验积淀，公司内已有一套以 Dubbo 为基石并根据公司业务需求大幅改造过的，能够兼容 Kubernetes 和 KVM 混合部署方式的成熟 Java 微服务治理框架。但酷家乐作为一家大中型创新型创业公司，各部门新业务新产品大量涌现，业务所依赖的技术框架语言需求层出不穷（设计展示类产品需求和浏览器端一体的 NodeJS 服务，云端渲染及科研部门需求的 Python，C++等），此时通过嵌入 JAR 包这种语言相关的方式做服务治理满足业务需求已经力有不逮。\n酷家乐2017年开始使用自建/托管 Kubernetes 集群作为生产级别容器编排设施，具有成熟的升级维护和问题解决经验，而 Istio 服务网格在 Kubernetes 平台上通过 sidecar 方式注入与语言彻底解偶的服务治理方案，正是目前阶段最合适的异构（多开发语言框架）的解决方案。下文讲述我们如何将数以百计的 Serverless 服务通过 Istio VirtualService 作为桥梁打通和已有 Java 微服务之间的沟通调用。\nServerless 通过 Istio VirtualService 作为桥梁打通和已有微服务间沟通的 KFaas（Kujiale Faas）方案 下图是酷家乐国内集群 serverless 云函数架构。\n在酷家乐，来自主站 www.kujiale.com 的流量都必须统一经过已有服务治理体系下的 Java 网关服务site-gateway进行 JWT 鉴权，过滤以及按规则转发到对应集群中的服务上。在当前治理体系下的能够接受流量转发的服务只能是 Java 服务， 因对应环境下 Serverless 服务都只部署在同一个 Kubernetes 集群中，我们将匹配 /faas/api/ 规则的 HTTP 请求用该 Java 服务进行订阅，并借助 SpringCloud zuul 将流量直接转发到 Istio 集群内网关服务上（cluster-local-gateway，与 Istio-ingress-gateway 同配置，区别是只接受来自内网的流量，并且可以根据负载情况动态扩容），并与 Serverless 服务部署在同一集群中，这样我们解决了 Serverless 服务被已有治理体系调用的问题。\n如下是一个展示平台业务案例，这个业务服务分别部署在集群中分别由两部分组成。\n第一部分\n部署在 Kubernetes 集群 faas-alpha namespace 的 Knative service，在集群内的访问方式与普通的 Kubernetes service 并无区别，即 http://saas-showroom.faas-alpha.svc.cluster.local\n第二部分\n部署在 Kubernetes 集群 kfaas-system namespace 下的 Istio VirtualService，其具体的路由规则如下所示。\napiVersion: networking.Istio.io/v1alpha3 kind: VirtualService metadata: name: faas-alpha-ns-saas-showroom-ksvc-virtualservice namespace: kfaas-system spec: gateways: - knative-serving/cluster-local-gateway - knative-serving/knative-ingress-gateway hosts: - faas-alpha-ksvc-gateway.kfaas-system.svc.cluster.local http: - match: - uri: prefix: /faas/api/saas/showroom/ rewrite: authority: saas-showroom.faas-alpha.svc.cluster.local route: - destination: host: cluster-local-gateway.Istio-system.svc.cluster.local weight: 100  HTTP path 前缀匹配 /faas/api/p/saas/virtual-showroom/ （目前我们采用了 prefix 和 exact 两种方式，后续 regex 匹配功能也会在可避免路由冲突的情况下进一步开放出来） HTTP host 必须是 faas-alpha-ksvc-gateway.kfaas-system.svc.cluster.local （该 Kubernetes service 是 cluster-local-gateway 的 external-service，在非生产环境通过多个 external-service 多个测试环境共用一个 istio-system 下的 cluster-local-gateway 服务） 流量转发目标服务 saas-showroom.faas-alpha.svc.cluster.local 可加入重试，延时等规则提升在网格请求转发的鲁棒性 通过 weight 设置的百分比，后续我们会用来解决蓝绿发布流量管理的能力  Serverless 服务调用已有 Java 微服务治理体系服务 这里我们通过另一个 Java 出口网关服务解决，因为转发订阅规则都是已有服务治理体系内的方案，这里就无需再描述了。实际上 Serverless 通过入口和出口网关的方式接入另一个微服务治理体系的做法叫做东西向网关的方式，不同治理体系下虽然规则，用法及格式都不同，通过两边都能相互兼容的网关服务打通相互的调用是业界常用的做法，在酷家乐一些新收购的子公司/部门业务也通过这样的方式进行兼容。\nKFaas 技术方案与 Istio / knative 间的版本解偶 2018年我们在 Istio 尚未发布1.0正式版本前，在测试环境已经开始尝试。随着版本1.0 开始，我们在生产环境逐步迭代了 1.0.6 -\u0026gt; 1.1.7 -\u0026gt; 1.4.6 -\u0026gt; 1.5.4 （部分集群），包括 Knative 0.8 -\u0026gt; 0.9 -\u0026gt; 0.14 -\u0026gt; 0.15。在此过程中我们认为 Istio/knative 这些设施版本更迭已经成为一种常态， 我们初期的一些做法比如将业务相关的配置写入 istio-system namespace 中，在某些不兼容版本更新时就等于埋下了地雷。为此，我们专门设计了一个既依赖 Istio / knative 设施又与其固定版本解偶的 Kfaas 方案。\n在 kfaas-system namespace 内包含：\n Serverless 入口出口的东西向网关服务，并可根据负载进行弹性伸缩 Serverless 动态路由配置的 VirtualService 特定的业务相关或内网独立使用的域名证书 ingress 配置  酷家乐服务业务使用 Istio VirtualService 量级 测试环境当下业务量级下，截止2020年末 VirtualService 已达 700+。\n服务网格技术在酷家乐的未来展望 在酷家乐的实践中，我们使用 Istio 服务网格方案打通了不同服务治理下的服务集，取得了快速推进落地 Serverless 设施的成果。公司几十条业务线因为有了这套更为高效的生产力工具，产品和研发团队相比之前在同等时间内现在可以取得更多的业务成果，我们作为一家 SaaS 服务企业，是云原生赋能软件产业的典型案例。\n随着公司多元化业务产品线在 2021 年进一步推进，多语言框架的异构服务，更细粒度的服务治理 等需求势不可挡，业务需求对基础设施的要求进一步攀升，这套以 Kubernetes/Istio 为代表的云原生技术必将给酷家乐创造更加广泛的价值。\n"},{"url":"https://istio.tetratelabs.io/zh/tags/announcements/","title":"announcements","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/blog/whats-new-istio-1-9/","title":"Istio 1.9 有哪些更新？","description":"2月9日，Istio 宣布发布Istio 1.9版本。在这个版本中，我们可以看到虚拟机更广泛地被采用到服务网格中，而且对虚拟机的支持、对虚拟机的 cert 发放、对工作负载入口的健康检查也更加完善。","content":"2 月 9 日，Istio 宣布发布 Istio 1.9 版本。在这个版本中，我们可以看到虚拟机更广泛地被采用到服务服务网格中，而且对虚拟机的支持、对虚拟机的 cert 发放、对工作负载入口的健康检查也更加完善。Istio 最新的 1.7 和 1.8 两个版本，在让 VM 成为服务网格中一流的工作负载方面取得了很多进展，而 cert 发放则是最后需要弥补的缺口。\n服务网格中的虚拟机集成 虚拟机集成是 Istio 的核心功能之一，在这个版本中，它升级到了测试版，这意味着它可以用于生产，不再是玩具。\n在 Istio 服务网格中运行 Kubernetes 工作负载已经有一段时间了，在过去的几个 Istio 版本中，运行虚拟机工作负载也是如此。最新发布的 Istio 使得在服务服务网格中混合 Kubernetes 和 VM 工作负载更加容易。\n常见的用例包括在数据中心的虚拟机或云环境中的虚拟机上运行应用程序。这些虚拟机要么运行传统的，要么运行第三方应用 / 服务。其中一些应用 / 服务不会在短时间内消失–或者在某些情况下，永远不会消失！其中一些虚拟机工作负载是应用现代化历程的一部分，包括转向微服务或 RESTful 服务，部署为分布式服务，其中一些在容器中运行。在这个应用现代化历程中，其中一些虚拟机运行单体工作负载，直到它们被分解为微服务：在虚拟机中运行这些应用提供了一条通往目标 RESTful 服务或 API 的路径，并使过渡更加平稳。\n通过这样的渐进式方法，您可以开始将运行在虚拟机中的现有应用程序上岗到服务网格中。然后，随着你建立起你的服务服务网格实践，你可以逐渐将这些单体应用分解为服务，并更轻松地将它们部署在多个集群、云和混合环境中。Istio 可以使用 WorkloadEntry、WorkloadSelector 和 WorkloadGroup 来帮助您实现这一点，管理服务网格中的虚拟机，以促进您的应用现代化历程中更有保障的过渡。\n与 Kubernetes Service API 保持一致 通过 Kubernetes 服务 API，基础设施提供商和平台运营商可以为不同的目的设置多个 Controller。因此，它将 Gateway 与 Envoy 解耦，方便了 Istio 中不同反向代理后端的使用。\nIstio 从 1.6 版本开始就积极与 Kubernetes SIG-NETWORK 组合作，使用 Kubernetes Service API 来替代现有的 Gateway 声明，并将服务网格中的服务对外暴露。以前，你需要创建一个 VirtualService 来绑定到 Gateway 上，以便将服务暴露在服务网格之外。现在，您可以使用 GatewayClass、Gateway 和 Route。GatewayClass 定义了一组共享共同配置和行为的 Gateways。这类似于 IngressClass 的 Ingress 和 StorageClass 的 PersistentVolumes。Route 类似于 VirtualService 中的 Route 配置。你可以参考 Istio 文档来尝试这个功能，但要注意这个功能还处于实验阶段。\n总结 Istio 1.9 让每个功能的状态更加清晰，这也有助于增强用户使用的信心。经过最近几次大的改动，相信 Istio 的 API 会在进一步的发展中变得更加稳定。\n将服务服务网格扩展到虚拟机，一直是 Tetrate 成立的重要使命之一。Tetrate 提供 Istio 支持，以及为多集群、多租户和多云构建的基于 Istio 的优质服务网状管理平台。\n资源  Istio 1.9 版本：https://istio.io/latest/news/releases/1.9.x/announcing-1.9/ Tetrate Service Bridge：https:/tetrate.io/tetrate-service-bridge GetIstio，Tetrate 测试过的开源 Istio 发行版：https://getistio.io 联系 Tetrate 了解更多信息  "},{"url":"https://istio.tetratelabs.io/zh/tags/getistio/","title":"getistio","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/blog/launching-getistio/","title":"Tetrate Istio Distro 简介：获取 Istio 最简单的方法","description":"GetMesh是一个集成和生命周期管理 CLI 工具，可以确保使用支持和审核的 Istio 版本。","content":"Istio 是云原生世界中最受欢迎、发展最迅速的开源项目之一；虽然这种增长充分说明了用户从 Istio 中获得的价值，但其快速的发布节奏对于用户来说也是一种挑战，因为他们可能要同时管理多个不同版本的 Istio 集群，并为云平台手动配置 CA 证书。\n概述 我们今天推出了一个名为 GetMesh的新开源项目，为用户提供了安装和升级 Istio 的最简单方法。GetMesh提供了一个经过审核的 Istio 上游发行版–Istio 的强化镜像，并提供持续的支持，安装、管理和升级更加简单。它将与云原生和流行的 on-prem 证书管理器（如 AWS ACM、Venafi 等）进行整合。此次发布的内容包括：\n GetMeshCLI，最简单的方式来安装，操作和升级 Istio。GetMesh提供了一个安全的、经过审核的、上游的 Istio 发行版，经过 AKS、EKS 和 GKE 的测试。 免费的 Istio 基础在线课程，现在可以在 Tetrate 学院获得。 一个新的社区，汇集了 Istio 和 Envoy 用户和技术合作伙伴。  GetMeshCLI GetMesh是一个集成和生命周期管理 CLI 工具，可确保使用支持和审核的 Istio 版本。企业需要能够控制 Istio 的版本，支持 Istio 的多个版本，在版本之间轻松移动，与云提供商的认证系统集成，并集中配置管理和验证。GetIsio CLI 工具支持这些企业级需求，因为它：\n 强制获取 Istio 的认证版本，并且只允许安装 Istio 的兼容版本。 允许在多个 istioctl 版本之间无缝切换。 包括符合 FIPS 标准的版本。 通过整合多个来源的验证库，提供 Istio 配置验证平台。 使用多个云提供商证书管理系统来创建用于签署服务网格管理工作负载的 Istio CA 证书，以及提供与云提供商的多个附加集成点。  快速开始 下面的命令获得一个 shell 脚本，下载并安装与脚本检测到的操作系统发行版相对应的 GetMesh二进制文件（目前支持 macOS 和 Linux）。此外，还下载了最新支持的 Istio 版本。此外，该脚本还将 GetMesh的位置添加到 PATH 变量中（需要重新登录以获得 PATH 填充）。\ncurl -sL https://istio.tetratelabs.io/getmesh/install.sh | bash 下面的视频展示了 GetMesh命令行工具的基本使用方法。\n 参与进来 作为 GetMesh的一部分，我们还为 Istio、Envoy 和服务网格的开发者、最终用户和技术合作伙伴推出了一个新的社区。社区对所有人开放。GetIstio.io 网站还包括使用 Istio 的实用教程。\n如果您想将学习提升到一个新的水平，我们还准备了一个免费的 Istio 基础知识课程，作为 Tetrate Academy 的一部分。这是一门自学课程，有 8 个模块，包括理论课程，我们在其中解释理论和概念，实践课程，包括实验室和测验，以便您可以检查您的知识。加入我们的周会，提交问题，或者在 Slack 中提问。任何贡献都不会太小，你的意见和贡献很重要！\nGetMesh订阅 Tetrate 为 GetMesh提供商业支持，可直接与 Istio 专家联系，优先修复错误并提供 7x24 支持。更多详情请点击这里。\n相关链接  func-e：func-e.io GitHub：https://github.com/tetratelabs/getistio 加入 Istio Slack 并搜索 GetMesh频道与我们联系。 获得 “Istio 基础知识 “认证：https://academy.tetrate.io 获取 Istio 订阅：https://www.tetrate.io/getistio  "},{"url":"https://istio.tetratelabs.io/zh/tags/security/","title":"security","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/blog/external-ca-integration-with-cert-manager-using-istio-csr/","title":"使用 istio-csr 将外部 CA 与证书管理器集成","description":"这篇博客将展示如何使用 istio-csr 扩展将 cert-manager 作为外部 CA 集成到你的 Istio 服务网格。 ","content":"在本文中，我将展示如何使用 istio-csr 扩展将 cert-manager 作为外部 CA 集成到 Istio 服务网格中。\n背景 对于密钥和证书管理，Istio 在 istiod 控制平面内使用其自己的证书颁发机构（CA）。\n在这里，我们将使用 cert-manager 设置的 Issuer 作为外部 CA，使用 Istio CSR API 签署工作负载证书，并将 CSR 请求直接从工作负载传递到外部 CA。\n搭建环境 我们使用 Kubernetes 1.18 和 Istio 1.8 进行了此演示：\n  使用 minikube 部署 Kubernetes 集群（\u0026gt; = 1.16）。\nminikube start --memory=10000 --cpus=4 --kubernetes-version=1.18.6   安装 helm3 以进行证书管理器 CRD 安装。\ncurl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | sh   安装 GetIstio 并获取 Istio。\ncurl -sL https://istio.tetratelabs.io/getmesh/install.sh | sh getmesh fetch   部署证书管理器 在 cert-manager 名称空间中安装 cert-manager。\nkubectl create namespace cert-manager helm repo add jetstack https://charts.jetstack.io helm repo update helm install \\  cert-manager jetstack/cert-manager \\  --namespace cert-manager \\  --version v1.1.0 \\  --set installCRDs=true 配置证书管理者颁发者 虽然我们可以使用 cert-manager 连接多个发行商，但在本示例中，我们将配置 cert-manager 创建一个自签名 CA 来颁发工作负载证书。该 istio-ca secret 将持有 CA 密钥 / 证书对。\napiVersion: cert-manager.io/v1 kind: Issuer metadata: name: selfsigned spec: selfSigned: {} --- apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: istio-ca spec: isCA: true duration: 2160h # 90d secretName: istio-ca commonName: istio-ca subject: organizations: - cluster.local - cert-manager issuerRef: name: selfsigned kind: Issuer group: cert-manager.io --- apiVersion: cert-manager.io/v1 kind: Issuer metadata: name: istio-ca spec: ca: secretName: istio-ca kubectl create ns istio-system kubectl apply -f https://raw.githubusercontent.com/cert-manager/istio-csr/master/hack/demo/cert-manager-bootstrap-resources.yaml -n istio-system 部署 istio-csr 代理以进行证书管理 istio-csr 通过官方 helm chart 进行部署。它将使用名为的证书 istio-ca 来生成 istio-ca 工作负载证书和验证的 secret。\nhelm repo add https://chart.jetstack.io helm repo update helm install -n cert-manager cert-manager-istio-csr jetstack/cert-manager-istio-csr 该代理还创建一个 secret istod-tls，该 secret 持有 tls 证书/密钥，以便 istiod 服务 XDS。此新创建的证书由 istio-ca 签署。\n安装和配置 Istio 初始化 Istio operator。\ngetmesh istioctl operator init 在 operator yaml 中配置：\n 配置工作负载的外部 CA 地址 禁用 isidod 作为 CA 服务器 提供来自 cert-manager 的 istiod 的 TLS 证书  apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata: namespace: istio-system name: istio-operator-csr spec: profile: \u0026#34;demo\u0026#34; hub: containers.istio.tetratelabs.com values: global: # 将 istio 代理的证书提供者改为 cert-manager。 caAddress: cert-manager-istio-csr.cert-manager.svc:443 components: pilot: k8s: env: # 禁用 istiod CA Sever 功能。 - name: ENABLE_CA_SERVER value: \u0026#34;false\u0026#34; overlays: - apiVersion: apps/v1 kind: Deployment name: istiod patches: # 使用 secret 挂载 Istio 服务和 webhook 证书。 - path: spec.template.spec.containers.[name:discovery].args[7] value: \u0026#34;--tlsCertFile=/etc/cert-manager/tls/tls.crt\u0026#34; - path: spec.template.spec.containers.[name:discovery].args[8] value: \u0026#34;--tlsKeyFile=/etc/cert-manager/tls/tls.key\u0026#34; - path: spec.template.spec.containers.[name:discovery].args[9] value: \u0026#34;--caCertFile=/etc/cert-manager/ca/root-cert.pem\u0026#34; - path: spec.template.spec.containers.[name:discovery].volumeMounts[6] value: name: cert-manager mountPath: \u0026#34;/etc/cert-manager/tls\u0026#34; readOnly: true - path: spec.template.spec.containers.[name:discovery].volumeMounts[7] value: name: ca-root-cert mountPath: \u0026#34;/etc/cert-manager/ca\u0026#34; readOnly: true - path: spec.template.spec.volumes[6] value: name: cert-manager secret: secretName: istiod-tls - path: spec.template.spec.volumes[7] value: name: ca-root-cert configMap: secretName: istiod-tls defaultMode: 420 name: istio-ca-root-cert 您可以通过以下命令对 istio-system 命名空间的所有 cert-manager 证书进行验证。\nkubectl get certificates -n istio-system NAME READY SECRET AGE istio-ca True istio-ca 16m istiod True istiod-tls 16m 部署应用 这里我们部署了一个简单的证书验证工作负载。\nkubectl create ns foo kubectl label ns foo istio-injection=enabled kubectl apply -f samples/sleep/sleep.yaml -n foo kubectl get pods -n foo NAME READY STATUS RESTARTS AGE sleep-8f795f47d-vv6hx 2/2 Running 0 42s 验证为工作负载发出的 mTLS 证书 工作负载运行后，我们可以使用 istioctl proxy-config 命令检查 SDS 中的 secret。\ngetmesh istioctl pc secret sleep-8f795f47d-vv6hx.foo -o json \u0026gt; proxy_secret 检查一下 proxy_secret。应该有一个名为 ROOTCA 的字段，在 ROOTCA 中应该有一个由cert-manager istio-ca 签署的 trustedCA 字段。\n比较 trustedCA 中的 base64 值和 istio-system 中的 istio-ca secret ca.crt。这两个值应该是一样的。\nkubectl get secrets -n istio-system istio-ca -o json \u0026gt; istio-ca 总结 本文演示了如何将 cert-manager 作为 Istio 服务网格的外部 CA 进行集成。当服务网格在 Day 2实施阶段被引入时，cert-manager/服务网格的集成可以在不同的云中成功实施，并使用 cert-manager 的全新或现有部署。最后，您将获得两个世界中最好的东西：Istio 与您所选择的外部 CA 的集成。\n"},{"url":"https://istio.tetratelabs.io/zh/blog/","title":"博客","description":"社区博客","content":""},{"url":"https://istio.tetratelabs.io/zh/istio-ca-certs-integrations/acmpca-integration/","title":"ACM Private CA 集成","description":"与 ACM Private CA 集成。","content":"在这里，我们不使用自签名的根证书，而是从 AWS ACM Private CA 服务中获得 Istio 这个中介 CA，再由它来签署工作负载证书。这种方法可以为工作负载提供与 ACM Private CA 中的根 CA 相同的信任根。由于 Istio 自己签署工作负载证书，与直接获得 ACM Private CA 本身签署的证书相比，获得工作负载证书的延迟要少得多。\ngetmesh gen-ca 命令提供了连接到 ACM Private CA 并获得中间 CA 证书签名的选项。它使用这样获得的证书细节来创建 cacerts Kubernetes secret，供 Istio 用来签署工作负载证书。Istio 在启动时，会检查 cacerts secret 的存在，以决定是否需要使用该 cert 来签署工作负载证书。\n先决条件  在 AWS ACM Private CA 中设置的 CA 和 CA的ARN。 附带 AWSCertificateManagerPrivateCAFullAccess 和 AWSCertificateManagerFullAccess 策略的AWS证书。  配置设置 与连接 ACM 私有 CA 和创建 CSR 相关的参数可以通过配置文件或命令行选项提供。建议创建一个配置文件。下面给出一个配置文件的例子，参数是不言自明的。\nacmpca-config.yaml\nproviderName: \u0026#34;aws\u0026#34; providerConfig: aws: signingCAArn: {your acmpca CA ARN} # 用于 CSR 的模板。 templateArn: \u0026#34;arn:aws:acm-pca:::template/SubordinateCACertificate_PathLen0/V1\u0026#34; # 可选字段。留空将确实为 SHA256WITHRSA。 signingAlgorithm: SHA256WITHRSA certificateParameters: secretOptions: # 在目标集群上创建 \u0026#34;cacerts\u0026#34; Kubernetes secret 的命名空间。 istioCANamespace: \u0026#34;istio-system\u0026#34; # SecretFilePath 是用于以 yaml 格式存储 Kubernetes Secret 的文件路径。 secretFilePath: # 启用 force 标志后，强制删除 istioNamespace 中的 \u0026#34;cacerts\u0026#34; secret，并创建一个新的 secret。 overrideExistingCACertsSecret: true # 覆盖现有的 “cacerts” secret，用新的 secret 代替。 caOptions: # ValidityDays 表示 CA 过期前的有效天数。 validityDays: 365 # KeyLength 是要创建的 key 的比特位数。 keyLength: 2048 # 这是 x509.CertificateRequest。下面只显示了几个字段。 certSigningRequestParams: subject: commonname: \u0026#34;getmesh.example.io\u0026#34; country: - \u0026#34;US\u0026#34; locality: - \u0026#34;Sunnyvale\u0026#34; organization: - \u0026#34;Istio\u0026#34; organizationunit: - \u0026#34;engineering\u0026#34; emailaddresses: - \u0026#34;youremail@example.io\u0026#34; 一旦我们满足了前提条件并创建了配置文件，我们就可以运行 getmesh gen-ca 命令来创建 cacerts Kubernetes secret 以及 secret 的本地 yaml 文件。getmesh 连接到你的 Kubernetes 配置指向的集群。\ngetmesh gen-ca --config-file acmpca-config.yaml 运行完该命令，你会发现在 ~/.getmesh/secret/ 下创建了一个文件，并且在 istio-system 命名空间中创建了 cacerts secret。istiod 启动后会使用这个证书来签署工作负载证书。\n"},{"url":"https://istio.tetratelabs.io/zh/ecosystem-partners/appviewx/","title":"AppViewX","description":"AppViewX","content":"我们很高兴能与 AppviewX 合作。要获得这种伙伴关系的概述，请访问伙伴关系概述页面。\n"},{"url":"https://istio.tetratelabs.io/zh/ecosystem-partners/jetstack/cert-manager/","title":"Cert Manager","description":"在 Istio 中集成 Cert Manager。","content":" 这篇文章最初发表在 Istio 官方文档。\n cert-manager 是一个自动管理证书的工具。它可以与 Istio 网关集成，管理 TLS 证书。\n配置 请查阅 cert-manager 安装文档以开始使用。无需特殊更改即可与 Istio 一起使用。\n用法 Istio Gateway cert-manager 可以用于向 Kubernetes 写入机密，然后网关可以引用它。首先Certificate，请按照cert-manager 文档配置资源。本Certificate应在相同的命名空间创建istio-ingressgateway部署。例如，aCertificate可能看起来像：\napiVersion: cert-manager.io/v1alpha2 kind: Certificate metadata: name: ingress-cert namespace: istio-system spec: secretName: ingress-cert commonName: my.example.com dnsNames: - my.example.com ... 一旦我们创建了证书，我们应该看到在 istio-system 命名空间中创建的 secret。然后，这可以在 tls 配置中，在 credentialName 下的 Gateway 中引用：\napiVersion: networking.istio.io/v1alpha3 kind: Gateway metadata: name: gateway spec: selector: istio: ingressgateway servers: - port: number: 443 name: https protocol: HTTPS tls: mode: SIMPLE credentialName: ingress-cert # 这应该与证书的 secretName 相匹配。 hosts: - my.example.com # 这应该与证书中的 DNS 名称相匹配。 Kubernetes Ingress cert-manager 通过在 Ingress 对象上配置注释来提供与 Kubernetes Ingress 的直接集成。如果使用此方法，则 Ingress 必须位于与 istio-ingressgateway 部署相同的命名空间中，因为 secret 只能在同一命名空间中读取。\n或者，Certificate 可以按照 Istio Gateway 所述创建一个，然后在该 Ingress 对象中引用：\napiVersion: networking.k8s.io/v1beta1 Kind: Ingress metadata: name: ingress annotations: kubernetes.io/ingress.class: istio spec: rules: - host: my.example.com http: ... tls: - hosts: - my.example.com # 这应该与证书中的 DNS 名称相匹配。 secretName: ingress-cert # 这应该与证书的 secretName 相匹配。 "},{"url":"https://istio.tetratelabs.io/zh/istio-ca-certs-integrations/gcp-cas-integration/","title":"GCP CAS 集成","description":"GCP CAS 的 Istio CA 证书","content":"在这里，我们不使用自签的根证书，而是从 GCP CAS 服务中获得一个中间的 Istio CA，再由它来签署工作负载证书。这种方法使工作负载的信任根与 GCP CAS 中的根 CA 所提供的相同。由于 Istio 自己签署工作负载证书，与直接获得 GCP CAS 本身签署的证书相比，获得工作负载证书的延迟要少得多。\ngetmesh gen-ca 命令提供了连接到 GCP CAS 并获得中间 CA 证书签名的选项。它使用这样获得的证书细节来创建 cacerts Kubernetes secret，供 Istio 用来签署工作负载证书。Istio 在启动时，会检查 cacerts secret 的存在，以决定是否需要使用这个 cert 来签署工作负载证书。\n前提条件  在 GCP CAS 中设立了一个 CA 环境变量 GOOGLE_APPLICATION_CREDENTIALS 所指向的 GCP 凭证文件，以获取由 GCP CAS 签名的 CA 位设置的 CSR。这里给出了获取凭证文件的详细方法。  配置设置 与连接到 GCP CAS 和创建 CSR 相关的参数可以通过文件或命令行选项提供。建议创建一个配置文件。 下面给出了一个配置文件的例子，参数是不言自明的。\ngcp-cas-config.yaml\nproviderName: \u0026#34;gcp\u0026#34; providerConfig: gcp: # 这将保存你在 GCP 上创建的证书颁发机构的完整 CA 名称。 casCAName: \u0026#34;projects/{project-id}/locations/{location}/certificateAuthorities/{YourCA}\u0026#34; certificateParameters: secretOptions: # 在目标集群上创建 \u0026#34;cacerts\u0026#34; Kubernetes secret 的命名空间。 istioCANamespace: \u0026#34;istio-system\u0026#34; # SecretFilePath 是用于以 yaml 格式存储 Kubernetes Secret 的文件路径。 secretFilePath: # 启用 force 标志后，强制删除 istioNamespace 中的 \u0026#34;cacerts\u0026#34; secret，并创建一个新的 secret。 overrideExistingCACertsSecret: true # 覆盖现有的 “cacerts” secret，用新的 secret 代替。 caOptions: # ValidityDays 表示 CA 过期前的有效天数。 validityDays: 365 # KeyLength 是要创建的 key 的比特位数。 keyLength: 2048 # 这是 x509.CertificateRequest。下面只显示了几个字段。 certSigningRequestParams: subject: commonname: \u0026#34;getmesh.example.io\u0026#34; country: - \u0026#34;US\u0026#34; locality: - \u0026#34;Sunnyvale\u0026#34; organization: - \u0026#34;Istio\u0026#34; organizationunit: - \u0026#34;engineering\u0026#34; emailaddresses: - \u0026#34;youremail@example.io\u0026#34; 一旦我们满足了前提条件并创建了配置文件，我们就可以运行 getmesh gen-ca 命令来创建 cacerts Kubernetes secret 以及 secret 的本地 yaml 文件。getmesh 连接到你的 Kubernetes 配置指向的集群。\ngetmesh gen-ca --config-file gcp-cas-config.yaml 运行完该命令，你会发现在 ~/.getmesh/secret/ 下创建了一个文件，并且在 istio-system 命名空间中创建了 cacerts secret。istiod 启动后会使用这个证书来签署工作负载证书。\n"},{"url":"https://istio.tetratelabs.io/zh/ecosystem-partners/jetstack/","title":"Jetstack","description":"Jetstack","content":"我们很高兴能与Jetstack合作。有关此次合作的概述，请访问 Jetstack 合作伙伴页面。\n对于详细的技术信息，我们准备了以下资源，以便您开始使用。\n Istio Cert Manager 集成  "},{"url":"https://istio.tetratelabs.io/zh/ecosystem-partners/keyfactor/","title":"Keyfactor","description":"Keyfactor","content":"我们很高兴能与 KeyFactor 合作。要了解这一合作关系的概况，请访问合作关系概述页面。\n"},{"url":"https://istio.tetratelabs.io/zh/ecosystem-partners/weaveworks/","title":"Weaveworks","description":"Weaveworks","content":"我们很高兴能与 Weaveworks 合作。要了解这一合作关系的概况，请访问合作关系概述页面。\n"},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/install-istio/","title":"安装 Istio","description":"如何使用 GetMesh CLI 安装 Istio。","content":"GetMesh 默认与你的 Kubernetes 配置所定义的集群进行通信。在继续之前，请确保你连接到了正确的集群。\n要安装 Istio 的 demo profile，可以使用 getmesh istioctl 命令来完成。\ngetmesh istioctl install --set profile=demo 输出：\n$ getmesh istioctl install --set profile=demo This will install the Istio demo profile with [\u0026#34;Istio core\u0026#34; \u0026#34;Istiod\u0026#34; \u0026#34;Ingress gateways\u0026#34; \u0026#34;Egress gateways\u0026#34;] components into the cluster. Proceed? (y/N) Y ✔ Istio core installed ✔ Istiod installed ✔ Ingress gateways installed ✔ Egress gateways installed ✔ Installation complete \u0026lt;/pre\u0026gt; Once this step is completed, the validation can be done by confirming the GetMesh and Istio versions installed, using the [version command](/getmesh-cli/reference/getmesh_version): getmesh version 输出：\n$ getmesh version getmesh version: 0.6.0 active istioctl: 1.8.2-tetrate-v0 client version: 1.8.2-tetrate-v0 control plane version: 1.8.2-tetrate-v0 data plane version: 1.8.2-tetrate-v0 (2 proxies) 除了版本输出之外，用户还可以通过发出 config-validate 命令 来验证预期的功能（阅读更多关于 config 验证)。\ngetmesh config-validate 在重新安装 Kubernetes 集群和 Istio 的情况下，输出结果会类似于下面的样子：\n$ getmesh config-validate Running the config validator. This may take some time... NAMESPACE NAME RESOURCE TYPE ERROR CODE SEVERITY MESSAGE default default Namespace IST0102 Info The namespace is not enabled for Istio injection. Run \u0026#39;kubectl label namespace default istio-injection=enabled\u0026#39; to enable it, or \u0026#39;kubectl label namespace default istio-injection=disabled\u0026#39; to explicitly mark it as not needing injection. The error codes of the found issues are prefixed by \u0026#39;IST\u0026#39; or \u0026#39;KIA\u0026#39;. For the detailed explanation, please refer to - https://istio.io/latest/docs/reference/config/analysis/ for \u0026#39;IST\u0026#39; error codes - https://kiali.io/documentation/latest/validations/ for \u0026#39;KIA\u0026#39; error codes "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/install-istio-updates/","title":"安装 Istio 更新","description":"详细的 Istio 更新说明。","content":"通过 GetMesh 交付的 Istio 版本比上游版本的支持时间更长，并且会主动为关键的错误修复和安全更新打补丁。要检查你运行的 Istio 版本是否是最新的，或者是否缺少任何关键的安全补丁，请运行 check-upgrade 命令。该命令连接到集群（由 Kubernetes 配置定义），以验证现有的 Istio 安装，将这些安装与最新的可用 GetMesh 认证版本进行比较，并推荐建议的升级。要检查升级，请运行：\ngetmesh check-upgrade 输出将是类似于：\n$ getmesh check-upgrade [Summary of your Istio mesh] active istioctl version: 1.8.1-tetrate-v0 data plane version: 1.8.2-tetrate-v0 (2 proxies) control plane version: 1.8.2-tetrate-v0 [GetMesh Check] - 1.8.2-tetrate-v0 is the latest version in 1.8-tetrate "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/install-and-update-of-getistio/","title":"安装和更新 GetMesh","description":"如何安装和跟新 GetMesh。","content":"Tetrate Istio Distro可以通过以下命令获得。\ncurl -sL https://istio.tetratelabs.io/getmesh/install.sh | bash 默认情况下，这将下载最新版本的 Tetrate Istio Distro和认证的 Istio。要检查下载是否成功，运行 version 命令。\ngetmesh version 或者\ngetmesh version --remote=false #只有客户端版本的详细信息 以下表格的输出表明 Tetrate Istio Distro已成功安装。\ngetmesh version: 0.6.0 active istioctl: 1.8.2-tetrate-v0 要查看 Tetrate Istio Distro及其支持的功能的可用命令列表，运行 help 命令。\ngetmesh --help 下载 Tetrate Istio Distro后，可以通过运行 update 命令自我更新到最新版本。\ngetmesh update 虽然我们建议始终使用最新的 GetMesh，但如果用户出于测试或其他原因想下载不同版本的 GetMesh，可以使用以下命令。\nexport GETISTIO_VERSION=\u0026lt;your_version\u0026gt; # 比如说0.5.0 curl -sL https://istio.tetratelabs.io/getmesh/install.sh | bash 这将把现有的 Tetrate Istio Distro版本覆盖到刚刚下载的版本。\n"},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/install-istio-and-manage-multiple-istioctl/","title":"管理多个 istioctl","description":"如何安装 Istio 和管理多个 istioctl。","content":"下载并安装了最新的 GetMesh 和 Istio 的可信版本后，我们建议使用 getmesh 来调用 istioctl。我们建议始终使用 getmesh 来调用 istioctl。GetMesh 可以轻松地在多个版本的 istioctl 之间切换，并进行版本兼容性和配置检查，以确保只部署经过认证的 Istio。\n参考 Istio 文档，了解最新的 istioctl 命令和选项。\n现实生活中的需求往往决定了使用不同版本的 istioctl (而不是最新版本) 或由于自定义配置而利用多个版本的 istioctl。下面介绍实现的步骤。\n通过 GetMesh 使用 show 命令列出当前下载的 Istio 版本。\ngetmesh show Example output would be\n1.7.6-distro-v0 1.8.1-distro-v0 1.8.2-distro-v0 (Active) 如果还没有下载到所需的 Istio 版本，操作者可以先通过 list 命令查询可信的 Istio 版本列表。\ngetmesh list 输出示例为：\nISTIO VERSION FLAVOR FLAVOR VERSION K8S VERSIONS *1.8.2 tetrate 0 1.16,1.17,1.18 1.8.1 tetrate 1 1.16,1.17,1.18 1.7.6 tetratefips 2 1.16,1.17,1.18 1.7.5 tetratefips 3 1.16,1.17,1.18 1.7.4 tetrate 0 1.16,1.17,1.18 以下是利用 fetch 命令获取 Istio 1.8.1 版本的例子。\ngetmesh fetch --version 1.8.1 --flavor tetrate --flavor-version 0 在上面的例子中，Flavor tetrate 映射到上游 Istio，并添加了可能的补丁，Flavor tetratefips 是符合 FIPS 标准的 Flavor tetrate 版本。\n使用 show 命令 getmesh show 交叉检查是否下载了 Istio 版本，输出将列出所有版本并标记活动版本。\n$ getmesh show 1.7.4-distro-v0 1.7.6-distro-v0 1.8.1-distro-v0 (Active) 1.8.2-distro-v0 要切换到不同版本的 istioctl，请运行 switch 命令，例如：\ngetmesh switch --version 1.8.1 --flavor tetrate --flavor-version=0 输出示例为：\nistioctl switched to 1.8.1-tetrate-v0 now "},{"url":"https://istio.tetratelabs.io/zh/blog/how-to-set-up-istio-with-getistio-on-gke/","title":"如何使用 Tetrate Istio Distro 在 GKE 上安装 Istio","description":"本文将带大家亲身体验Tetrate Istio Distro在GKE上的安装和使用。","content":"Tetrate Istio Distro 是由 Tetrate 开源的基于 Istio 的发行版。他主要解决了用户使用 Istio 时候的以下痛点：\n Istio 生命周期管理 经过测试的安全的 Istio 配置 可原生的计算环境支持 陡峭的学习曲线及持续支持  想要了解更多关于 Tetrate Istio Distro 的信息请访问 https://istio.tetratelabs.io/。\n本文将从带你动手安装和使用 Istio，包括：\n 在 GKE 上安装 Istio 1.7 添加一台虚拟机到 mesh 中 部署 Bookinfo 示例 集成虚拟机测试 升级 Istio 到 1.8  从以上过程中你将了解 Istio 的部署架构、基本功能和操作。\n准备条件 为了完成动手操作，你需要准备以下环境：\n 一个 Google Cloud 账号，并且其中有足够的余额 在本地安装 gcloud 工具安装 Istio  这篇博客只适用于 Istio 1.7，1.8 版本的虚拟机整合步骤有变化，请参考 Istio 文档。\n安装 Istio 使用 Tetrate Istio Distro 安装 Istio 1.7.5。\ncurl -sL https://istio.tetratelabs.io/getmesh/install.sh | bash getmesh fetch 1.7.5 使用 demo profile（包括 Ingress gateway、egress gateway 和 Istiod 所有组件） 安装 Istio：\ngetmesh istioctl install --set profile=demo --set values.global.meshExpansion.enabled=true Detected that your cluster does not support third party JWT authentication. Falling back to less secure first party JWT. See https://istio.io/docs/ops/best-practices/security/#configure-third-party-service-account-tokens for details. ✔ Istio core installed ✔ Istiod installed ✔ Ingress gateways installed ✔ Egress gateways installed ✔ Installation complete 查看 istio-system namespace 下的 pod：\nkubectl get pod -n=istio-system NAME READY STATUS RESTARTS AGE istio-egressgateway-695f5944d8-wdk6s 1/1 Running 0 67s istio-ingressgateway-5c697d4cd7-4cgq7 1/1 Running 0 67s istiod-59747cbfdd-sbffx 1/1 Running 0 106s 设置 sidecar 自动注入：\nkubectl label namespace bookinfo istio-injection=enabled 部署 Bookinfo 示例。\nkubectl create ns bookinfo kubectl apply -n bookinfo -f samples/bookinfo/platform/kube/bookinfo.yaml service/details created serviceaccount/bookinfo-details created deployment.apps/details-v1 created service/ratings created serviceaccount/bookinfo-ratings created deployment.apps/ratings-v1 created service/reviews created serviceaccount/bookinfo-reviews created deployment.apps/reviews-v1 created deployment.apps/reviews-v2 created deployment.apps/reviews-v3 created service/productpage created serviceaccount/bookinfo-productpage created deployment.apps/productpage-v1 created 确认示例部署完成。\nkubectl exec \u0026#34;$(kubectl get pod -n bookinfo -l app=ratings -o jsonpath=\u0026#39;{.items[0].metadata.name}\u0026#39;)\u0026#34; -n bookinfo -c ratings -- curl -s productpage:9080/productpage | grep -o \u0026#34;\u0026lt;title\u0026gt;.*\u0026lt;/title\u0026gt;\u0026#34; 正常情况下你将看到这样的显示：\n\u0026lt;title\u0026gt;Simple Bookstore App\u0026lt;/title\u0026gt; 允许外网访问 mesh：\nkubectl -n bookinfo apply -f samples/bookinfo/networking/bookinfo-gateway.yaml export INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=\u0026#39;{.spec.ports[?(@.name==\u0026#34;http2\u0026#34;)].nodePort}\u0026#39;) export SECURE_INGRESS_PORT=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=\u0026#39;{.spec.ports[?(@.name==\u0026#34;https\u0026#34;)].nodePort}\u0026#39;) echo \u0026#34;$INGRESS_PORT\u0026#34; echo \u0026#34;$SECURE_INGRESS_PORT\u0026#34; export INGRESS_HOST=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=\u0026#39;{.status.loadBalancer.ingress[0].ip}\u0026#39;) echo \u0026#34;$INGRESS_HOST\u0026#34; export GATEWAY_URL=$INGRESS_HOST:$INGRESS_PORT echo \u0026#34;$GATEWAY_URL\u0026#34; 应用默认的 DestinationRule。\nkubectl apply -n bookinfo -f samples/bookinfo/networking/destination-rule-all.yaml 向 Istio mesh 中加入虚拟机 我们将在虚拟机中安装 MySQL，并将其配置为 ratings 服务的后台。最终，bookinfo 示例的拓扑将如下图所示。\n我们将在 Google cloud 中创建一台虚拟机，并将它添加到 Istio Mesh 中。假设虚拟机实例的名称是 instance-1，首先为虚拟机创建证书。\nkubectl create secret generic cacerts -n istio-system \\  --from-file=samples/certs/ca-cert.pem \\  --from-file=samples/certs/ca-key.pem \\  --from-file=samples/certs/root-cert.pem \\  --from-file=samples/certs/cert-chain.pem 安装 Istio mesh 扩展。\ngetmesh istioctl install \\  -f manifests/examples/vm/values-istio-meshexpansion.yaml 在 Cloud shell 中执行以下命令，生成虚拟机扩展的配置文件。\nVM_NAME=instance-1 VM_NAMESPACE=vm WORK_DIR=vm SERVICE_ACCOUNT=instance-1 cat \u0026lt;\u0026lt;EOF\u0026gt; \u0026#34;${WORK_DIR}\u0026#34;/vmintegration.yaml apiVersion: install.istio.io/v1alpha1 kind: IstioOperator spec: values: global: meshExpansion: enabled: true EOF getmesh istioctl install -f \u0026#34;${WORK_DIR}\u0026#34;/vmintegration.yaml kubectl create namespace \u0026#34;${VM_NAMESPACE}\u0026#34; kubectl create serviceaccount \u0026#34;${SERVICE_ACCOUNT}\u0026#34; -n \u0026#34;${VM_NAMESPACE}\u0026#34; # 1 hours，注意这个过期时间，这个 token 仅在认证时候使用，后面就不需要了。 tokenexpiretime=3600 echo \u0026#39;{\u0026#34;kind\u0026#34;:\u0026#34;TokenRequest\u0026#34;,\u0026#34;apiVersion\u0026#34;:\u0026#34;authentication.k8s.io/v1\u0026#34;,\u0026#34;spec\u0026#34;:{\u0026#34;audiences\u0026#34;:[\u0026#34;istio-ca\u0026#34;],\u0026#34;expirationSeconds\u0026#34;:\u0026#39;$tokenexpiretime\u0026#39;}}\u0026#39; | kubectl create --raw /api/v1/namespaces/$VM_NAMESPACE/serviceaccounts/$SERVICE_ACCOUNT/token -f - | jq -j \u0026#39;.status.token\u0026#39; \u0026gt; \u0026#34;${WORK_DIR}\u0026#34;/istio-token kubectl -n \u0026#34;${VM_NAMESPACE}\u0026#34; get configmaps istio-ca-root-cert -o json | jq -j \u0026#39;.\u0026#34;data\u0026#34;.\u0026#34;root-cert.pem\u0026#34;\u0026#39; \u0026gt; \u0026#34;${WORK_DIR}\u0026#34;/root-cert ISTIO_SERVICE_CIDR=$(echo \u0026#39;{\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;Service\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;name\u0026#34;:\u0026#34;tst\u0026#34;},\u0026#34;spec\u0026#34;:{\u0026#34;clusterIP\u0026#34;:\u0026#34;1.1.1.1\u0026#34;,\u0026#34;ports\u0026#34;:[{\u0026#34;port\u0026#34;:443}]}}\u0026#39; | kubectl apply -f - 2\u0026gt;\u0026amp;1 | sed \u0026#39;s/.*valid IPs is //\u0026#39;) touch \u0026#34;${WORK_DIR}\u0026#34;/cluster.env echo ISTIO_SERVICE_CIDR=$ISTIO_SERVICE_CIDR \u0026gt; \u0026#34;${WORK_DIR}\u0026#34;/cluster.env echo \u0026#34;ISTIO_INBOUND_PORTS=3306,8080\u0026#34; \u0026gt;\u0026gt; \u0026#34;${WORK_DIR}\u0026#34;/cluster.env touch \u0026#34;${WORK_DIR}\u0026#34;/hosts-addendum echo \u0026#34;${INGRESS_HOST}istiod.istio-system.svc\u0026#34; \u0026gt; \u0026#34;${WORK_DIR}\u0026#34;/hosts-addendum touch \u0026#34;${WORK_DIR}\u0026#34;/sidecar.env echo \u0026#34;PROV_CERT=/var/run/secrets/istio\u0026#34; \u0026gt;\u0026gt;\u0026#34;${WORK_DIR}\u0026#34;/sidecar.env echo \u0026#34;OUTPUT_CERTS=/var/run/secrets/istio\u0026#34; \u0026gt;\u0026gt; \u0026#34;${WORK_DIR}\u0026#34;/sidecar.env 将虚拟机配置文件导入到虚拟机实例 instance-1 中。使用 ssh 登录到虚拟机实例 instance-1 中，将为 Kubernetes 集群和 Istio 生成的文件拷贝到虚拟机的 $HOME 目录下。\nsudo apt -y update sudo apt -y upgrade sudo mkdir -p /var/run/secrets/istio sudo cp \u0026#34;${HOME}\u0026#34;/root-cert.pem /var/run/secrets/istio/root-cert.pem sudo mkdir -p /var/run/secrets/tokens sudo cp \u0026#34;${HOME}\u0026#34;/istio-token /var/run/secrets/tokens/istio-token # Setup Istio on the VM curl -LO https://storage.googleapis.com/istio-release/releases/1.7.1/deb/istio-sidecar.deb sudo dpkg -i istio-sidecar.deb sudo cp \u0026#34;${HOME}\u0026#34;/cluster.env /var/lib/istio/envoy/cluster.env sudo cp \u0026#34;${HOME}\u0026#34;/sidecar.env /var/lib/istio/envoy/sidecar.env sudo sh -c \u0026#39;cat $(eval echo ~$SUDO_USER)/hosts-addendum \u0026gt;\u0026gt; /etc/hosts\u0026#39; sudo cp \u0026#34;${HOME}\u0026#34;/root-cert.pem /var/run/secrets/istio/root-cert.pem sudo mkdir -p /etc/istio/proxy sudo chown -R istio-proxy /var/lib/istio /etc/certs /etc/istio/proxy /var/run/secrets 注意：默认情况下虚拟机的防火墙会拒绝对 3306 端口的入站请求，我们需要配置 VPC 中的防火墙规则，以允许 mesh 中的服务访问虚拟机的 3306 端口。\n现在可以启动虚拟机中的 Istio 了。\nsudo systemctl start istio 虚拟机集成测试 在虚拟机中安装 MySQL，并作为服务的后端。\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y mariadb-server sudo mysql GRANT ALL PRIVILEGES ON *.* TO \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39; WITH GRANT OPTION; quit; sudo systemctl restart mysql curl -q https://raw.githubusercontent.com/istio/istio/release-1.7/samples/bookinfo/src/mysql/mysqldb-init.sql | mysql -u root -ppassword mysql -u root -ppassword test -e \u0026#34;select * from ratings;\u0026#34; mysql -u root -ppassword test -e \u0026#34;update ratings set rating=5 where reviewid=1;select * from ratings;\u0026#34; hostname -I # 假如这里获取到的 IP 地址是 \u0026lt;virtual_machine_ip\u0026gt; 将虚拟机中的服务注册到 mesh 中。\ngetmesh istioctl experimental add-to-mesh -n vm mysqldb \u0026lt;virtual_machine_ip\u0026gt; mysql:3306 将看到这样的输出：\n2020-09-17T11:34:37.740252Z warn Got \u0026#39;services \u0026#34;mysqldb\u0026#34; not found\u0026#39; looking up svc \u0026#39;mysqldb\u0026#39; in namespace \u0026#39;vm\u0026#39;, attempting to create it 2020-09-17T11:34:38.111244Z warn Got \u0026#39;endpoints \u0026#34;mysqldb\u0026#34; not found\u0026#39; looking up endpoints for \u0026#39;mysqldb\u0026#39; in namespace \u0026#39;vm\u0026#39;, attempting to create them 部署 ratings 服务的 v2 版本，使用 MySQL 作为存储后端。\nkubectl apply -n bookinfo -f samples/bookinfo/platform/kube/bookinfo-ratings-v2-mysql-vm.yaml kubectl apply -n bookinfo -f samples/bookinfo/networking/virtual-service-ratings-mysql-vm.yaml 为部署在虚拟机上的 MySQL 服务添加 DestinationRule、ServiceEntry 和 WorkloadEntry 的配置。\napiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: mtls-mysqldb-vm spec: host: mysqldb.vm.svc.cluster.local trafficPolicy: tls: mode: ISTIO_MUTUAL --- apiVersion: networking.istio.io/v1alpha3 kind: ServiceEntry metadata: name: mysqldb-vm spec: hosts: - mysqldb.vm.svc.cluster.local location: MESH_INTERNAL ports: - number: 3306 name: mysql protocol: mysql resolution: STATIC workloadSelector: labels: app: mysqldb-vm --- apiVersion: networking.istio.io/v1alpha3 kind: WorkloadEntry metadata: name: mysqldb-vm spec: address: \u0026lt;virtual_machine_ip\u0026gt; #修改为虚拟机的 IP labels: app: mysqldb-vm instance-id: ubuntu-vm-mariadb 升级到 Isito 1.8 2020 年 11 月 19 日，Istio 1.8 发布，支持使用canary 和in-place 升级。下面我们将使用 in-place 方式升级 Istio。\ngetmesh fetch --version 1.8 getmesh istioctl upgrade Confirm to proceed [y/N]? 输入 y 确认升级，确认控制平面升级完成后，接下来我们来升级数据平面。\nkubectl rollout restart deployment --namespace bookinfo 使用 getmesh istioctl proxy-status -n bookinfo 命令检查 proxy 的版本，可以看到都已经升级为了 1.8.0。\n常用命令 以下是在以上操作过程中的常用命令。\n使用 gcloud 命令登录到 Google cloud 的虚拟机\ngcloud compute ssh jimmy@instance-1 --zone=us-west2-a 清理 bookinfo 示例\n在解压后的 istio 安装包的根目录下执行：\nsamples/bookinfo/platform/kube/cleanup.sh "},{"url":"https://istio.tetratelabs.io/zh/tags/%E6%A1%88%E4%BE%8B%E5%88%86%E4%BA%AB/","title":"案例分享","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/blog/netease-qingzhou-istio-practice/","title":"网易轻舟如何基于 Istio 实现微服务架构演进","description":"网易轻舟使用 Istio 的实践分享。","content":"作者：裴斐，网易轻舟高级架构师。\nProblem 网易作为一家拥有众多互联网业务的公司，不同业务结合自身的业务特性、团队组成均有一些微服务技术栈选择、体系建设，这在业务发展初期并没有问题。当业务持续发展，不管业务规模、复杂度、团队的组成都发生了变化，这时候微服务架构就会遇到诸多问题：\n 各业务分别投入研发，研发成本高 网易集团技术资产无法沉淀 微服务框架对业务侵入性大，需要业务人员明显感知、学习、掌控和维护 升级周期长，即使是很小版本的框架升级，都需要动辄1个月以上的升级周期 语言局限，绝大多数核心业务的微服务体系基于Java语言构建，对其他语言支持薄弱  Strategy Service Mesh是云原生体系下重要的微服务技术，可以有效的解决网易诸多互联网业务在微服务架构下存在的问题。网易选择Istio这一有代表性的Service Mesh开源框架有着深刻的考虑：\n 有深厚的云原生背景及大厂背书 Istio的核心数据面组件Envoy是云原生数据面的事实标准组件 在Service Mesh领域，Istio是最为流行的框架选择，有着活跃的技术社区和优秀的技术架构 Istio在帮助企业落地、框架易用性方面持续优化，具备企业应用的亲和性  在确定Istio为Service Mesh框架选型后，网易数帆的轻舟团队构建了轻舟Service Mesh平台，以解决网易集团诸多互联网业务面临的微服务架构问题，并整合已有的微服务治理框架，形成支撑通用分布式、微服务架构演进的微服务平台，赋能更多企业的微服务架构演进与升级。此外，网易轻舟还基于Istio技术栈实现了API网关体系升级，基于Envoy与Isito的轻舟API网关能力更丰富，性能更好，已成为网易API网关的标准组件。\n尽管Istio提供了非常完整的Service Mesh解决方案，企业在构建Service Mesh体系时仍需要明晰的建设路线。 架构设计 网易轻舟Service Mesh整体架构如下。\n架构设计要点：\n 通过扩展Envoy+定制Istio进行了整体的架构设计，并进行相应的可行性验证。 以Envoy为核心的数据面，支持多种拦截方式。除原生Istio支持的全量拦截TCP流量外，加入了IP指向、动态控制拦截等易于业务接入的流量拦截方式。 以Istio Pilot为核心的控制面，其他组件可插拔。Istio 1.5之前版本控制面组件较多，维护成本较高。选定控制面核心组件Pilot为必要组件，其他组件可插拔，不仅降低了Istio生产落地的风险和运维成本，也让研发、维护者在体系构建上更加聚焦。 多种扩展方式，供业务已有平台快速接入。提供了原生Istio CRD、MCP、API平面等多种平台开放方式，一方面将原生能力完整保留，另一方面通过简单Restful API方式，降低企业平台构建或已有平台接入成本。 性能优化：组件、网络多管齐下。一方面在组件层进行优化，如将Istio早期版本集中式Mixer后端能力下沉到Envoy filter，提供基于调用链路审计的配置瘦身等。另一方面配合容器网络进行网络加速，降低延时。  演进方案 基于整体架构设计，结合业务实际的架构、技术栈，形成微服务架构演进方案。以网易电商业务演进方案为例，演进架构图如下：\n演进要点：\n 基于业务现有技术、架构分析，形成迁移的整体架构 业务接入：在基础设施层进行适配，保障业务无感知迁移 跨云互访：基于边缘网关的混合云方案，保障迁移前后环境无缝互访 高可用保障：兜底路由、灰度引流等能力建设，保障迁移过程的SLA  平台建设 Istio落地过程中，业务需要网格整体视图及快速治理能力，为此我们增强了网易轻舟微服务平台，加入Service Mesh管控能力，支持Service Mesh与微服务框架（Spring Cloud、Dubbo、gRPC、Thrift）跨集群统一管控，帮助用户现有微服务架构平滑迁移。\n建设要点：结合业务痛点，完善产品能力\n 可观测性：提供整体视图及快速治理功能 易用性：云原生概念产品级封装 扩展性：Open API 体系建设，业务平台快速接入  体系建设 基于Istio的Service Mesh技术架构需要完整的体系保障。\n体系建设要点： 构建、部署体系：Service Mesh组件CICD、自动部署 质量体系：自动化功能、性能、稳定性测试；整体故障测试；混沌测试 排障体系：业务、组件排障，快速对Service Mesh体系的故障定位与恢复 运维保障体系：立体化监控、报警 热升级体系：支持Sidecar热升 开源技术体系：轻舟团队对Service Mesh社区持续贡献\n场景扩展：支撑API网关 设计要点：\n 扩展Service Mesh技术栈，复用云原生技术成果 整体设计与可行性验证 Envoy作为高性能数据面，增强插件扩展能力 Istio Pilot作为基础控制面，多种扩展接入方式 API平面设计，屏蔽平台差异，方便平台快捷接入  Results  网易严选、传媒、有道、行业平台等业务实现业务落地，千级服务、万级实例接入 实现网易微服务基础设施下沉。各业务线研发不再需要过多关注微服务治理，降低业务微服务整体研发与维护成本 快速引入多语言治理、热升级、故障注入、路由、熔断降级等服务治理能力 赋能网易集团业务，实现微服务技术栈的统一，向云原生技术方向演进 作为云原生基础设施长期规划，支撑更多应用场景：API网关、DB\u0026amp;中间件 Mesh、故障演练等。API网关已成为网易API网关标准组件，支撑网易传媒、严选、Lofter等多个业务核心服务全站流量接入 网易微服务架构与技术在业界处于领先梯队水平  "},{"url":"https://istio.tetratelabs.io/zh/blog/istio-18-a-virtual-machine-integration-odyssey/","title":"Istio 1.8: A Virtual Machine Integration Odyssey","description":"本文中我将带你了解 Istio 支持虚拟机的波澜壮阔的历史。","content":"本文将为你介绍 Istio 历史上对虚拟机负载的支持情况，尤其是 Istio 1.8 中引入的智能 DNS 代理及 WorkloadGroup 使得虚拟机与容器在资源抽象层面可以等同视之。我将为你展现一幅 Istio 支持虚拟机的波澜壮阔的奥德赛。\n前言 在我之前的博客中谈到 Istio 1.7 如何支持虚拟机，但那时虚拟机仍然无法无缝的集成到 Istio 中，因为还需要做很多手动的操作。现在，Istio 1.8 新增了 WorkloadGroup 及智能 DNS 代理，这使得如虚拟机这样的非 Kubernetes 工作负载可以在 Istio 中成为像 Pod 一样的一等公民。\n不论有没有为虚拟机安装 sidecar，虚拟机通常情况下无法直接访问 Kubernetes 集群中的 DNS 服务器以解析 Kubernetes 服务的 Cluster IP 的（虽然你也许可以通过一些黑客的手段做到），这是在 Istio 中集成虚拟的最后一块短板，终于在 Istio 1.8 中完成了突破。\n为什么要支持虚拟机？ 在我们将应用在迁移到云原生架构，不断容器化的过程中，将经历三个阶段，如下图所示。\n 阶段一：应用全部部署在虚拟机上 阶段二：应用既部署在虚拟机上也部署在容器里，正在从虚拟机向容器中迁移，并使用 Kubernetes 管理容器 阶段三：所有的应用优先部署在容器里，使用 Kubernetes 管理容器，使用 Istio 管理应用间的通信  上图仅是对以上三个阶段的最简化描述，实际上还会有多混合云、多机房、多集群等情况，且阶段三只是个理想化的阶段，容器和虚拟机将是长期共存的，但是容器化趋势不变。\n在阶段二中，人们通常会将新业务和少量应用率先实现容器化，并部署到 Kubernetes 中，在应用尚未完全实现容器化的时候，处于过度状态时会遇到很多问题，如何让应用与部署在虚拟机中的服务交互？虚拟机如何访问容器中的服务？在服务迁移的过程中如何保证稳定无缝？是否可以将容器和虚拟机纳入一个统一的控制平面来管理？Istio 从开源初期就考虑并着手解决这一问题。\nIstio 支持虚拟机的历史 Istio 对于虚拟机的支持是个漫长的过程，堪称是一部奥德赛。\nIstio mesh 扩张 Istio 从 0.2 版本开始通过 Istio Mesh Expansion 将虚拟机加入的 Mesh 中，但是需要满足以下前提条件：\n 虚拟机必须可以通过 IP 地址直接访问到应用的 Pod，这就要求容器与 VM 之间通过 VPC 或者 VPN 建立扁平网络，虚拟机不需要访问 Cluster IP，直接对服务的 Endpoint 端点访问即可。 虚拟机必须可以访问到 Istio 的控制平面服务（Pilot、Mixer、CA，现在已正整合为 Istiod），可以通过在 Istio Mesh 中部署负载均衡器将控制平面端点暴露给虚拟机。 （可选）虚拟机可以访问到 Mesh 内部的（部署在 Kubernetes 中）的 DNS server。  集成虚拟机的步骤如下：\n 为 Istio 控制平面服务及 Kubernetes 集群的 DNS 服务创建 Internal 负载均衡器； 生成 Istio Service CIDR、Service Account token、安全证书、Istio 控制平面服务的 IP（通过 Internal 负载均衡器暴露出来的 IP）的配置文件并发送给虚拟机； （可选）在虚拟机中安装、配置并启动 Istio 的组件、dnsmaq（用于DNS 发现），此时虚拟机可以使用 FQDN 访问 mesh 中的服务了，这一步是为了保证虚拟机可以正确解析出 mesh 中服务的 Cluster IP； 若要在虚拟机中运行服务，需要配置 sidecar，新增需要拦截的 inbound 端口，然后重启 istio，还需要运行 istioctl 为服务注册  下图展示的从集成虚拟机到在 mesh 中访问虚拟机中服务的详细流程。\n DNS 被虚拟机中部署的 dnsmasq 劫持，这使得它可以正确的获取 Istio 服务、Kubernetes 内置 DNS 的端点 IP； 访问 Kubernetes 的内置 DNS 服务（该服务已通过 Internal 负载均衡器暴露到集群外，可以直接访问）； 返回 productpage.bookinfo.svc.cluster.local 被解析出来的 Cluster IP，注意该 IP 地址无法直接访问，但是如果无法被 DNS 解析的话将导致 VM 对该服务的请求失败； 虚拟机对 mesh 中服务的访问被 sidecar proxy 劫持； 因为 proxy 已连接 Istio 控制平面，可通过 xDS 查询到该服务的端点，因此流量将被转发到其中的一个端点。关于这一步的详细过程请参考 Istio Handbook 中的 sidecar 流量路由机制分析 一节； 要想在 mesh 中访问 VM 中的服务，需要使用 istioctl register 命令手动将 VM 中的服务添加到 mesh 中，这本质上是将 VM 中的服务，注册到 Kubernetes 中的 service 和 endpoint； mesh 中的服务可以使用 VM 注册的服务名称（FQDN，例如 mysql.vm.svc.cluster.local）来访问；  以上 Istio 对虚拟机支持的方式一直延续到 Istio 1.0，在 Istio 1.1 的时候引入了新的 API ServiceEntry，使用它可以在 Istio 的内部服务注册表中添加额外的条目，这样 mesh 中的服务就可以访问/路由到这些手动指定的服务了，不再需要运行 istioctl register 命令，而且该命令在 Istio 1.9 中将被废弃。\nIstio 1.5 中增加了 istioctl experimental add-to-mesh 命令，可以将虚拟机中的服务添加到 mesh 中，其功能与 istioctl register 一样。\n新增资源抽象 Istio 从 1.6 版本开始在流量管理中引入了新的资源类型 WorkloadEntry，用以将虚拟机进行抽象，使得虚拟机在加入 mesh 后可以作为与 Kubernetes 中的 Pod 等同的负载，具备流量管理、安全管理、可视化等能力。通过 WorkloadEntry 可以简化虚拟机的网格化配置过程。WorkloadEntry 对象可以根据服务条目中指定的标签选择器选择多个工作负载条目和 Kubernetes pod。\nIstio 1.8 中增加了 WorkloadGroup 的资源对象，它提供了一个规范，可以同时包括虚拟机和 Kubernetes 工作负载，旨在模仿现有的用于 Kubernetes 工作负载的 sidecar 注入和部署规范模型来引导 Istio 代理。\n下面是虚拟机与 Kubernetes 中负载的资源抽象层级对比。\n   对比项 Kubernetes 虚拟机     基础调度单位 Pod WorkloadEntry   编排组合 Deployment WorkloadGroup   服务注册与发现 Service ServiceEntry    从上面的图表中我们可以看到，对于虚拟机工作负载是可以与 Kubernetes 中的负载一一对对应的。\n此时看似一切都比较完美了，但是直接将 Kubernetes 集群中的 DNS server 暴露出来会带来很大的安全风险，因此我们一般手动将虚拟机需要访问的服务的域名和 Cluster IP 对写到本机的 /etc/hosts 中，但是对于一个节点数量庞大的分布式集群来说，这种做法又有些不现实。\n通过配置虚拟机本地 /etc/hosts 访问 mesh 内服务的流程，如下图所示。\n 将虚拟机中的服务注册到 mesh 中； 将要访问的服务的域名、Cluster IP 对手动写入虚拟机本地的 /etc/hosts 文件中； 虚拟机获得访问服务的 Cluster IP； 流量被 sidecar proxy 拦截并解析出要访问的服务的端点地址； 访问服务的指定端点；  在 Kubernetes 中我们一般使用 Service 对象来实现服务的注册和发现，每个服务都有一个独立的 DNS 名称，应用程序可以使用服务名称来互相调用。我们可以使用 ServiceEntry 将虚拟机中的服务注册到 Istio 的服务注册表中，但是在 Kubernetes 集群中的 DNS server 无法对 mesh 外部暴露的情况下，虚拟机无法访问 Kubernetes 集群中的 DNS 服务以获取服务的 Cluster IP，从而导致虚拟机访问 mesh 中的服务失败。如果能在虚拟机中增加一个 sidecar 可以透明地拦截 DNS 请求，可获取 mesh 内所有服务的 ClusterIP，类似于图一中的 dnsmasq 的角色，这样不就可以解决问题了吗？\n智能 DNS 代理 Istio 1.8 中引入了智能 DNS 代理，虚拟机访问 mesh 内服务无需再配置 /ect/hosts，如下图所示。\nDNS proxy 是用 Go 编写的 Istio sidecar 代理。Sidecar 上的 Istio agent 将附带一个由 Istiod 动态编程的缓存 DNS 代理。来自应用程序的 DNS 查询会被 pod 或 VM 中的 Istio 代理透明地拦截和服务，该代理会智能地响应 DNS 查询请求，可以实现虚拟机到服务网格的无缝多集群访问。\n至此，Istio 1.8 中引入的 WordloadGroup 及智能 DNS 代理，补足了 Istio 对虚拟机支持的最后一块短板，使得部署在虚拟机中的遗留应用可以跟 Kubernetes 中的 Pod 一样完全等同看待。\n总结 在这部 Istio 支持虚拟机的奥德赛中，我们可以看到：从最初的将 mesh 中的 DNS server 暴露给外部，在虚拟机中安装配置 dnsmasq，到最后的使用智能 DNS 代理，并使用 WorkloadEntry、WorkloadGroup 和 ServiceEntry 等资源抽象，逐步实现了虚拟机和 pod 的统一管理。本文仅仅是针对单集群的情况，在实际的生产中使用还远远不够，我们还需要处理安全、多集群、多租户等诸多问题，欢迎关注 Tetrate 的旗舰产品 Tetrate Service Bridge 了解更多关于 Istio 应用在生产上的最佳实践。\n"},{"url":"https://istio.tetratelabs.io/zh/tags/vm/","title":"VM","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/","title":"参考","description":"关于 GetMesh 命令行的使用的详细信息。","content":"  "},{"url":"https://istio.tetratelabs.io/zh/config-validation/istio-config-validation/","title":"配置验证详情","description":"配置验证的命令用法","content":"config-validate 命令不限于通过 GetMesh 安装的 Istio 版本，而且适用于所有 Istio 发行版、上游和其他版本。\n下面的命令检查应用在 my-app.yaml 和 another-app.yaml 中定义的 manifest 是否会触发任何验证错误。该命令基于三个来源（Istio 上游、Kiali 和本地 GetMesh）报告结果，而无需应用任何配置更改。它可以防止不必要的停机或可预防的问题影响生产工作负载。\n# 根据当前集群验证本地 manifest getmesh config-validate my-app.yaml another-app.yaml 为方便起见，该命令可以使用指定目录中的所有 manifest，而不是像 operator 那样使用单个文件名。下面的示例从 my-manifest-dir 中提取所有 manifest，并检查应用这些 manifest 是否会触发任何验证警报。\n# 根据特定 namespace 中的当前集群验证目录中的本地 manifest getmesh config-validate -n bookinfo my-manifest-dir/ 当前实现的配置的验证也是可能的——可以利用下面的命令对集群或每个 namespace 进行验证。\n# 对所有 namespace getmesh config-validate # 对特定 namespace getmesh config-validate -n bookinfo 其输出结果将类似于：\nNAME RESOURCE TYPE ERROR CODE SEVERITY MESSAGE bookinfo-gateway Gateway IST0101 Error Referenced selector not found: \u0026#34;app=nonexisting\u0026#34; bookinfo-gateway Gateway KIA0302 Warning No matching workload found for gateway selector in this namespace The error codes of the found issues are prefixed by \u0026#39;IST\u0026#39; or \u0026#39;KIA\u0026#39;. For the detailed explanation, please refer to - https://istio.io/latest/docs/reference/config/analysis/ for \u0026#39;IST\u0026#39; error codes - https://kiali.io/documentation/latest/validations/ for \u0026#39;KIA\u0026#39; error codes "},{"url":"https://istio.tetratelabs.io/zh/download/downloads/","title":"","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/faq/faqs/","title":"","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/istio-cheatsheet/cheatsheet/","title":"","description":"","content":""},{"url":"https://istio.tetratelabs.io/zh/login/","title":"","description":"","content":""},{"url":"https://istio.tetratelabs.io/community/building-and-testing/","title":"Building and Testing","description":"","content":"Before you proceed, please make sure that you have the following dependencies available in your machine:\n https://github.com/google/addlicense https://github.com/golangci/golangci-lint a Kubernetes cluster (e.g. https://kind.sigs.k8s.io/)  Run linter Here we use golangci-lint configured in .golangci.yml for static analysis, so please make sure that you have it installed.\nTo run linter, simply execute:\nmake lint Run unittests Running unittests does not require any k8s cluster, and it can be done by\nmake test Build binary make build Run e2e tests Running end-to-end tests requires you to have a valid k8s context. Please note that e2e will use your default kubeconfig and default context.\nIn order to run e2e tests, execute:\nmake e2e-test Build auto-generated docs make doc-gen Add license headers We require every source code to have the specified license header. Adding the header can be done by\nmake license "},{"url":"https://istio.tetratelabs.io/zh/istio-ca-certs-integrations/cert-manager-integration/","title":"cert-manager CA 集成","description":"cert-manager CA 集成。","content":"本任务展示了如何使用 cert-manager 与外部证书授权机构一起提供控制平面和工作负载证书。cert-manager 是 Kubernetes 的 x509 证书操作员，它支持许多 Issuers，代表可以签署证书的证书授权机构。\nistio-csr 项目安装了一个代理，该代理负责验证来自 Istio 服务网格负载的传入证书签名请求，并通过配置的 Issuer 通过 cert-manager 进行签名。\n安装 istio-csr 首先，必须使用你喜欢的方法在集群上安装 cert-manager。\n$ helm repo add jetstack https://charts.jetstack.io $ helm repo update $ kubectl create namespace cert-manager $ helm install -n cert-manager cert-manager jetstack/cert-manager --set installCRDs=true 接下来，应该在 istio-system 命名空间中创建一个 Issuer，以便为你的 Istio 安装签署证书。在这种情况下，我们将使用通过 cert-manager 生成的自签名证书，尽管任何适合内部 PKI 系统的 Issuer 都可以使用。兼容的外部 Issuer 也可以在此安装中使用。\n 请注意，强烈不鼓励使用公开信任的证书，包括 ACME 证书。\n $ kubectl create namespace istio-system $ kubectl apply -n istio-system -f - \u0026lt;\u0026lt;EOF apiVersion: cert-manager.io/v1 kind: Issuer metadata: name: selfsigned spec: selfSigned: {} --- apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: istio-ca spec: isCA: true duration: 2160h # 90d secretName: istio-ca commonName: istio-ca subject: organizations: - cert-manager issuerRef: name: selfsigned kind: Issuer group: cert-manager.io --- apiVersion: cert-manager.io/v1 kind: Issuer metadata: name: istio-ca spec: ca: secretName: istio-ca EOF $ kubectl get issuers -n istio-system NAME READY AGE istio-ca True 12m 一旦 Issuer 准备就绪，istio-csr 就可以安装到集群中。\n$ helm install -n cert-manager cert-manager-istio-csr jetstack/cert-manager-istio-csr 确认 istio-csr 正在运行，并且 istiod 证书处于就绪状态。\n$ kubectl get pods -n cert-manager NAME READY STATUS RESTARTS AGE cert-manager-756bb56c5-cdvln 1/1 Running 0 111s cert-manager-cainjector-86bc6dc648-bjnrp 1/1 Running 0 111s cert-manager-istio-csr-5b9cd98696-v4f6j 1/1 Running 0 12s cert-manager-webhook-66b555bb5-4s7qb 1/1 Running 0 111s $ kubectl get certificates -n istio-system NAME READY SECRET AGE istiod True istiod-tls 28s 安装到新的 Istio 集群 安装新的 Istio 集群时，必须配置成 Istio 控制平面和工作负载都使用 istio-csr 作为 CA 服务器。安装时应使用以下配置：\n$ cat \u0026lt;\u0026lt; EOF \u0026gt; config.yaml apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata: namespace: istio-system spec: values: global: caAddress: cert-manager-istio-csr.cert-manager.svc:443 components: pilot: k8s: env: # Disable istiod CA Sever functionality - name: ENABLE_CA_SERVER value: \u0026#34;false\u0026#34; overlays: - apiVersion: apps/v1 kind: Deployment name: istiod patches: # Mount istiod serving and webhook certificate from Secret mount - path: spec.template.spec.containers.[name:discovery].args[7] value: \u0026#34;--tlsCertFile=/etc/cert-manager/tls/tls.crt\u0026#34; - path: spec.template.spec.containers.[name:discovery].args[8] value: \u0026#34;--tlsKeyFile=/etc/cert-manager/tls/tls.key\u0026#34; - path: spec.template.spec.containers.[name:discovery].args[9] value: \u0026#34;--caCertFile=/etc/cert-manager/ca/root-cert.pem\u0026#34; - path: spec.template.spec.containers.[name:discovery].volumeMounts[6] value: name: cert-manager mountPath: \u0026#34;/etc/cert-manager/tls\u0026#34; readOnly: true - path: spec.template.spec.containers.[name:discovery].volumeMounts[7] value: name: ca-root-cert mountPath: \u0026#34;/etc/cert-manager/ca\u0026#34; readOnly: true - path: spec.template.spec.volumes[6] value: name: cert-manager secret: secretName: istiod-tls - path: spec.template.spec.volumes[7] value: name: ca-root-cert configMap: secretName: istiod-tls defaultMode: 420 name: istio-ca-root-cert EOF $ getmesh istioctl install -f config.yaml 安装应完成，Istio 控制平面应处于就绪状态。\n$ kubectl get pods -n istio-system NAME READY STATUS RESTARTS AGE istio-ingressgateway-9ddfd475f-47ssj 1/1 Running 0 45s istiod-6ff8d84d66-tvdl2 1/1 Running 0 71s 现在，所有的工作负载证书都将通过 cert-manager 使用配置的 Issuer 来请求。\n"},{"url":"https://istio.tetratelabs.io/zh/changelog/","title":"Changelog posts","description":"Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.","content":"February Updates Feb 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nChanged\r  Better support for using applying additional filters to posts_tax_query for categories for custom WordPress syncs\n  Reporting fine-tuning for speed improvements (up to 60% improvement in latency)\n  Replaced login / registration pre-app screens with a cleaner design\n   Removed\r Removed an issue with the sync autolinker only interlinking selectively. Removed up an issue with prematurely logging out users    March Updates Mar 6, 2019\nLorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt dolore magna aliquyam erat, sed diam voluptua. At vero eos et ustoLorem ipsum dolor sit amet, consetetur.\u0026quot;\nAdded\r Some scheduled changelogs, tweets, and slack messages queued up this weekend and were not published on time. We fixed the issue and all delayed publications should be out. We now prioritize keywords over title and body so customers can more effectively influence search results Support form in the Assistant is now protected with reCaptcha to reduce spam reinitializeOnUrlChange added to the JavaScript API to improve support for pages with turbolinks   Fixed\r Fixed an issue with the sync autolinker only interlinking selectively. Fixed up an issue with prematurely logging out users    Changelog label Added\r Changed\r Depricated\r Removed\r Fixed\r Security\r Unreleased\r "},{"url":"https://istio.tetratelabs.io/zh/community-events/","title":"Community 活动","description":"","content":"您可以通过多种方式为社区做出贡献并参与其中：\n 在 GitHub 贡献 GetMesh 项目。 加入和参与到我们的活动中。 加入到 Istio Slack 中的 GetIstio channel。 在 Tetrate Academy 中获得 Istio 认证。  "},{"url":"https://istio.tetratelabs.io/community/contributing/","title":"Contributing to GetMesh","description":"","content":"We welcome contributions from the community. Please read the following guidelines carefully to maximize the chances of your PR being merged.\nCode Reviews  Indicate the priority of each comment, following this feedback ladder. If none was indicated it will be treated as [dust]. A single approval is sufficient to merge, except when the change cuts across several components; then it should be approved by at least one owner of each component. If a reviewer asks for changes in a PR they should be addressed before the PR is merged, even if another reviewer has already approved the PR. During the review, address the comments and commit the changes without squashing the commits. This facilitates incremental reviews since the reviewer does not go through all the code again to find out what has changed since the last review.  DCO All authors to the project retain copyright to their work. However, to ensure that they are only submitting work that they have rights to, we are requiring everyone to acknowledge this by signing their work.\nThe sign-off is a simple line at the end of the explanation for the patch, which certifies that you wrote it or otherwise have the right to pass it on as an open-source patch. The rules are pretty simple: if you can certify the below (from developercertificate.org):\nDeveloper Certificate of Origin Version 1.1 Copyright (C) 2004, 2006 The Linux Foundation and its contributors. 660 York Street, Suite 102, San Francisco, CA 94110 USA Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed. Developer's Certificate of Origin 1.1 By making a contribution to this project, I certify that: (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it. (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved. then you just add a line to every git commit message:\nSigned-off-by: Joe Smith \u0026lt;joe@gmail.com\u0026gt;  using your real name (sorry, no pseudonyms or anonymous contributions.)\nYou can add the sign off when creating the git commit via git commit -s.\nOr, you can sign off the whole PR via git rebase --signoff main.\n"},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh/","title":"getmesh","description":"","content":"getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.\nOptions  -h, --help help for getmesh -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh check-upgrade\t- Check if there are patches available in the current minor version getmesh config-validate\t- Validate the current Istio configurations in your cluster getmesh default-hub\t- Set or Show the default hub passed to \u0026ldquo;getmesh istioctl install\u0026rdquo; via \u0026ldquo;\u0026ndash;set hub=\u0026rdquo; e.g. docker.io/istio getmesh fetch\t- Fetch istioctl of the specified version, flavor and flavor-version available in \u0026ldquo;getmesh list\u0026rdquo; command getmesh gen-ca\t- Generate intermediate CA getmesh istioctl\t- Execute istioctl with given arguments getmesh list\t- List available Istio distributions built by Tetrate getmesh prune\t- Remove specific istioctl installed, or all, except the active one getmesh show\t- Show fetched Istio versions getmesh switch\t- Switch the active istioctl to a specified version getmesh version\t- Show the versions of getmesh cli, running Istiod, Envoy, and the active istioctl  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_check-upgrade/","title":"getmesh check-upgrade","description":"","content":"Check if there are patches available in the current minor version, e.g. 1.7-tetrate: 1.7.4-tetrate-v1 -\u0026gt; 1.7.5-tetrate-v1\ngetmesh check-upgrade [flags] Examples # example output $ getmesh check-upgrade ... - Your data plane running in multiple minor versions: 1.7-tetrate, 1.8-tetrate - Your control plane running in multiple minor versions: 1.6-tetrate, 1.8-tetrate - The minor version 1.6-tetrate is not supported by Tetrate.io. We recommend you use the trusted minor versions in \u0026quot;getmesh list\u0026quot; - There is the available patch for the minor version 1.7-tetrate. We recommend upgrading all 1.7-tetrate versions -\u0026gt; 1.7.4-tetrate-v1 - There is the available patch for the minor version 1.8-tetrate which includes **security upgrades**. We strongly recommend upgrading all 1.8-tetrate versions -\u0026gt; 1.8.1-tetrate-v1 In the above example, we call names in the form of x.y-${flavor} \u0026quot;minor version\u0026quot;, where x.y is Istio's upstream minor and ${flavor} is the flavor of the distribution. Please refer to 'getmesh fetch --help' or 'getmesh list --help' for more information. Options  -h, --help help for check-upgrade Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_config-validate/","title":"getmesh config-validate","description":"","content":"Validate the current Istio configurations in your cluster just like \u0026lsquo;istioctl analyze\u0026rsquo;. Inspect all namespaces by default. If the \u0026lt;file/directory\u0026gt; is specified, we analyze the effect of applying these yaml files against the current cluster.\ngetmesh config-validate \u0026lt;file/directory\u0026gt;... [flags] Examples # validating a local manifest against the current cluster $ getmesh config-validate my-app.yaml another-app.yaml # validating local manifests in a directory against the current cluster in a specific namespace $ getmesh config-validate -n bookinfo my-manifest-dir/ NAME RESOURCE TYPE ERROR CODE\tSEVERITY\tMESSAGE httpbin Service IST0108 Warning [my-manifest-dir/service.yaml:1] Unknown annotation: networking.istio.io/non-exist # for all namespaces $ getmesh config-validate NAMESPACE NAME RESOURCE TYPE ERROR CODE SEVERITY MESSAGE default bookinfo-gateway Gateway IST0101 Error Referenced selector not found: \u0026quot;app=nonexisting\u0026quot; bookinfo default Peerauthentication KIA0505 Error Destination Rule disabling namespace-wide mTLS is missing bookinfo bookinfo-gateway Gateway KIA0302 Warning No matching workload found for gateway selector in this namespace # for a specific namespace $ getmesh config-validate -n bookinfo NAME RESOURCE TYPE ERROR CODE SEVERITY MESSAGE bookinfo-gateway Gateway IST0101 Error Referenced selector not found: \u0026quot;app=nonexisting\u0026quot; bookinfo-gateway Gateway KIA0302 Warning No matching workload found for gateway selector in this namespace # for a specific namespace with Error as threshold for validation $ getmesh config-validate -n bookinfo --output-threshold Error NAME RESOURCE TYPE ERROR CODE SEVERITY MESSAGE bookinfo-gateway Gateway IST0101 Error Referenced selector not found: \u0026quot;app=nonexisting\u0026quot; The following is the explanation of each column: [NAMESPACE] namespace of the resource [NAME] name of the resource [RESOURCE TYPE] resource type, i.e. kind, of the resource [ERROR CODE] The error code of the found issue which is prefixed by 'IST' or 'KIA'. Please refer to - https://istio.io/latest/docs/reference/config/analysis/ for 'IST' error codes - https://kiali.io/documentation/latest/validations/ for 'KIA' error codes [SEVERITY] the severity of the found issue [MESSAGE] the detailed message of the found issue Options  -n, --namespace string namespace for config validation --output-threshold string severity level of analysis at which to display messages. Valid values: [Error Warning Info] (default \u0026quot;Info\u0026quot;) -h, --help help for config-validate Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_default-hub/","title":"getmesh default-hub","description":"","content":"Set or Show the default hub (root for Istio docker image paths) passed to \u0026ldquo;getmesh istioctl install\u0026rdquo; via \u0026ldquo;\u0026ndash;set hub=\u0026rdquo; e.g. docker.io/istio\ngetmesh default-hub [flags] Examples # Set the default hub to docker.io/istio $ getmesh default-hub --set docker.io/istio # Show the configured default hub $ getmesh default-hub --show # Remove the configured default hub $ getmesh default-hub --remove Options  -h, --help help for default-hub --remove remove the configured default hub --set string pass the location of hub, e.g. --set gcr.io/istio-testing --show set to show the current default hub value Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_fetch/","title":"getmesh fetch","description":"","content":"Fetch istioctl of the specified version, flavor and flavor-version available in \u0026ldquo;getmesh list\u0026rdquo; command\ngetmesh fetch [flags] Examples # Fetch the latest \u0026quot;tetrate flavored\u0026quot; istioctl of version=1.8 $ getmesh fetch --version 1.8 # Fetch the latest istioctl in version=1.7 and flavor=tetratefips $ getmesh fetch --version 1.7 --flavor tetratefips # Fetch the latest istioctl of version=1.7, flavor=tetrate and flavor-version=0 $ getmesh fetch --version 1.7 --flavor tetrate --flavor-version 0 # Fetch the istioctl of version=1.7.4 flavor=tetrate flavor-version=0 $ getmesh fetch --version 1.7.4 --flavor tetrate --flavor-version 0 # Fetch the istioctl of version=1.7.4 flavor=tetrate flavor-version=0 using name $ getmesh fetch --name 1.7.4-tetrate-v0 # Fetch the latest istioctl of version=1.7.4 and flavor=tetratefips $ getmesh fetch --version 1.7.4 --flavor tetratefips # Fetch the latest \u0026quot;tetrate flavored\u0026quot; istioctl of version=1.7.4 $ getmesh fetch --version 1.7.4 # Fetch the istioctl of version=1.8.3 flavor=istio flavor-version=0 $ getmesh fetch --version 1.8.3 --flavor istio # Fetch the latest \u0026quot;tetrate flavored\u0026quot; istioctl $ getmesh fetch As you can see the above examples: - If --flavor-versions is not given, it defaults to the latest flavor version in the list If the value does not have patch version, \u0026quot;1.7\u0026quot; or \u0026quot;1.8\u0026quot; for example, then we fallback to the latest patch version in that minor version. - If --flavor is not given, it defaults to \u0026quot;tetrate\u0026quot; flavor. - If --versions is not given, it defaults to the latest version of \u0026quot;tetrate\u0026quot; flavor. For more information, please refer to \u0026quot;getmesh list --help\u0026quot; command. Options  --name string Name of distribution, e.g. 1.9.0-istio-v0 --version string Version of istioctl e.g. \u0026quot;--version 1.7.4\u0026quot;. When --name flag is set, this will not be used. --flavor string Flavor of istioctl, e.g. \u0026quot;--flavor tetrate\u0026quot; or --flavor tetratefips\u0026quot; or --flavor istio\u0026quot;. When --name flag is set, this will not be used. --flavor-version int Version of the flavor, e.g. \u0026quot;--version 1\u0026quot;. When --name flag is set, this will not be used. (default -1) -h, --help help for fetch Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_gen-ca/","title":"getmesh gen-ca","description":"","content":"Generates intermediate CA from different managed services such as AWS ACMPCA, GCP CAS\ngetmesh gen-ca [flags] Examples - AWS: cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; aws.yaml providerName: aws disableSecretCreation: false providerConfig: aws: signingCAArn: \u0026lt;your ACM PCA CA ARN\u0026gt; templateArn: arn:aws:acm-pca:::template/SubordinateCACertificate_PathLen0/V1 signingAlgorithm: SHA256WITHRSA certificateParameters: secretOptions: istioCANamespace: istio-system secretFilePath: ~/.getmesh/secret/ overrideExistingCACertsSecret: false caOptions: certSigningRequestParams: raw: [] rawtbscertificaterequest: [] rawsubjectpublickeyinfo: [] rawsubject: [] version: 0 signature: [] signaturealgorithm: 0 publickeyalgorithm: 0 publickey: null subject: country: - US organization: - Istio organizationalunit: [] locality: - Sunnyvale province: - California streetaddress: [] postalcode: [] serialnumber: \u0026quot;\u0026quot; commonname: Istio CA names: [] extranames: [] attributes: [] extensions: [] extraextensions: [] dnsnames: - ca.istio.io emailaddresses: [] ipaddresses: [] uris: [] validityDays: 3650 keyLength: 2048 EOF getmesh gen-ca --config-file aws.yaml - GCP: cat \u0026lt;\u0026lt;EOF \u0026gt;\u0026gt; gcp.yaml providerName: gcp disableSecretCreation: false providerConfig: gcp: casCAName: projects/{project-id}/locations/{location}/certificateAuthorities/{YourCA} maxIssuerPathLen: 0 certificateParameters: secretOptions: istioCANamespace: istio-system secretFilePath: ~/.getmesh/secret/ overrideExistingCACertsSecret: false caOptions: certSigningRequestParams: raw: [] rawtbscertificaterequest: [] rawsubjectpublickeyinfo: [] rawsubject: [] version: 0 signature: [] signaturealgorithm: 0 publickeyalgorithm: 0 publickey: null subject: country: - US organization: - Istio organizationalunit: [] locality: - Sunnyvale province: - California streetaddress: [] postalcode: [] serialnumber: \u0026quot;\u0026quot; commonname: Istio CA names: [] extranames: [] attributes: [] extensions: [] extraextensions: [] dnsnames: - ca.istio.io emailaddresses: [] ipaddresses: [] uris: [] validityDays: 3650 keyLength: 2048 EOF getmesh gen-ca --config-file gcp.yaml Options  --config-file string path to config file --disable-secret-creation file only, doesn't create secret -p, --provider string name of the provider to be used, i.e aws, gcp --signing-ca string signing CA ARN string --template-arn string Template ARN used to be used for issuing Cert using CSR --signing-algorithm string Signing Algorithm to be used for issuing Cert using CSR for AWS --cas-ca-name string CAS CA Name string --max-issuer-path-len int32 CAS CA Max Issuer Path Length --common-name string Common name for x509 Cert request --country stringArray Country names for x509 Cert request --province stringArray Province names for x509 Cert request --locality stringArray Locality names for x509 Cert request --organization stringArray Organization names for x509 Cert request --organizational-unit stringArray OrganizationalUnit names for x509 Cert request --email stringArray Emails for x509 Cert request --istio-ca-namespace cacerts Namespace refered for creating the cacerts secrets in --secret-file-path string secret-file-path flag creates the secret YAML file --override-existing-ca-cert-secret override-existing-ca-cert-secret overrides the existing secret and creates a new one --validity-days int valid dates for subordinate CA --key-length int length of generated key in bits for CA -h, --help help for gen-ca Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_help/","title":"getmesh help","description":"","content":"Help provides help for any command in the application. Simply type getmesh help [path to command] for full details.\ngetmesh help [command] [flags] Options  -h, --help help for help Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_istioctl/","title":"getmesh istioctl","description":"","content":"Execute istioctl with given arguments where the version of istioctl is set by \u0026ldquo;getsitio fetch or switch\u0026rdquo;\ngetmesh istioctl \u0026lt;args...\u0026gt; [flags] Examples # install Istio with the default profile getmesh istioctl install --set profile=default # check versions of Istio data plane, control plane, and istioctl getmesh istioctl version Options  -h, --help help for istioctl Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_list/","title":"getmesh list","description":"","content":"List available Istio distributions built by Tetrate\ngetmesh list [flags] Examples $ getmesh list ISTIO VERSION\tFLAVOR FLAVOR VERSION\tK8S VERSIONS *1.8.2 tetrate\t0 1.16,1.17,1.18 1.8.1 tetrate\t0 1.16,1.17,1.18 1.7.6 tetrate\t0 1.16,1.17,1.18 1.7.5 tetrate\t0 1.16,1.17,1.18 1.7.4 tetrate\t0 1.16,1.17,1.18 '*' indicates the currently active istioctl version. The following is the explanation of each column: [ISTIO VERSION] The upstream tagged version of Istio on which the distribution is built. [FLAVOR] The kind of the distribution. As of now, there are three flavors \u0026quot;tetrate\u0026quot;, \u0026quot;tetratefips\u0026quot; and \u0026quot;istio\u0026quot;. - \u0026quot;tetrate\u0026quot; flavor equals the upstream Istio except it is built by Tetrate. - \u0026quot;tetratefips\u0026quot; flavor is FIPS-compliant, and can be used for installing FIPS-compliant control plain and data plain built by Tetrate. - \u0026quot;istio\u0026quot; flavor is the upstream build. Flavor version for upstream build will always be '0' [FLAVOR VERSION] The flavor's version. A flavor version 0 maps to the distribution that is built on exactly the same source code of the corresponding upstream Istio version. [K8S VERSIONS] Supported k8s versions for the distribution Options  -h, --help help for list Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_prune/","title":"getmesh prune","description":"","content":"Remove specific istioctl installed, or all, except the active one\ngetmesh prune [flags] Examples # remove all the installed $ getmesh prune # remove the specific distribution $ getmesh prune --version 1.7.4 --flavor tetrate --flavor-version 0 Options  --version string Version of istioctl e.g. 1.7.4 --flavor string Flavor of istioctl, e.g. \u0026quot;tetrate\u0026quot; or \u0026quot;tetratefips\u0026quot; or \u0026quot;istio\u0026quot; --flavor-version int Version of the flavor, e.g. 1 (default -1) -h, --help help for prune Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_show/","title":"getmesh show","description":"","content":"Show fetched Istio version\ngetmesh show [flags] Examples getmesh show Options  -h, --help help for show Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_switch/","title":"getmesh switch","description":"","content":"Switch the active istioctl to a specified version\ngetmesh switch [flags] Examples # Switch the active istioctl version to version=1.7.7, flavor=tetrate and flavor-version=0 $ getmesh switch --version 1.7.7 --flavor tetrate --flavor-version=0, # Switch to version=1.8.3, flavor=istio and flavor-version=0 using name flag $ getmesh switch --name 1.8.3-istio-v0 # Switch from active version=1.8.3 to version 1.9.0 with the same flavor and flavor-version $ getmesh switch --version 1.9.0 # Switch from active \u0026quot;tetrate flavored\u0026quot; version to \u0026quot;istio flavored\u0026quot; version with the same version and flavor-version $ getmesh switch --flavor istio # Switch from active version=1.8.3, flavor=istio and flavor-version=0 to version 1.9.0, flavor=tetrate and flavor-version=0 $ getmesh switch --version 1.9.0 --flavor=tetrate # Switch from active version=1.8.3, flavor=istio and flavor-version=0 to version=1.8.3, flavor=tetrate, flavor-version=1 $ getmesh switch --flavor tetrate --flavor-version=1 # Switch from active version=1.8.3, flavor=istio and flavor-version=0 to the latest 1.9.x version, flavor=istio and flavor-version=0 $ getmesh switch --version 1.9 Options  --name string Name of distribution, e.g. 1.9.0-istio-v0 --version string Version of istioctl, e.g. 1.7.4. When --name flag is set, this will not be used. --flavor string Flavor of istioctl, e.g. \u0026quot;tetrate\u0026quot; or \u0026quot;tetratefips\u0026quot; or \u0026quot;istio\u0026quot;. When --name flag is set, this will not be used. --flavor-version int Version of the flavor, e.g. 1. When --name flag is set, this will not be used (default -1) -h, --help help for switch Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/zh/getmesh-cli/reference/getmesh_version/","title":"getmesh version","description":"","content":"Show the versions of getmesh cli, running Istiod, Envoy, and the active istioctl\ngetmesh version [flags] Options  -h, --help help for version --remote Use --remote=false to suppress control plane and data plane check (default true) Options inherited from parent commands  -c, --kubeconfig string Kubernetes configuration file SEE ALSO  getmesh\t- getmesh is an integration and lifecycle management CLI tool that ensures the use of supported and trusted versions of Istio.  "},{"url":"https://istio.tetratelabs.io/community/release/","title":"Release process","description":"","content":"In order to cut a new release tag and release the new version from the main branch, you should create a PR where GETMESH_LATEST_VERSION in install.sh is updated to be the new release tag. In this way, the install.sh would behave so that it would download the new version by default.\n"},{"url":"https://istio.tetratelabs.io/zh/search/","title":"Search Result","description":"this is meta description","content":""},{"url":"https://istio.tetratelabs.io/zh/contact/","title":"Vous avez des questions","description":"this is meta description","content":""}]